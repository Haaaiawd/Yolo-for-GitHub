分 类 号_\___\___\____ 密级_\___公开_\____

收藏编号_\___\___\____ 学号__ \__

学校代码 10386 编号_\___\___\___\___

(应用研究)

**基于遥感图像的飞机目标检测与细粒度识别算法研究**

|     |     |
| --- | --- |
| 工程领域： | 新一代电子信息技术（含量子技术）等 |
| 研究方向： |     |
| 研究生姓名： | 张雪  |
| 指导教师、职称： | 林珊玲讲师 |
| 协助导师、职称： | 林坚普讲师 |
| 所在学院： | 先进制造学院 |
| 答辩委员会主席： |     |

二〇二五 年 六月

基于遥感图像的飞机目标检测与细粒度识别算法研究

中文摘要

随着遥感技术的快速发展，飞机目标检测在军事侦察、环境监测等领域的重要性日益凸显。然而，遥感图像中的飞机目标检测面临诸多挑战，如目标尺寸小、背景复杂、数据量大等，现有检测算法难以满足高精度和实时性检测的需求。此外，嵌入式平台的计算资源有限，如何在这些平台上实现高效的目标检测也是一项重要挑战。针对上述问题，本文围绕精度提升、轻量化处理和嵌入式部署三个核心问题开展研究，具体的研究内容如下：

（1）针对光学遥感图像中飞机目标检测算法因背景复杂、受测飞机目标较小以及外观差异较小导致检测精度不足的问题，提出了一种融合全局信息与双域注意力机制的检测与细粒度识别算法（GDA-YOLO）全拼。该算法以YOLOv8全拼为基础，设计并引入基于全局信息的快速空间金字塔池化模块，帮助模型在复杂环境中更好地区分目标与背景；提出了双域注意力机制提升模型对飞机细粒度特征的敏感性；采用并行路径改进下采样模块以保留小目标细节信息；最后改进了损失函数，通过自适应惩罚因子加速模型的收敛。实验结果表明：与原始YOLOv8n相比，该算法在公开数据集MAR20上的精确率，召回率、mAP50以及mAP50-95分别提高了3.3%，2.6%，3.2%和2.6%；在NWPU VHR-10数据集上分别提高了5%，5.1%，2.5%和0.3%；同时，参数量和运算量分别降低了6.6%和3.7%。

（2）为了降低计算复杂度并适应嵌入式部署，制定了模型轻量化策略。首先对模型进行预处理，以确保剪枝过程的安全性和功能完整性，通过构建依赖图与LAMP全拼重要性评估实现了自动化剪枝，并结合微调训练筛选出最佳模型。针对蒸馏过程中存在的跨任务协议不一致性问题，通过结合二元分类蒸馏损失、基于IoU的定位蒸馏损失与GDA-YOLO原始损失函数，优化教师模型向剪枝后的轻量化学生模型的知识迁移。实验结果表明：轻量化处理后的模型相较于原始GDA-YOLO模型，参数量减少了86.5%，计算复杂度降低了71.2%，推理速度提升了约56.1%。与此同时，模型精度稍有提升，成功实现了模型轻量化。

（3）本文基于NVIDIA Jetson Xavier NX嵌入式平台，结合TensorRT推理优化技术，搭建了一个用户友好的遥感图像飞机目标检测系统。该系统通过图形用户界面（GUI）实现了实时图像采集、目标检测推理及结果展示，优化了用户体验。实验表明，相较于PyTorch平台，经过TensorRT优化后的模型推理时间22.3ms降至15.4ms，推理速度提升了30.9%，实现了嵌入式平台的高效检测。

关键词：遥感图像；飞机目标检测；细粒度识别；深度学习；模型轻量化

Research on Aircraft Target Detection and Fine-Grained Recognition Algorithms in Remote Sensing Images

Abstract

With the rapid development of remote sensing technology, aircraft target detection has become increasingly important in fields such as military reconnaissance and environmental monitoring. However, the detection of aircraft targets in remote sensing images presents several challenges, including small target sizes, complex backgrounds, and large data volumes. Existing detection algorithms struggle to meet the demands for both high accuracy and real-time performance. Additionally, the limited computational resources of embedded platforms pose another significant challenge for efficient target detection. To address these issues, this thesis focuses on three core aspects: performance optimization, lightweight processing, and embedded deployment. The specific research contributions are as follows:

(1) To overcome the problem of insufficient detection accuracy in optical remote sensing images caused by complex backgrounds, small target sizes, and minimal appearance differences, a novel detection and fine-grained recognition algorithm (GDA-YOLO) is proposed. Based on YOLOv8, this algorithm introduces a fast spatial pyramid pooling module based on global information to help the model better distinguish between targets and backgrounds in complex environments. A dual-domain attention mechanism is proposed to enhance the model's sensitivity to fine-grained features of aircraft. Additionally, a parallel path is used to improve the downsampling module, preserving details of small targets. An adaptive penalty factor is incorporated into the loss function to accelerate model convergence. Experimental results show that, compared with the original YOLOv8n, the proposed algorithm improves precision, recall, mAP50, and mAP50-95 by 3.3%, 2.6%, 3.2%, and 2.6%, respectively, on the public MAR20 dataset; on the NWPU VHR-10 dataset, improvements of 5%, 5.1%, 2.5%, and 0.3% are achieved. At the same time, the number of parameters and computational complexity are reduced by 6.6% and 3.7%, respectively.

(2) To reduce computational complexity and facilitate embedded deployment, a model lightweighting strategy is developed. The model is preprocessed to ensure the safety and integrity of the pruning process. By constructing a dependency graph and evaluating importance using LAMP, automated channel pruning is achieved. Fine-tuning training is then applied to select the best model. To address inconsistencies in cross-task protocols during knowledge distillation, a binary classification distillation loss, an IoU-based localization distillation loss, and the original GDA-YOLO loss function are combined to optimize knowledge transfer from the teacher model to the pruned lightweight student model. Experimental results demonstrate that, compared to the original GDA-YOLO, the lightweighted model achieves a 86.5% reduction in parameters, a 71.2% reduction in computational complexity, and a 56.1% increase in inference speed. Meanwhile, the model’s accuracy is slightly improved, successfully achieving model lightweighting.

(3) Based on the NVIDIA Jetson Xavier NX embedded platform and TensorRT inference optimization, a user-friendly remote sensing aircraft target detection system is developed. This system integrates real-time image acquisition, target detection inference, and result visualization through a graphical user interface (GUI), significantly enhancing user experience. Experimental results show that, compared to the PyTorch platform, the inference time of the TensorRT-optimized model is reduced from 22.3ms to 15.4ms, resulting in a 30.9% improvement in inference speed, enabling efficient target detection.

Keywords: Remote Sensing Images; Aircraft Target Detection; Fine-Grained Recognition; Deep Learning; Model Lightweight

目录

[中文摘要 I](#_Toc192363200)

[Abstract II](#_Toc192363201)

[第一章 绪论 1](#_Toc192363202)

[1.1 研究背景及意义 1](#_Toc192363203)

[1.2 国内外研究现状 2](#_Toc192363204)

[1.2.1 传统目标检测研究现状 2](#_Toc192363205)

[1.2.2 深度学习目标检测研究现状 3](#_Toc192363206)

[1.2.3 遥感飞机目标检测研究现状 5](#_Toc192363207)

[1.3 本文主要研究内容 7](#_Toc192363208)

[1.4 本文结构安排 8](#_Toc192363209)

[第二章 相关理论与技术介绍 11](#_Toc192363210)

[2.1 卷积神经网络的结构与特点 11](#_Toc192363211)

[2.1.1 卷积层 12](#_Toc192363212)

[2.1.2 池化层 13](#_Toc192363213)

[2.1.3 激活函数 13](#_Toc192363214)

[2.1.4 全连接层 16](#_Toc192363215)

[2.2 YOLO目标检测算法原理和结构 17](#_Toc192363216)

[2.2.1 YOLO算法基本原理 17](#_Toc192363217)

[2.2.2 YOLOv8算法结构 18](#_Toc192363218)

[2.3 目标检测模型轻量化方法 22](#_Toc192363219)

[2.3.1 模型剪枝 22](#_Toc192363220)

[2.3.2 知识蒸馏 23](#_Toc192363221)

[2.4 本章小结 24](#_Toc192363222)

[第三章 基于GDA-YOLO的飞机目标检测与细粒度识别算法 25](#_Toc192363223)

[3.1 模型整体框架 25](#_Toc192363224)

[3.2 网络结构设计与优化 26](#_Toc192363225)

[3.2.1 基于全局信息的快速空间金字塔池化模块 26](#_Toc192363226)

[3.2.2 双域注意力机制 27](#_Toc192363227)

[3.2.3 下采样方式的改进 28](#_Toc192363228)

[3.2.4 损失函数改进 29](#_Toc192363229)

[3.3 实验结果与分析 31](#_Toc192363230)

[3.3.1 实验设备和数据集 31](#_Toc192363231)

[3.3.2 公共评价指标 32](#_Toc192363232)

[3.3.3 不同空间金字塔池化模块的实验与结果分析 32](#_Toc192363233)

[3.3.4 不同注意力机制的实验与结果分析 33](#_Toc192363234)

[3.3.5 消融实验与结果分析 34](#_Toc192363235)

[3.3.6 对比实验与结果分析 36](#_Toc192363236)

[3.4 本章小结 40](#_Toc192363237)

[第四章 基于飞机目标检测与细粒度识别算法的轻量化方法研究 41](#_Toc192363238)

[4.1 轻量化方案的选择和制定 41](#_Toc192363239)

[4.2 模型剪枝流程 43](#_Toc192363240)

[4.2.1 模型预处理 43](#_Toc192363241)

[4.2.2 构建依赖图 44](#_Toc192363242)

[4.2.3 基于LAMP重要性评估的通道剪枝 46](#_Toc192363243)

[4.2.4 微调训练 47](#_Toc192363244)

[4.3 知识蒸馏优化方案 48](#_Toc192363245)

[4.3.1 跨任务协议不一致性问题 48](#_Toc192363246)

[4.3.2 蒸馏损失函数优化 50](#_Toc192363247)

[4.4 实验结果与分析 51](#_Toc192363248)

[4.4.1 实验设备和数据集 51](#_Toc192363249)

[4.4.2 公共评价指标 52](#_Toc192363250)

[4.4.3 剪枝实验与结果分析 52](#_Toc192363251)

[4.4.4 蒸馏实验与结果分析 56](#_Toc192363252)

[4.4.5 模型各阶段性能对比分析 58](#_Toc192363253)

[4.5 本章小结 59](#_Toc192363254)

[第五章 遥感飞机目标检测算法应用系统搭建 60](#_Toc192363255)

[5.1 应用系统整体设计 60](#_Toc192363256)

[5.2 嵌入式计算平台部署 61](#_Toc192363257)

[5.2.1 硬件平台介绍 61](#_Toc192363258)

[5.2.2 开发环境配置 63](#_Toc192363259)

[5.2.3 TensorRT加速处理 64](#_Toc192363260)

[5.2.4 加速效果对比 67](#_Toc192363261)

[5.3 检测系统界面设计 68](#_Toc192363262)

[5.3.1 系统开发环境 68](#_Toc192363263)

[5.3.2 系统界面设计 68](#_Toc192363264)

[5.3.3 系统功能展示 70](#_Toc192363265)

[5.4 本章小结 71](#_Toc192363266)

[总结与展望 72](#_Toc192363267)

[总结 72](#_Toc192363268)

[展望 73](#_Toc192363269)

[参考文献 75](#_Toc192363270)

[致谢 81](#_Toc192363271)

[个人简历 82](#_Toc192363272)

[在学期间的研究成果及发表的学术论文 83](#_Toc192363273)

# 第一章 绪论

## 1.1 研究背景及意义

遥感技术是一种通过非接触方式，利用卫星、无人机、飞机等传感器从远距离获取地面、海洋、大气等自然或人工物体信息的技术。遥感图像则是通过这些传感器收集到的地面信息数据，通常以光学、红外、雷达等多种电磁波波段的形式呈现。自2010年高分专项启动以来，我国先后发射了多个高分卫星，成功实现了亚米级空间分辨率与高时间分辨率的有机结合，显著提升了对地观测的能力。近年来，随着高分十一号、十二号等卫星的投入使用，遥感数据的获取不仅覆盖范围持续扩大，数据精度与更新频率也得到了显著提升。通过天基、临近空间及航空平台等多种观测手段，这些卫星具备了全天候、全天时、全球覆盖的对地观测能力。这一技术的进步，不仅为环境监测、灾害预警、资源调查等领域提供了强有力的支持，也使得如何从海量遥感图像中高效提取关键信息，成为当前遥感图像处理领域的核心挑战与研究热点。

在现代战争和军事侦察中，飞机目标检测尤为重要。随着遥感技术的不断进步，尤其是在卫星遥感和航空遥感平台的应用上，飞机目标的检测和识别已成为军事作战战略决策的关键。准确的飞机目标检测不仅直接影响作战方的战略部署和战术选择，更在空中作战、情报侦察及制空权争夺中扮演着至关重要的角色。举例来说，在2011年利比亚战争中，北约通过卫星与无人机的遥感图像成功监控并精准打击了卡扎菲政权的空军基地，极大地改变了战局格局。类似地，2014年俄罗斯与乌克兰的冲突中，乌克兰军方通过卫星遥感和无人机数据进行实时目标侦察，精准定位敌方飞机并进行有效反击。这些案例表明，飞机目标检测技术的高效性与精准性在现代军事行动中具有决定性作用。随着信息化战争的深入发展，遥感技术与飞机目标检测的结合，不仅为空中打击和防空作战提供了实时情报支持，还能通过干扰敌方空中优势，显著提升作战效能。因此，研究遥感图像中的飞机目标检测，已成为提升军事侦察、精准打击和制空权争夺能力的关键技术。

近年来，深度学习技术，特别是卷积神经网络（Convolutional Neural Networks, CNN）已经在许多计算机视觉任务中展现出优异的性能，尤其是在自然图像目标检测方面。然而，遥感图像与自然场景图像存在显著差异，这使得现有的深度学习模型在处理遥感图像时面临诸多挑战。特别是在遥感图像中的飞机目标检测任务中，由于受测飞机目标较小、背景复杂以及外观差异较小，传统的深度学习算法在这类任务中的适应性和表现力仍显不足。因此，如何进一步提升深度学习模型在细粒度识别任务中的检测精度，成为遥感图像目标检测领域亟待解决的关键问题。

此外，随着嵌入式平台和边缘计算技术的崛起，如何在计算资源受限的条件下实现高效的目标检测也成为一个重要研究方向。尤其是对于实时性要求较高的军事应用场景，优化模型的计算开销与推理效率对于提升检测系统的实用性至关重要。通过合理的轻量化策略，可以在保持检测精度的同时，减少计算量、降低推理延迟，使模型能够在资源有限的嵌入式平台上高效运行，从而推动遥感图像目标检测技术在实际场景中的应用。

在此背景下，本文旨在研究基于深度学习的遥感图像飞机目标检测与细粒度识别问题，探索通过算法创新与优化，提升飞机目标检测的精度和效率。考虑到嵌入式平台在计算资源上的限制，本文还将探讨模型轻量化的方法，设计适用于嵌入式平台的高效目标检测算法。通过这些研究，本文期望为遥感图像中的飞机目标检测提供一种既高效又精准的解决方案，为相关领域的应用提供技术支持。

## 1.2 国内外研究现状

### 1.2.1 传统目标检测研究现状

传统的目标检测方法通常依赖于基于机器学习的框架，主要包括候选区域生成、特征提取和分类器设计三个关键步骤。

候选区域生成是目标检测的首要步骤，目的是从图像中生成可能包含目标的区域。在早期的传统方法中，候选区域生成通常依赖于滑动窗口技术，即通过在图像中逐步滑动一个固定大小的窗口，对每个窗口内的图像区域进行分类。这种方法简单直观，但计算量大，效率较低。为了减少计算量，Uijlings等人<sup>\[</sup>[<sup>1</sup>](#_ENREF_1)<sup>\]</sup>提出选择性搜索（Selective Search）方法，采用图像分割和合并策略，通过生成可能包含目标的候选区域来提高效率，尽管该方法有效减少了计算量，但仍然存在对小目标的检测效果不佳的问题。

特征提取是目标检测中的另一个关键步骤，传统方法依赖于人工设计的特征来描述图像中的目标。常见的特征提取方法包括方向梯度直方图（Histogram of Oriented Gradients，HOG）<sup>\[</sup>[<sup>2</sup>](#_ENREF_2)<sup>\]</sup>、尺度不变特征变换（Scale-Invariant Feature Transform，SIFT）<sup>\[</sup>[<sup>3</sup>](#_ENREF_3)<sup>\]</sup>和加速鲁棒特征（Speeded-Up Robust Features，SURF）<sup>\[</sup>[<sup>4</sup>](#_ENREF_4)<sup>\]</sup>等。HOG特征通过计算图像局部区域的梯度方向直方图，能够有效地捕捉目标的形状信息，特别在行人检测中表现优异。SIFT通过提取具有尺度和旋转不变性的局部特征，使得图像中的目标在多种变换下仍然能够稳定识别。SURF则在SIFT的基础上进行了优化，通过加速特征提取过程，使得其在实时检测中更具优势。尽管这些手工特征能够提供一定的判别力，但它们往往缺乏对复杂背景和多样化目标的适应性，且特征的选择和设计需要大量的先验知识和经验。

分类器设计是目标检测的最后一步，目的是根据提取的特征来判断候选区域是否包含目标。传统方法常采用基于机器学习的分类器，如支持向量机（Support Vector Machine，SVM）<sup>\[</sup>[<sup>5</sup>](#_ENREF_5)<sup>\]</sup>、最近邻（k-Nearest Neighbors，k-NN）<sup>\[</sup>[<sup>6</sup>](#_ENREF_6)<sup>\]</sup>、随机森林（Random Forest，RF）<sup>\[</sup>[<sup>7</sup>](#_ENREF_7)<sup>\]</sup>、条件随机场（Conditional Random Field，CRF）<sup>\[</sup>[<sup>8</sup>](#_ENREF_8)<sup>\]</sup>以及基于稀疏表示的分类器（Sparse Representation Classification，SRC）<sup>\[</sup>[<sup>9</sup>](#_ENREF_9)<sup>\]</sup>等方法，对候选区域进行分类。另一种典型的分类器是Adaboost<sup>\[</sup>[<sup>10</sup>](#_ENREF_10)<sup>\]</sup>，它通过组合多个弱分类器形成强分类器，常用于人脸检测等应用。然而，传统分类器的性能通常受到特征选择和区域生成策略的限制，尤其在面对复杂背景和遮挡问题时，检测精度会大打折扣。

总体而言，传统的基于机器学习的目标检测方法在一定场景下取得了一定的成功，但仍存在诸如计算复杂度高、缺乏对复杂场景适应性差、无法自动学习高层次特征等问题。因此，随着深度学习的发展，基于卷积神经网络的目标检测方法逐渐成为主流，并能够克服传统方法的一些局限性。

### 1.2.2 深度学习目标检测研究现状

随着深度学习的迅速发展，卷积神经网络在计算机视觉中的应用取得了巨大成功，尤其是在目标检测任务中。现代目标检测算法大致分为两大类：两阶段目标检测算法和单阶段目标检测算法。

两阶段目标检测算法通常包含候选区域生成和区域分类及位置回归两个步骤。这类方法由于能够充分学习目标特征，因此通常具有较高的检测精度，适合精度要求较高的任务。然而，候选区域生成和后续的细化处理通常带来了较大的计算开销，从而使得检测速度较慢。R-CNN<sup>\[</sup>[<sup>11</sup>](#_ENREF_11)<sup>\]</sup>是两阶段目标检测算法的开创性工作，由Girshick等人提出。R-CNN首先使用选择性搜索生成候选区域，然后通过卷积神经网络提取特征，最后将特征输入SVM进行分类。虽然R-CNN大幅提高了检测精度，但每个候选区域都需要单独进行特征提取和分类，计算量庞大，速度较慢。为了提高效率，Girshick等人<sup>\[</sup>[<sup>12</sup>](#_ENREF_12)<sup>\]</sup>于2015年提出了Fast R-CNN，该方法通过共享卷积特征图和引入RoI池化层，在减少计算开销的同时提高了检测精度，但其区域提取过程仍然较慢，未能完全解决效率问题。为了进一步提升检测速度，Ren等人<sup>\[</sup>[<sup>13</sup>](#_ENREF_13)<sup>\]</sup>提出了Faster R-CNN，采用了区域建议网络（Region Proposal Network，RPN）来自动生成候选区域，取代了传统的选择性搜索，从而显著提高了速度和效率。然而，尽管RPN有效减少了候选区域生成的时间开销，Faster R-CNN在处理多个不规则区域框时，仍然面临不同尺寸区域框的匹配和优化问题。在此基础上，He等人<sup>\[</sup>[<sup>14</sup>](#_ENREF_14)<sup>\]</sup>提出了Mask R-CNN，在Faster R-CNN的框架上增加了一个分支，用于同时进行目标检测和实例分割，提供了像素级别的目标分割信息，进一步提高了检测的精度和适应性。Cai等人<sup>\[</sup>[<sup>15</sup>](#_ENREF_15)<sup>\]</sup>提出的Cascade R-CNN通过引入级联结构逐步优化预测边界框与实际边界框的交并比（Intersection over Union，IoU）阈值，进一步提升了检测精度。此外，Lin等人<sup>\[</sup>[<sup>16</sup>](#_ENREF_16)<sup>\]</sup>提出的特征金字塔网络（Feature Pyramid Networks，FPN）通过构建多尺度的特征金字塔，解决了上下文信息丢失的问题，特别在小目标和多尺度目标检测中表现突出。后续的NAS-FPN<sup>\[</sup>[<sup>17</sup>](#_ENREF_17)<sup>\]</sup>和Bi-FPN<sup>\[</sup>[<sup>18</sup>](#_ENREF_18)<sup>\]</sup>进一步优化了特征金字塔的结构，提升了检测性能。近年来，随着Transformer和注意力机制的引入，目标检测的精度得到了显著提升。例如，Sun等人<sup>\[</sup>[<sup>19</sup>](#_ENREF_19)<sup>\]</sup>提出的Sparse RCNN采用了稀疏注意力机制，在提升检测性能的同时减少了计算量。同年，Liu等人提出的Swin Transformer<sup>\[</sup>[<sup>20</sup>](#_ENREF_20)<sup>\]</sup> 通过创新的特征提取方法，进一步提高了目标检测的精度。

虽然两阶段目标检测算法在精度和效率上取得了显著进展，但仍然面临一些挑战。候选区域生成依然是瓶颈，尽管像RPN这样的方法能够自动生成候选区域，但在复杂背景和小目标处理上依然存在困难。此外，尽管多尺度特征融合和精细化处理（如Cascade R-CNN和FPN）有所提升，计算开销仍然较高，尤其在多目标检测和实时处理任务中。因此，如何在提升精度的同时优化计算效率，仍然是两阶段目标检测算法亟需解决的问题。

单阶段目标检测算法通过将目标检测任务视为回归问题，直接在原始图像上预测目标的位置和类别。相比于传统的两阶段方法，单阶段方法具有较低的计算开销和更快的检测速度，因此特别适合实时应用。YOLO（You Only Look Once）<sup>\[</sup>[<sup>21</sup>](#_ENREF_21)<sup>\]</sup>由Redmon等人提出，是最早的单阶段目标检测算法之一。其主要优势在于高效的端到端检测流程，通过在训练和推理阶段同时关注整个图像，使模型能够编码类别的全局信息。然而，YOLO早期版本的检测精度相对较低，尤其在小目标和复杂背景的检测任务中表现不佳。为了解决这些问题，Redmon<sup>\[</sup>[<sup>22</sup>](#_ENREF_22)<sup>\]</sup>和Farhadi等<sup>\[</sup>[<sup>23</sup>](#_ENREF_23)<sup>\]</sup>人先后提出了YOLOv2和YOLOv3，通过增加网络深度、引入多尺度特征以及优化训练策略，进一步提升了检测精度和速度。随后，YOLOv4<sup>\[</sup>[<sup>24</sup>](#_ENREF_24)<sup>\]</sup>通过结合Mish激活函数、CSPDarknet53主干网络等优化技术，进一步提升了检测性能。YOLOv5<sup>\[</sup>[<sup>25</sup>](#_ENREF_25)<sup>\]</sup>则在此基础上引入了Focus结构和自适应图像缩放策略，使得推理效率更高，适用于更广泛的应用场景。YOLOv6<sup>\[</sup>[<sup>26</sup>](#_ENREF_26)<sup>\]</sup>和YOLOv7<sup>\[</sup>[<sup>27</sup>](#_ENREF_27)<sup>\]</sup>分别由Li等人和Wang等人提出，采用了新的高效网络结构和优化标签分配策略，进一步提升了检测精度。YOLOv8<sup>\[</sup>[<sup>28</sup>](#_ENREF_28)<sup>\]</sup>在YOLOv5的基础上进一步优化了模型的灵活性与检测精度，并针对不同硬件平台进行了优化。2024年，YOLOv9<sup>\[</sup>[<sup>29</sup>](#_ENREF_29)<sup>\]</sup>、YOLOv10<sup>\[</sup>[<sup>30</sup>](#_ENREF_30)<sup>\]</sup>和YOLO11<sup>\[</sup>[<sup>31</sup>](#_ENREF_31)<sup>\]</sup>相继发布，继续推动目标检测领域在精度和速度上的进步。YOLOv12<sup>\[</sup>[<sup>32</sup>](#_ENREF_32)<sup>\]</sup>作为最新的版本发布于2025年，通过引入区域注意力模块、残差高效层聚合网络以及快速注意力机制等技术创新，打破了CNN模型在YOLO系列中的主导地位。另一经典单阶段算法是SSD<sup>\[</sup>[<sup>33</sup>](#_ENREF_33)<sup>\]</sup>，由Liu等人提出。SSD通过VGG-16作为主干网络，并在网络末端加入多尺度特征提取层，以增强不同尺度目标的检测能力。相比于YOLO，SSD具备更好的小目标检测能力，但在大目标检测上精度较低，同时由于基于默认锚框的回归预测，其召回率受到一定限制。为了解决这一问题，DSSD<sup>\[</sup>[<sup>34</sup>](#_ENREF_34)<sup>\]</sup>和FSSD<sup>\[</sup>[<sup>35</sup>](#_ENREF_35)<sup>\]</sup>通过引入反卷积操作和特征融合技术，使SSD在小目标检测方面的性能得到进一步提升。RetinaNet<sup>\[</sup>[<sup>36</sup>](#_ENREF_36)<sup>\]</sup>针对单阶段检测中前景与背景类别极度不均衡的问题，提出了Focal Loss，以降低易分类背景样本对训练的影响，从而改善模型对小目标和密集目标的检测性能，然而，RetinaNet的计算开销较大，在速度上不如YOLO系列。近年来，研究者们开始探索摆脱锚框的单阶段检测方案。CornerNet<sup>\[</sup>[<sup>37</sup>](#_ENREF_37)<sup>\]</sup>和CenterNet<sup>\[</sup>[<sup>38</sup>](#_ENREF_38)<sup>\]</sup>分别通过检测目标的角点和中心点来完成目标定位，避免了锚框匹配的不稳定性，在某些场景下表现优于传统单阶段检测算法。DETR<sup>\[</sup>[<sup>39</sup>](#_ENREF_39)<sup>\]</sup>则引入了Transformer架构，通过自注意力机制实现端到端检测，完全摒弃了锚框和非极大值抑制（Non-Maximum Suppression，NMS）后处理。然而，DETR在小目标检测和收敛速度方面存在一定问题，为此，Deformable DETR<sup>\[</sup>[<sup>40</sup>](#_ENREF_40)<sup>\]</sup>通过引入可变形注意力机制，提高了特征提取的灵活性，有效提升了检测效率。随后，RT-DETR<sup>\[</sup>[<sup>41</sup>](#_ENREF_41)<sup>\]</sup>在进一步优化Transformer计算效率的同时，提高了实时检测任务中的精度，使得Transformer架构在目标检测领域的应用更加广泛。

总体而言，单阶段目标检测算法在检测速度和计算效率方面具有显著优势。然而，由于单阶段方法缺乏显式的候选区域筛选过程，其检测精度仍难以达到两阶段方法的水平，尤其在复杂背景、小目标检测和密集目标场景下仍面临较大挑战。因此，如何在保证计算效率的同时进一步提升检测精度，仍然是单阶段目标检测算法的重要研究方向。

### 1.2.3 遥感飞机目标检测研究现状

早期的遥感图像飞机目标检测主要依赖于手工设计的模板匹配技术。模板匹配法的核心思想是通过预设的模板与图像中的候选区域进行匹配，从而确定目标的位置。虽然这种方法在处理特定目标时表现出较好的效果，但其局限性也十分明显。例如，Xu等人<sup>\[</sup>[<sup>42</sup>](#_ENREF_42)<sup>\]</sup>提出的结合边缘势函数和人工蜂群算法的方法能够提高模板的形态建模能力，但在高分辨率遥感图像中，模板匹配仍然面临较高的计算复杂度，且对目标尺度和旋转变化的适应性较差。Wu等人<sup>\[</sup>[<sup>43</sup>](#_ENREF_43)<sup>\]</sup>通过方向估计改进模板匹配方法，消除了方向影响并结合重构的相似性度量和拼图匹配算法来完成检测任务，但仍然难以应对复杂背景和多目标情况。Lin等人<sup>\[</sup>[<sup>44</sup>](#_ENREF_44)<sup>\]</sup>设计的旋转不变特征径向梯度角模板，在复杂背景下表现了较强的抗噪声能力，但对高分辨率图像的适应性仍有限，且计算量较大。因此，尽管模板匹配法在特定任务中表现良好，但其在复杂背景、多目标和高分辨率图像中的局限性限制了其在实际应用中的推广。

随着研究的深入，遥感飞机目标检测逐渐转向传统的机器学习方法，尤其是基于特征提取与分类的技术框架。Diao等人<sup>\[</sup>[<sup>45</sup>](#_ENREF_45)<sup>\]</sup>提出结合深度信念网络和视觉显著性机制的检测框架，通过显著性机制快速生成候选框，减少了穷尽搜索的计算开销，提高了效率。然而，该方法在多尺度和多目标检测任务中仍面临效率问题，特别是在高分辨率图像中，候选框生成过程仍需大量计算，并且在多目标存在时容易产生漏检和误检。何燕等人<sup>\[</sup>[<sup>46</sup>](#_ENREF_46)<sup>\]</sup>提出的仿射尺度不变特征变换（ASIFT）方法，通过增强对仿射变换的鲁棒性，解决了尺度和旋转变化问题，但对于复杂背景和多目标，ASIFT依然无法有效区分目标，并且计算复杂度较高。总体来说，传统机器学习方法在处理多目标和复杂场景时，依赖于精细的特征设计和分类策略，但其处理目标间相互影响和复杂背景的能力有限，导致其在大规模遥感图像中的应用效果不尽如人意。因此，虽然传统机器学习方法通过特征提取与分类提升了检测精度，但在多目标检测和复杂背景下仍面临挑战，这也推动了基于深度学习的方法逐渐成为遥感飞机目标检测的主流。

近年来，深度学习方法逐渐应用于遥感飞机目标检测。尽管通用目标检测模型在自然环境下能较好地完成任务，但由于遥感图像的拍摄视角单一、目标尺寸小和飞机目标特征相似，通用目标检测算法往往在遥感图像中出现漏检和误检问题。因此，研究者提出了多种针对遥感图像的改进方法。例如，Wu等人<sup>\[</sup>[<sup>47</sup>](#_ENREF_47)<sup>\]</sup>通过自校准卷积和空洞卷积优化Mask R-CNN，增强了高层特征信息，改善了高分辨率遥感图像中密集目标和复杂背景的检测效果，然而该方法依然面临计算量大、实时性差的问题，尤其在处理大规模图像时，计算开销巨大，难以满足实时检测的需求。Wang等人<sup>\[</sup>[<sup>48</sup>](#_ENREF_48)<sup>\]</sup>提出的飞机目标区域提议网络通过滑动窗口扫描特征图并根据飞机与基座的尺寸比值生成候选框，有效解决了不同飞机之间的尺度差异，尽管如此，候选框生成过程仍然较为繁琐，且对目标之间重叠和密集布局的适应性较差，易导致误检和漏检。针对小目标和复杂背景，Liu等人<sup>\[</sup>[<sup>49</sup>](#_ENREF_49)<sup>\]</sup>提出的YOLO-extract算法通过新的特征提取器和坐标注意力机制显著提高了飞机目标的检测精度，然而该方法在处理小目标时，仍面临模型尺寸与检测速度之间的平衡问题，对于高分辨率图像的小目标检测仍然存在精度不高和推理速度较慢的挑战。Zhao等人<sup>\[</sup>[<sup>50</sup>](#_ENREF_50)<sup>\]</sup>基于YOLOX算法提出了自适应注意力特征融合的多尺度目标检测方法，提升了遥感图像目标的特征表示能力。尽管该方法有效聚合了多尺度上下文信息，但在高分辨率图像中的细粒度目标检测方面，仍面临模型对小目标辨识能力不足的问题，且多尺度策略带来的计算量增加限制了其在实时检测中的应用。Zhang等人<sup>\[</sup>[<sup>51</sup>](#_ENREF_51)<sup>\]</sup>改进了YOLOv5的特征融合结构，提出了Efficient-RepGFPN，进一步增强了小目标的检测能力。然而，这种改进在提升检测精度方面仍有局限，尤其在复杂背景中，模型容易出现噪声干扰，影响检测效果。

由于飞机型号的识别对于提高航空安全、军事实力评估及精准打击能力等具有深远影响，许多学者也在此基础上开展了对飞机细粒度识别的研究。细粒度识别主要是为了解决同一类别内目标外观差异较小的问题，尤其在遥感图像中，飞机外观往往非常相似。为了提高精度，研究者们提出了多种方法来增强对细微差异的辨识能力，克服如复杂背景、尺度变化和方向变化等带来的挑战。例如，Zuo等人<sup>\[</sup>[<sup>52</sup>](#_ENREF_52)<sup>\]</sup>提出的基于深度卷积神经网络的飞机型号识别框架，通过飞机分割网络生成精细的分割结果，结合关键点检测网络识别飞机方向和边界框，并引入多旋转细化策略显著提高检测精度。然而，该方法在处理大规模遥感图像时计算开销较大，且多旋转细化策略在方向变化较大的场景下仍存在一定的局限性。曹旭等人<sup>\[</sup>[<sup>53</sup>](#_ENREF_53)<sup>\]</sup>提出混合增强样本处理方法与旋转混合任务级联网络，利用双三元组伪孪生架构优化细粒度识别性能。尽管此方法提升了网络的泛化能力，但生成混合样本可能会引入噪声，影响模型的稳定性。赵志恒等人<sup>\[</sup>[<sup>54</sup>](#_ENREF_54)<sup>\]</sup>通过改进特征提取模块并嵌入多尺度注意力机制，增强了模型在细粒度目标检测中的区分能力，但其多尺度注意力机制在高分辨率图像中可能导致计算量增加，影响模型性能。

总体而言，虽然基于深度学习的遥感飞机目标检测方法在精度上相较于传统方法有了显著提升，但这些方法在处理小目标、复杂背景、实时性以及模型部署方面仍然存在一定的不足。因此，针对遥感图像中飞机目标检测与细粒度识别的技术需求，如何提升检测精度、优化模型轻量化、实现高效的嵌入式部署，仍然是当前和未来研究的关键问题。本文将围绕这三大核心问题，提出一种新的方法，以期解决现有算法的局限性，并提升遥感飞机目标检测的实用性和部署能力。

## 1.3 本文主要研究内容

结合计算机视觉和深度学习的前沿理论，本文针对遥感图像中飞机目标检测与细粒度识别的技术需求，围绕精度提升、模型轻量化及嵌入式部署三个核心问题开展研究，具体内容包括：

（1）针对光学遥感图像中飞机目标检测因复杂背景干扰、小目标密集分布以及飞机外观高度相似导致检测精度不足及细粒度识别能力有限的问题，提出了一种融合全局信息与双域注意力机制的检测算法。首先，为增强模型对全局信息的捕捉能力，设计了一种基于全局最大池化的快速空间金字塔池化模块，通过捕获图像整体结构信息，帮助模型在复杂环境中更好地区分目标与背景。其次，为提升模型对飞机细粒度特征的敏感性，提出了一种双域注意力机制，通过融合空间域与通道域信息，精确定位图像中关键区域和局部细节，显著增强了模型对飞机型号间细微差别的辨识能力，从而兼顾目标检测与细粒度识别任务的需求。此外，针对小目标在特征提取过程中信息易丢失的问题，采用并行路径优化下采样模块，有效保留小目标的空间细节信息，进一步提高了细粒度识别性能。最后，基于PIoU（Powerful-IoU）损失函数的改进，引入自适应惩罚因子，强化了对边界框回归的约束，从而兼顾检测精度与模型收敛速度。通过设计消融实验和对比实验，验证了本文方法在复杂场景下不仅具备更高的检测精度，还在细粒度识别任务中展现了更优异的性能。

（2）为进一步减少改进后目标检测模型的冗余参数并提升部署效率，本文结合GDA-YOLO模型特性与硬件约束，系统地对比了当前主流轻量化技术，最终确定了以结构化剪枝和知识蒸馏为核心的轻量化策略。首先，在对模型进行模块重构并保护检测头关键层的基础上，构建依赖图并通过LAMP评分进行重要性评估，实现了自动化的结构化剪枝，有效避免了通道不匹配和层崩溃问题。随后，针对密集目标检测知识蒸馏过程中存在的跨任务协议不一致性问题，通过结合二元分类蒸馏损失、基于IoU的定位蒸馏损失与GDA-YOLO原始损失函数，优化教师模型向剪枝后的轻量化学生模型的知识迁移，成功实现了分类与定位性能的同步提升。通过剪枝、蒸馏及其协同优化的实验，验证了本文轻量化策略的有效性，成功实现了模型轻量化。

（3）基于Jetson Xavier NX嵌入式平台完成了算法的边缘部署与优化。通过采用低精度数据类型进行推理计算、网络层和张量融合技术减少冗余操作，并将模型从PyTorch格式转换为ONNX格式，再生成TensorRT的Engine格式，成功实现了目标检测算法在Jetson Xavier NX平台的部署。此外，本文还设计并实现了一个用户友好的遥感图像飞机目标检测系统，通过图形用户界面（Graphical User Interface，GUI）提供操作界面，支持实时图像采集、目标检测推理及结果展示，优化了用户体验，为实际应用中的目标检测任务提供了可靠的技术支持与实践经验。

## 1.4 本文结构安排

本文共分为五章，具体结构安排如下：

第一章：绪论。本章主要介绍了研究的背景与意义，阐述遥感图像中飞机目标检测与细粒度识别的研究价值，并分析了当前该领域面临的挑战。接着，梳理了国内外相关研究现状，分别从传统目标检测方法、深度学习目标检测方法以及遥感飞机目标检测方法三个方面进行综述，探讨不同技术的发展脉络及其优缺点，为后续研究提供理论依据。随后，明确了本文的研究目标与主要内容，概述本文围绕检测精度提升、模型轻量化以及嵌入式部署三大核心问题展开的研究工作。最后，简要介绍了论文的章节结构安排，以便读者更清晰地理解本文的研究框架。

第二章：相关理论与技术分析。本章系统地介绍了卷积神经网络的基本结构与特点，包括卷积层、池化层、激活函数和全连接层的功能与作用。接着，本章深入分析了YOLO目标检测算法的原理与结构，以YOLO算法的基本原理为基础，详细介绍了YOLOv8的结构设计，并揭示了各模块如何协同作用以提升检测性能与效率。最后，本章还探讨了目标检测模型的轻量化方法，包括模型剪枝和知识蒸馏技术的原理与应用，为后续章节的研究奠定了理论基础。

第三章：基于GDA-YOLO的飞机目标检测与细粒度识别算法。本章以YOLOv8为基础，分析了该模型在遥感图像飞机目标检测与细粒度识别任务中的不足之处，并提出了一种融合全局信息与双域注意力机制的算法（Global and Dual-domain Attention YOLO，GDA-YOLO）。该算法通过捕获图像整体结构信息，有效减少了背景干扰，并融合了空间域与通道域的信息，显著提升了模型对飞机型号细微差异的辨识能力。通过详细的实验结果和分析，验证了该算法在飞机目标检测与细粒度识别任务中的有效性和优势。

第四章：基于遥感飞机目标检测与细粒度识别算法的轻量化方法研究。本章围绕模型轻量化问题展开研究，重点探讨如何在保持检测精度的同时减少模型的计算开销，以适应嵌入式设备的部署需求。首先，分析了轻量化方案的选择与制定，结合目标检测任务的特点与硬件约束，确定以结构化剪枝和知识蒸馏为核心的轻量化策略。接着，详细介绍了模型剪枝的流程，包括模型预处理、依赖图构建、基于LAMP重要性评估的通道剪枝及剪枝后的微调训练。随后，分析了密集目标检测知识蒸馏任务中的跨任务协议不一致性的问题，通过引入二元分类蒸馏损失和基于IoU的定位蒸馏损失，并结合原始损失函数优化蒸馏策略，以提升剪枝后学生模型的检测精度与鲁棒性。最后，通过实验验证了轻量化策略的有效性，实现模型轻量化的同时保持了良好的检测性能。

第五章：基于嵌入式平台的飞机目标检测算法部署与实现。本章介绍了基于轻量化GDA-YOLO模型的遥感飞机目标检测系统的搭建与部署。首先，对应用系统进行了整体设计，包括硬件平台的选择和软件系统的架构。接着，详细描述了在NVIDIA Jetson Xavier NX嵌入式平台上的开发环境配置和检测算法的部署过程。然后，展示了检测系统的界面设计和功能实现，包括系统开发环境、界面布局和主要功能模块。最后，对本章的工作进行了总结，验证了系统的实用性和高效性。

最后是总结与展望。总结了本文的研究工作和主要贡献，回顾了在遥感图像飞机目标检测与细粒度识别领域所取得的研究成果。针对研究中存在的不足，提出了未来的研究方向，展望了该领域在实际应用中的发展前景和潜力。

# 第二章 相关理论与技术分析

遥感图像处理对高效信息提取提出了迫切需求，深度学习尤其是卷积神经网络为该领域带来了突破。本章将系统介绍卷积神经网络的基本结构与特点，重点分析YOLO目标检测算法的原理与结构，并探讨模型轻量化技术，为后续研究奠定理论基础。

## 2.1 卷积神经网络的结构与特点

卷积神经网络在计算机视觉领域的应用尤为广泛，如图像分类、目标检测和语义分割等任务中均表现出优异的效果，其设计受到了生物视觉系统中感受野机制的启发，能够通过卷积运算从输入数据中自动提取特征。典型的卷积神经网络由输入层、卷积层、池化层、全连接层和输出层构成。卷积层负责提取局部特征，通过权值共享机制降低计算复杂度；池化层用于压缩特征图，既减少了数据维度，又增强了模型的抗干扰能力；全连接层将提取到的特征映射到分类空间，并生成最终的预测结果。这种层次化的结构使CNN能够捕捉数据的多层次表示，从而有效应对复杂的视觉任务。相比传统方法，CNN的特点在于无需手动设计特征提取规则，而是通过端到端的训练自动学习数据中的模式。这种灵活性和高效性使其成为深度学习领域的重要工具，并广泛应用于各类人工智能任务。其基本结构如图2-1所示，本节将逐一介绍卷积神经网络的这些组成成分。

图2-1 卷积神经网络基本结构

### 2.1.1 卷积层

卷积层是卷积神经网络中最核心的组件之一，负责提取输入数据中的特征，通过卷积操作有效捕捉图像的局部模式和结构信息。卷积层的主要运算是通过卷积核（即权值矩阵）在输入图像上滑动，计算其覆盖区域内的像素加权和，从而生成特征映射（Feature Map）。这种机制不仅能够提取图像的边缘、纹理等底层特征，还可以通过堆叠多层卷积逐步提取高层次特征，如形状和复杂物体的局部细节。

卷积层的关键参数包括卷积核的大小（如3×3或5×5）、步长（Stride）以及填充方式（Padding）。步长决定了卷积核每次滑动的步幅，直接影响输出特征图的尺寸；填充用于在输入数据边缘补充像素值，以保持输出特征图的尺寸与原始输入一致。输出特征图的尺寸可以通过以下公式（2-1）计算：

（2-1）

其中，是输出特征图的尺寸，是输入数据的尺寸，是卷积核的大小，是填充大小，是步长。

此外，卷积层采用了局部感受野和权值共享的机制。局部感受野使每个神经元仅关注输入图像的一小部分区域，捕捉局部特征；权值共享则允许同一卷积核在整个输入图像上共享参数，大幅减少了模型的参数量和计算复杂度。通过堆叠多个卷积层，卷积神经网络可以逐层提取低层次到高层次的特征，为分类、检测等任务奠定基础。

图2-2 卷积层计算过程

### 2.1.2 池化层

池化层作为卷积神经网络中的重要组成部分，主要用于降低特征图的空间分辨率，同时提取特征的主要信息以增强模型的鲁棒性。常用的池化操作包括最大池化（Max Pooling）和平均池化（Average Pooling）。最大池化操作通过滑动窗口在特征图上提取窗口内的最大值作为输出。其主要目的在于保留图像中重要的局部特征，如边缘或纹理，这些特征通常表现为局部区域的强烈响应。由于只关注最大值，最大池化能够有效滤除图像中的噪声和次要信息，使模型更集中于具有显著特征的区域。平均池化则在窗口内计算所有像素的均值，并将该平均值作为输出。平均池化适合保留图像中的整体信息，例如背景、模糊区域等，这些特征通常是图像的整体结构。由于窗口内所有像素的均值都会被考虑，平均池化能够有效保留模糊和背景区域的细节。图2-3为最大池化和平均池化计算过程。

图2-3 最大池化和平均池化计算过程

### 2.1.3 激活函数

卷积运算本质上是线性求和的过程，即使再多的卷积层叠加，最后输出的还是输入的线性组合，并不能解决复杂的问题。激活函数是卷积神经网络中引入非线性变换的关键组件,通过对输入进行非线性变换，产生非线性的神经响应，使其可以学习和表示复杂的非线性模式。常用的激活函数包括Sigmoid、Softmax、ReLU和SiLU等，每种激活函数在特性和适用场景上各有不同。

Sigmoid函数是最早被广泛应用的激活函数之一，将输入值映射到(0,1)的范围内，其数学表达式和曲线图如公式（2-2）、图2-4所示：

（2-2）

图2-4 Sigmoid激活函数

从图中可以看出，Sigmoid函数连续且单调递增，具有良好的平滑性和可微性，因此常用于二分类任务中。由于其输出值恒为正数，Sigmoid函数对梯度的更新方向具有一致性。然而，当输入值处于极大或极小时，函数的梯度趋于零，可能导致梯度消失问题。此外，Sigmoid函数的输出不以零为中心，这可能引发梯度更新的不平衡，从而减慢网络的训练速度。

Softmax函数常用于多分类任务的输出层。它能够将网络的输出转换为一组概率值，表示每个类别的预测概率，且这些概率之和为1。Softmax的数学表达式和曲线图如公式（2-3）、图2-5所示：

（2-3）

图2-5 Softmax激活函数

其中，表示第个类别的输入，K是类别总数，是对输入进行指数运算后的结果，而分母是所有类别输入指数的和，确保输出是一个概率分布。Softmax函数使得每个类别的预测值变为一个概率值，方便后续的决策。Softmax与Sigmoid不同，Sigmoid主要用于二分类任务，而Softmax适用于多分类问题，可以同时处理多个类别的预测。

ReLU（Rectified Linear Unit）是分段线性函数，其数学表达式和曲线图如公式（2-4）、图2-6所示：

（2-4）

图2-6 ReLU激活函数

ReLU函数通过对负值直接输出零，对正值保持线性，使得计算简单且高效。与Sigmoid函数相比，ReLU能够有效缓解梯度消失问题，从而在深层网络中表现出优异的性能。然而，ReLU函数的缺陷在于，当神经元的输入长期为负值时，其梯度会变为零，从而导致神经元死亡现象，这可能限制网络的表达能力。

SiLU（Sigmoid Linear Unit），也称Swish函数，是一种结合了Sigmoid和ReLU特性的激活函数，其数学表达式和曲线图如公式（2-5）、图2-7所示：

（2-5）

图2-7 SiLU激活函数

SiLU是一种非单调的激活函数，能够根据输入值的不同动态调整输出，从而增强模型的表达能力。与ReLU类似，SiLU在正值区域表现为线性，但在负值区域的输出逐渐趋近于零，而非完全为零。这种特性有助于梯度流动，从而提高网络的优化效率。然而，与ReLU相比，SiLU的计算复杂度较高，这可能对某些实时性要求较高的任务带来挑战。

### 2.1.4 全连接层

全连接层（Fully Connected Layer，FC）是卷积神经网络中将特征向量映射到输出空间的重要模块，其作用是对前几层提取到的高层次特征进行综合，生成任务所需的最终结果。在全连接层中，每个神经元都与上一层的所有神经元相连，构成了一个密集连接的神经网络结构。这种连接方式可以捕捉特征之间的全局关联，使得模型具备强大的表达能力，能够对特征进行更高层次的非线性组合。全连接层的输出通常通过激活函数映射到分类概率分布或回归值，从而完成任务目标。数学上，全连接层的计算可以表示为公式（2-6）：

（2-6）

其中，是权重矩阵，是输入向量，是偏置向量，是非线性激活函数。通过对权重和偏置的训练，全连接层能够学习到输入特征与目标输出之间的复杂映射关系。

然而，由于全连接层密集的连接方式，其参数量通常较大，这容易导致模型的过拟合问题，特别是在数据不足的情况下。为此，常常引入正则化技术（如L2正则化<sup>\[</sup>[<sup>55</sup>](#_ENREF_55)<sup>\]</sup>）或使用Dropout<sup>\[</sup>[<sup>56</sup>](#_ENREF_56)<sup>\]</sup>等机制，通过随机丢弃部分神经元的连接来缓解过拟合。此外，由于全连接层的计算复杂度较高，通常位于网络的末端，仅处理卷积层和池化层已经提取好的低维特征，以减少计算开销。

全连接层在卷积神经网络中的作用不可或缺，其将卷积和池化层提取的多层次特征整合为语义表达，为分类、检测或其他任务提供了决策依据。随着深度学习的发展，部分轻量化模型中使用全局平均池化等技术替代传统的全连接层，从而进一步降低参数量和计算复杂度，但在许多需要高精度的任务中，全连接层依然占据重要地位。图2-8为全连接网络结构示意图。

图2-8 全连接层网络结构示意图

## 2.2 YOLO目标检测算法原理和结构

YOLO系列算法作为目标检测领域的经典方法，以其高效的检测性能和快速的处理速度受到广泛关注。YOLOv8作为该系列的重要版本，在继承前代算法优势的基础上，进一步优化了网络结构和检测机制，在检测速度和精度上均取得了显著提升。因此，本研究选择基于YOLOv8算法进行研究，以实现遥感图像中飞机目标的高效检测与识别。接下来，本文将详细介绍YOLO算法的基本原理以及YOLOv8的结构特点，为后续研究提供理论基础。

### 2.2.1 YOLO算法基本原理

YOLO算法是当前目标检测领域中最为流行和高效的实时目标检测方法之一，其核心思想在于将目标检测问题转化为回归问题，通过CNN直接预测目标的类别和边界框，而不需要像R-CNN那样使用选择性搜索生成候选框。YOLO算法首次提出时便突破了传统检测框架的复杂性，采用端到端的训练方式，大大提升了检测速度，并逐步成为实时目标检测任务中的重要选择。

YOLOv1算法流程图如图2-9所示，该算法将输入图像划分为S×S的网格，每个网格单元负责预测B个边界框（Bounding Boxes），并输出每个边界框的置信度（Confidence Score）、目标的类别概率以及相应的位置参数。具体来说，每个网格会预测边界框的中心位置、宽度和高度相对于网格的位置，并且还会预测该框是否包含目标的置信度。此外，YOLO还对每个网格单元预测C个类别的概率，并使用独热编码（One-Hot Encoding）方式表示最终的目标类别。最终，算法通过NMS剔除冗余边界框，仅保留最具置信度的边界框，从而确保检测结果的精确性。

与传统目标检测方法相比，YOLO的主要优势在于其检测速度和计算效率。由于YOLO不依赖于候选框生成，它能够通过单一网络直接预测目标的位置和类别，从而极大地加速了检测过程。因此，YOLO算法在实时目标检测场景中具有显著的优势。尽管早期版本的YOLO在小目标检测精度上有所不足，但随着后续版本的改进，YOLO系列在精度与效率之间达到了更加优化的平衡，逐步成为现代目标检测任务中的重要技术之一。

图2-9 YOLOv1算法流程图（图片中的文字改成中文）

### 2.2.2 YOLOv8算法结构

YOLOv8继承了YOLO系列的一贯高效设计，是当前先进的目标检测算法之一，YOLOv8的整体模型结构由Backbone、Neck、Head三个部分组成，图2-10为YOLOv8整体结构图。

图2-10 YOLOv8整体结构图（这个图太大了，而且应该内容能中文就中文的，下同）

（1）Backbone

Backbone是YOLOv8的特征提取网络，负责提取输入图像的基础特征，是整个模型的核心部分，其主要结构有CBS模块、C2f模块和快速空间金字塔模块（Spatial Pyramid Pooling – Fast，SPPF）组成。

CBS模块是YOLOv8的基础构建单元，图2-11为CBS模块结构图，CBS模块结合了卷积层、批归一化层（Batch Normalization，BN）和SiLU激活函数。卷积层负责提取特征，捕捉图像中的边缘和纹理等局部信息；批归一化层通过归一化处理减少内部协变量偏移，加快模型收敛；而SiLU激活函数则兼具Sigmoid的平滑性和ReLU的稀疏性，有效提升了非线性表达能力。CBS模块在特征提取过程中高效集成了这些功能，是整个网络性能的基础保障。

图2-11 CBS模块结构

C2f模块是对传统CSP（Cross-Stage Partial）模块的优化设计，进一步提升了网络的性能并降低计算开销。图2-12为C2f模块结构图。C2f模块的关键思想是将输入特征图分为两部分，其中一部分直接通过网络进行处理，而另一部分则经过一定的卷积变换后，与前者的输出进行融合与拼接。这种分流与融合的设计使得网络能够有效地利用不同层次的特征信息，同时减少冗余计算。

图2-12 C2f模块结构图

在C2f中，Bottleneck结构作为其核心组件之一，发挥了重要作用，Bottleneck结构图如图2-13所示。Bottleneck首先通过一个1×1卷积层减少特征图的通道数，从而降低计算复杂度。接着，使用一个3×3卷积层提取更深层次的特征，并扩展感受野。为了缓解梯度消失问题，网络引入了跳跃连接，将输入直接与输出相加。最后，输出通过跳跃连接与卷积层输出拼接，形成最终的特征图。

图2-13 Bottleneck结构图

SPPF是一种高效的空间金字塔池化模块，能够提取全局上下文信息。SPPF通过多尺度的池化操作生成多种尺度的特征表示，并将其拼接为统一尺寸的输出特征图。相较于传统的SPP模块，SPPF通过优化设计显著减少了计算复杂度，同时增强了网络的全局感知能力。在YOLOv8中，SPPF常用于Backbone的最后阶段，以最大化全局特征的表达效果。

图2-14 SPPF模块结构图

总体而言，CBS提供了强大的特征提取能力，C2f优化了特征融合效率，而SPPF则通过全局信息强化模型感知。这些模块的协同作用，使得YOLOv8在性能和效率之间达到了更优的平衡，为目标检测任务提供了卓越的解决方案。

（3）Neck

Neck的主要任务是对多尺度特征进行融合，增强模型对不同尺寸目标的感知能力。在YOLOv8中，Neck采用了FPN和路径聚合网络（Path Aggregation Network，PAN）<sup>\[</sup>[<sup>57</sup>](#_ENREF_57)<sup>\]</sup>的组合结构，旨在更好地捕捉和融合来自Backbone的多尺度特征图。具体而言，FPN提供了上采样和下采样操作，通过逐层融合来整合不同尺度的特征，同时保留图像的高分辨率细节。这种结构使得特征图中的语义信息能够在不同层次间流动和共享，从而增强了目标检测模型对复杂场景中的多尺度目标的感知能力。同时，PAN模块进一步优化了FPN结构。PAN通过引入跳跃连接机制，将高层特征图中的语义信息引导到低层特征图，使低层特征能够保留边缘和边界细节，而高层特征则更好地提取目标的语义信息和全局结构。这样，Neck模块不仅保留了多尺度特征的丰富性，还增强了语义信息的传播和融合，使得模型能更有效地处理复杂背景和小目标，显著提升了目标检测的准确性和鲁棒性。

（4）Head

从YOLO系列的早期版本到YOLOv5<sup>\[</sup>[<sup>25</sup>](#_ENREF_25)<sup>\]</sup>，其检测头始终采用“耦合”（Coupled）设计，即通过一层卷积同时完成分类和定位任务。这种设计具有结构简单、计算效率高的优点，但由于分类任务和定位任务的优化目标存在一定差异，耦合结构可能导致二者之间相互干扰，从而影响检测精度。直到YOLOX<sup>\[</sup>[<sup>58</sup>](#_ENREF_58)<sup>\]</sup>的问世，YOLO系列首次引入了“解耦头”（Decoupled Head）的设计方案。该方案针对分类和定位任务分别构建独立的分支，通过两条并行路径分别提取类别特征和位置特征，并各自独立优化分类损失和定位损失，有效避免了任务间的冲突。图2-15为YOLOv8检测头结构图，YOLOv8同样采用了解耦头结构，通过将输入特征图分为两条并行路径，分别专注于分类特征提取和定位特征提取。随后，利用一层1×1卷积对特征进行细化处理，分别完成分类和定位任务。这样的设计显著提升了分类与定位任务的独立性和特征表达的准确性，从而使模型在多目标场景中的表现更加优异。通过引入解耦头，YOLOv8克服了耦合头在任务优化中存在的瓶颈问题，在保持高效计算的同时，进一步提升了分类精度和定位准确性，为目标检测任务提供了更强大的性能支持。

图2-15 YOLOv8检测头结构图

YOLOv8的损失函数设计相对简洁且高效，主要包括分类损失和回归损失两大部分，同时取消了YOLOv5中的目标置信度分支。在分类损失方面，YOLOv8采用了二元交叉熵损失（Binary Cross-Entropy Loss，BCE Loss），这是一种常用的二分类损失函数，适用于多标签分类问题。通过对每个类别的预测概率与真实标签进行交叉熵计算，BCE Loss能够有效衡量分类的准确性。在回归损失方面，YOLOv8结合了Distribution Focal Loss（DFL）和Complete Intersection over Union Loss（CIoU）<sup>\[</sup>[<sup>59</sup>](#_ENREF_59)<sup>\]</sup>的优势。DFL是一种针对边界框回归的新型损失函数，其创新之处在于不直接预测固定值，而是预测一个概率分布，并通过Softmax函数进行离散化处理。这种方法对边界模糊问题表现尤为出色，有助于提升检测精度。CIoU则是一种改进的IoU损失函数，综合考虑了边界框的中心点距离、宽高比以及尺度信息，从多个维度衡量边界框的回归质量。通过DFL和CIoU的组合，YOLOv8在分类和回归两项任务上均实现了良好的性能表现，为目标检测任务提供了更加全面的支持。

## 2.3 目标检测模型轻量化方法

随着深度学习在实际应用中的广泛部署，模型的计算开销与参数量逐渐成为瓶颈，尤其在资源受限的设备上，如何在保证模型性能的前提下实现网络的高效运行成为研究的热点。模型轻量化技术通过对网络结构和参数进行优化，显著减少模型的存储需求和推理时间。常见的轻量化方法包括剪枝、量化、知识蒸馏和低秩分解等，其中剪枝和知识蒸馏是两种应用广泛且高效的轻量化技术。接下来，将详细介绍剪枝与知识蒸馏的原理及应用。

### 2.3.1 模型剪枝

模型剪枝是一种常用的网络轻量化方法，旨在去除深度神经网络中冗余的权重或结构单元，从而减小模型的参数量和计算复杂度，提升模型的推理速度。在深度学习模型逐渐趋于大规模、复杂化的背景下，剪枝技术能够有效缓解模型在存储、传输和部署方面的挑战，尤其在资源受限的环境中展现出显著优势。

模型剪枝主要分为非结构化剪枝和结构化剪枝两类。非结构化剪枝的核心思想是根据权重的重要性将网络中较小的权重置零，形成稀疏网络，从而减少模型的参数量。这种方法侧重于微观层面的权重精简，虽然能显著减少参数数量，但由于剪枝后权重分布的不规则性，难以充分利用硬件加速。在实际应用中，非结构化剪枝通常需要与稀疏矩阵优化技术结合，以提高运行效率。与非结构化剪枝不同，结构化剪枝则侧重于宏观层面的网络结构优化，主要通过删除整个神经元、通道或卷积核来实现模型轻量化。这种方法保持了网络的整体结构规则性，使得剪枝后的模型更易于在现有硬件上进行高效推理。尤其在卷积神经网络中，结构化剪枝通过移除冗余通道或卷积核，能够显著减小网络规模和计算量，同时保持模型的原有拓扑结构。

图2-16 非结构化剪枝和结构化剪枝示意图

模型剪枝在实际应用中具有多重优势。一方面，剪枝后的模型参数量显著减少，从而降低存储和传输的成本。另一方面，剪枝通过优化网络结构，减少了推理过程中所需的计算量，提升了模型的执行效率。此外，剪枝还能够在一定程度上提高模型的泛化性能，减少过拟合风险。整体而言，剪枝技术为深度学习模型在资源受限场景下的高效部署提供了重要支撑。

### 2.3.2 知识蒸馏

知识蒸馏是一种通过将大型复杂的教师模型的知识转移到小型简单的学生模型中的方法，旨在降低模型的参数量和计算复杂度，同时尽可能保持原有模型的性能。知识蒸馏的核心思想是利用教师模型对输入数据产生的软目标（Soft Targets）概率分布作为监督信号，指导学生模型进行学习。这种软目标包含了类别之间的置信度信息，能够为学生模型提供更加平滑且信息丰富的监督，帮助学生模型学习更具泛化能力的特征表示和决策边界。教师模型传递给学生模型的知识不仅包括最终输出结果，还可能包含中间层的特征信息，从而实现知识的全面蒸馏。

知识蒸馏根据传递知识的形式可分为两类：基于特征的知识蒸馏和基于逻辑的知识蒸馏。图2-17分别展示了基于特征和基于逻辑的知识蒸馏原理图。基于特征的方法通过匹配教师和学生模型中间层的特征表示来传递细粒度知识，但这种方法通常要求两者结构相似，且在特征对齐上会增加额外的计算开销。相比之下，基于逻辑的知识蒸馏侧重于让学生直接模仿教师模型的最终输出概率分布，通过温度参数对软目标进行平滑处理，使学生模型能够更充分地捕捉类别间的细微差异。由于不依赖中间层特征对齐，逻辑蒸馏方法实现简单、计算成本低，且更具灵活性和推广性，因此在实际应用中往往表现得更为高效。

（a）基于特征的知识蒸馏 （b）基于逻辑的知识蒸馏

图2-17 知识蒸馏原理图

## 2.4 本章小结

本章系统地介绍了卷积神经网络及其在目标检测中的应用，首先阐述了卷积层、池化层、激活函数、全连接层等关键组成部分的功能与作用，分析了每一层如何通过特征提取、降维和非线性变换等操作增强网络对复杂图像模式的学习能力。接着，本章深入分析了YOLO目标检测算法的原理与结构，以YOLO算法的基本原理为基础，详细介绍了YOLOv8的结构设计，重点探讨了其Backbone、Neck和Head模块的设计思想，并揭示了各模块如何协同作用以提升检测性能与效率。最后，考虑到目标检测模型在实际应用中面临的计算开销和参数量问题，尤其是在资源受限的设备上，本章探讨了模型轻量化技术，重点介绍了模型剪枝和知识蒸馏两种方法，分析了它们如何在减小模型规模的同时提升推理速度并减少计算复杂度。本章节为后续的算法改进与应用研究奠定了坚实的理论基础，为构建高效、精确的目标检测系统提供了重要的理论支持。

# 第三章 基于GDA-YOLO的飞机目标检测与细粒度识别算法

尽管YOLOv8在通用目标检测领域展现了卓越的性能，但在光学遥感图像中的飞机目标检测任务上，仍面临诸多挑战。这些挑战主要体现在小目标检测精度不足、相似外观飞机的区分困难以及复杂背景下的检测鲁棒性较差等方面。针对这些问题，本章节提出了一种创新的GDA-YOLO算法，通过融合全局信息和双域注意力机制，优化YOLOv8n模型，显著提升了模型对目标细节与全局背景的感知能力。

接下来，本章将详细介绍GDA-YOLO算法的整体框架，阐明其核心设计思想和关键目标。随后，将对各个模块的具体实现进行详细说明，并通过精心设计的消融实验与对比实验，验证方案的有效性与先进性。

## 3.1 模型整体框架

YOLOv8提供了n/s/m/l/x五个版本，为了更好地满足光学遥感图像飞机目标检测任务对计算资源、快速响应和轻量级部署的需求，本文基于体积最小的YOLOv8n模型进行了改进，提出了GDA-YOLO。图3-1为GDA-YOLO整体结构图。

图3-1 GDA-YOLO整体结构图

首先，设计了基于全局信息的快速空间金字塔池化模块（SPPF_Global），增强了模型对全局信息的捕捉能力，减少了复杂背景对检测效果的干扰；其次，在Backbone与Neck之间加入了双域注意力机制（Dual-Domain Attention，DDA），提升了模型对图像中细微特征的感知能力，帮助模型更好地理解图像中的重要区域；然后，引入了并行下采样模块（Parallel Downsampling，PDS）<sup>\[</sup>[<sup>27</sup>](#_ENREF_27)<sup>\]</sup>，以保留小目标的细节信息；最后，通过PIoU损失函数加速了模型的收敛速度并提高了检测精度。

## 3.2 网络结构设计与优化

### 3.2.1 基于全局信息的快速空间金字塔池化模块

在YOLOv8中，SPPF模块通过多次池化操作提取不同尺度的特征，从而有效增强了模型在多尺度目标上的感知能力。具体来说，SPPF通过在特征图上应用连续三次的5×5最大池化操作，并将池化前后的结果拼接在一起，最终将不同尺度的特征融合成一个固定大小的特征向量。这种方式使得模型能够从多个尺度上提取信息，特别适用于处理含有不同大小目标的图像，尤其是在目标检测任务中，目标的尺寸差异可能很大，SPPF模块因此能有效提升检测性能。

尽管SPPF模块能够在一定程度上提升模型的多尺度特征提取能力，但其仍然存在一定局限性。首先，SPPF采用的是固定的池化窗口大小（例如5×5），这意味着其对不同尺寸输入的适应性较差。尤其在遥感图像中，飞机目标的尺度差异较大，固定大小的池化窗口可能无法充分适应大尺寸目标或小尺寸目标的特征提取需求。其次，SPPF主要侧重于局部区域的特征提取，而对整个图像的全局信息的感知相对较弱。在背景复杂且目标与背景具有相似特征的场景中，SPPF模块可能无法充分利用全局上下文信息，导致背景与目标之间的区分较为困难，进而影响检测精度。

为了解决这一问题并增强模型的全局信息捕获能力，减少复杂背景对检测结果的影响，本文在原始SPPF模块中引入了全局最大池化层，提出了基于全局信息的快速空间金字塔池化模块（SPPF_Global），该模块的结构如图3-2所示。通过将两个自适应最大池化层（AdaptiveMaxPool2d）的输出大小设置为(1,1)，使得池化窗口的大小与输入特征图的大小相匹配，从而实现对整个特征图的全局最大池化操作。无论输入图像的大小如何，SPPF_Global模块都能够捕获整个图像的全局特征。通过综合考虑背景信息，它能够在整个图像中寻找最显著的特征，这些特征通常与飞机目标的关键部位相关联，有助于减少背景干扰对飞机目标检测的影响，从而显著提高了检测的准确性和鲁棒性。

图3-2 SPPF_Global模块结构

### 3.2.2 双域注意力机制

在深度学习中，注意力机制作为一种模仿人类视觉聚焦机制的技术，已广泛应用于各种视觉任务。注意力机制的核心思想是使模型能够根据输入的不同部分的重要性，自适应地调整其注意力分配，从而提升模型对关键特征的学习能力。在目标检测、图像分类、分割等任务中，注意力机制通过强调图像中具有重要信息的区域或特征，显著提高了模型的表现。

由于各类飞机的整体特征高度相似，不同飞机型号的区别主要体现在局部细节的不同，而模型难以区分这些细小差距，导致飞机型号误检率高。因此，为了提高模型对不同型号飞机的检测精度，增强模型捕获和利用图像中重要的细节特征信息的能力，本文提出了一种双域注意力机制（Dual-Domain Attention，DDA），DDA融合了高效通道注意力（Efficient Channel Attention，ECA）<sup>\[</sup>[<sup>60</sup>](#_ENREF_60)<sup>\]</sup>和空间注意力（Spatial Attention，SA）<sup>\[</sup>[<sup>61</sup>](#_ENREF_61)<sup>\]</sup>，通过空间域与通道域的信息引导，帮助模型关注图像中的重要区域，增强不同通道特征之间的关联性，从而提高模型对不同机型的检测精度。DDA模块的示意图如图3-3所示。

图3-3 DDA模块结构示意图

首先输入特征图会经过全局平均池化（Global Average Pooling，GAP），将特征图从大小为W×H×C的矩阵变成大小为1×1×C的向量。然后，通过一维卷积操作得到每个通道的权重，完成跨通道间的信息交互。一维卷积的卷积核大小由一个自适应函数来控制，的公式如下：

（3-1）

其中，表示取距离最近的奇数，式中的和用于改变通道数与卷积核大小的比例，本文参考文献\[60\]将其分别设置为2和1，取值会根据通道数改变，能够充分融合部分通道间的交互。最后，通过Sigmoid激活函数得到归一化后的权重，将原始特征图与权重通过逐点元素相乘，得到具有通道维度上加权特征的输出并传递给SA模块。

SA模块会将此时的特征图沿着通道维度分别进行求均值和求最大值的操作，得到两个特征图。然后将这两个特征图连接起来，通过卷积操作及Sigmoid激活函数得到注意力权重。最后，将权重应用于原始输入特征图上，得到加权后的特征图作为模型的输出。

通过DDA模块，模型能够同时关注到图像中的通道特征和空间位置，帮助模型更全面地理解图像，捕获并利用图像中重要的细节特征信息。这种细粒度的特征学习和关注机制，有助于模型在处理飞机目标检测时，精确区分不同飞机型号之间的细微差异，从而提高细粒度识别的精度和模型的整体检测能力。

### 3.2.3 下采样方式的改进

在计算机视觉任务中，下采样是指通过降低输入数据的空间维度来减少数据量。下采样操作会使特征图的空间尺寸减小，但却能增大每个神经元的感受野，这有助于模型捕捉更广泛的上下文信息，提取图像的重要特征，帮助模型更好地理解图像内容。然而，光学遥感图像中的飞机目标的尺寸普遍较小，在YOLOv8模型中仅单独采用步幅为2的卷积层进行下采样，这个过程中模型会偏向于学习图像中的大型目标，导致小目标的细节信息丢失，降低了模型对小目标的识别能力。

为了解决这个问题，本文采用了并行下采样模块（PDS），通过两个并行的路径，同时使用最大池化和卷积操作实现下采样。为了在提取丰富特征和高效融合之间取得平衡，在Backbone和Neck阶段设置不同的通道数，图3-4为PDS结构图，展示了PDS在Backbone和Neck的结构及维度变化情况，其中B表示批次大小，C表示通道数，H表示高度，W表示宽度。

（a）Backbone中的PDS模块 （b）Neck中的PDS模块

图3-4 PDS模块结构

首先，左边的分支采用最大池化操作，通过将输入特征图的空间尺寸减半来减小特征图的大小。随后，在Neck部分，通过一个1×1的卷积操作，进一步减少通道数以降低计算量，提高计算效率。在Backbone部分则通道数保持不变，使得模型能够更好地保留输入特征中的信息。右边的分支首先通过1×1卷积操作压缩通道，再使用步幅为2的3×3卷积操作减小特征图的尺寸，并且调整通道数以匹配左侧分支的输出通道数。最后，将左右两个分支的结果进行合并，完成下采样操作。

这样的下采样方式兼顾了最大池化和卷积操作，能够在不同尺度上提取特征，有助于保留小目标的细节信息。同时，并行策略可以更充分地捕捉特征信息，弥补了YOLOv8中下采样操作在光学遥感目标检测任务中存在的缺陷，提高模型对小目标的识别能力和检测精度。此外，由于最大池化操作不需要额外的参数，并且PDS模块中的第一个卷积操作能够将输入特征图的通道数减半，降低了模型的参数量和运算量。因此，PDS模块不仅能够提高模型的性能，还能够有效地减少模型的参数量和运算量，使得模型更加轻量化。

### 3.2.4 损失函数改进

在目标检测中，一个高效的损失函数对于实现良好的定位性能至关重要。许多学者基于IoU的损失函数做了大量改进工作，这些改进工作都是围绕惩罚项进行的。在YOLOv8中采用了CIoU作为损失函数，其表达公式如下：

（3-2）

其中，是预测框中心点和真实框中心点之间的距离，是预测框和真实框的最小外部框的对角线长度，是权重系数，用来衡量长宽比的一致性，和的表达公式如下：

（3-3）

（3-4）

其中，和分别表示真实框的宽和高，和表示预测框的宽和高。当预测框与真实框不重叠时，单纯增大预测框的尺寸会降低，导致回归过程中预测框的扩大，从而影响收敛速度。此外，虽然CIoU能够反映中心点距离和纵横比差异，但是没有直接捕捉预测框与真实框之间的形状差异，也不能反映真实框大小的变化。而光学遥感图像中的飞机目标具有多样的形状和尺寸，并且会受到观测角度和距离的影响，这使得CIoU损失函数未能有效地适应飞机目标检测任务的需求。

因此，本文引入一种具有尺寸自适应性惩罚因子的边界框回归损失函数PIoU（Powerful-IoU）<sup>\[</sup>[<sup>62</sup>](#_ENREF_62)<sup>\]</sup>，帮助预测框更加直接有效地回归。PIoU的表达公式如下：

（3-5）

其中，表示惩罚因子，的表达公式如下：

（3-6）

其中，、、、是预测框与真实框对应边的距离绝对值，和是真实框的宽和高。CIoU和PIoU表达公式中所涉及的参数如图3-5所示。

图3-5 CIoU、PIoU参数示意图

由于值与预测框和真实框的最小外接框的大小无关，因此扩大预测框不会改变值，这有效解决了预测框放大问题，加快了收敛速度。此外，PIoU的惩罚函数，即，可以根据预测框的质量自适应地调整梯度幅度，当惩罚因子较大（>2）时，表示预测框和真实框之间存在较大差异，取较小的值，从而抑制了来自低质量锚框的有害梯度。当接近1时，表示预测框接近真实框，较大的会加快回归速度。随着预测框质量的提升而逐渐减小，直至稳定地优化到与真实框完全对齐，给飞机目标检测带来更快的收敛速度和更高的检测精度。

## 3.3 实验结果与分析

### 3.3.1 实验设备和数据集

本文实验的硬件环境配置如下：操作系统为Ubuntu 20.04.5 LTS，CPU为AMD EPYC 9754 128-Core，GPU为NVIDIA GeForce RTX 3090，显存容量为24GB。本文方法基于Python 3.8.18和Pytorch 1.13.1深度学习框架实现。模型训练总迭代轮数为300轮，初始学习率设定为0.01，使用随机梯度下降SGD优化器，学习动量为0.937。输入训练样本大小设置为640×640。

数据集采用MAR20数据集<sup>\[</sup>[<sup>63</sup>](#_ENREF_63)<sup>\]</sup>和NWPU VHR-10数据集<sup>\[</sup>[<sup>64</sup>](#_ENREF_64)<sup>\]</sup>。其中，MAR20数据集是当前公开规模最大的用于军用飞机目标识别的光学遥感图像数据集之一。数据来自于Google Earth，包含3842张图像，涵盖了20种不同型号的军用飞机，编号为A1到A20。这些图像大多尺寸为800×800像素。由于数据集中的20个细粒度类别都属于同一个飞机大类，不同型号的飞机具有相似的外观特征，因此类间相似性较高。数据集按照不同机场包含的各飞机型号的目标数量划分为训练集和验证集。其中，训练集包括1331张图像和7870个目标实例，验证集包含2511张图像和14471个目标实例。NWPU VHR-10数据集包含800张光学遥感图像，其中650张为有目标图像，150张为背景图像，共3651个实例。数据集的类别为飞机、船、储罐、棒球场、网球场、篮球场、田径场、港口、桥和车辆共10个类别。数据集按照6:2:2的比例随机划分为训练集、验证集和测试集。

### 3.3.2 公共评价指标

为验证本文算法性能，采用精确率（Precision，P）、召回率（Recall，R）、平均精度均值（Mean Average Precision，mAP）、参数量（Parameters）、浮点运算次数（Floating-point Operations Per Second，FLOPs）、在GPU条件下每张图的推理时间（Latency）作为评价指标。上述指标的计算表达式分别为：

（3-7）

（3-8）

（3-9）

其中，TP、FP和FN分别表示正确检测到目标框、误检框和漏检框的数量；AP表示平均精度，mAP是对所有类别的AP求平均值所得，mAP50和mAP50-95分别表示不同IoU阈值下的平均精度均值；n表示检测的类别数。

### 3.3.3 不同空间金字塔池化模块的实验与结果分析

为了验证本文提出的SPPF_Global模块在光学遥感图像飞机目标检测任务上的有效性，本文在MAR20数据集上基于YOLOv8n模型对比了SPPF_Global模块与其他主流空间金字塔池化模块（SPP<sup>\[</sup>[<sup>65</sup>](#_ENREF_65)<sup>\]</sup>、SPPF<sup>\[</sup>[<sup>28</sup>](#_ENREF_28)<sup>\]</sup>、ASPP<sup>\[</sup>[<sup>66</sup>](#_ENREF_66)<sup>\]</sup>、RFB<sup>\[</sup>[<sup>67</sup>](#_ENREF_67)<sup>\]</sup>、SPPCSPC<sup>\[</sup>[<sup>27</sup>](#_ENREF_27)<sup>\]</sup>和SimCSPSPPF<sup>\[</sup>[<sup>26</sup>](#_ENREF_26)<sup>\]</sup>）对模型大小和精度的影响。实验结果如表3-1所示。

表3-1 不同空间金字塔池化模块的性能对比

|     |     |     |     |     |     |     |     |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Module | Precision | Recall | mAP50 | mAP50-95 | Parameters<br><br>(M) | FLOPs<br><br>(B) | Latency<br><br>(ms) |
| SPP | 78.3% | 77.2% | 83.2% | 62.2% | 3.01 | 8.1 | 0.89 |
| SPPF | 81.0% | 78.7% | 84.6% | 63.2% | 3.01 | 8.1 | 0.88 |
| ASPP | 81.5% | 77.4% | 84.5% | 63.2% | 3.83 | 8.7 | 0.91 |
| RFB | 81.1% | 77.0% | 84.0% | 62.8% | 3.18 | 8.2 | 0.89 |
| SPPCSPC | 81.3% | 78.1% | 84.2% | 63.1% | 4.62 | 9.4 | 0.97 |
| SimCSPSPPF | 81.0% | 78.1% | 84.9% | 63.4% | 3.36 | 8.4 | 0.90 |
| SPPF_Global | 82.2% | 78.5% | 85.6% | 64.0% | 3.06 | 8.0 | 0.88 |

从表中实验结果可以看出，不同空间金字塔池化模块在模型性能上存在一定差异。其中，SPPF_Global模块在精确率、召回率、mAP50和mAP50-95指标上均表现优异。相比于原始模型使用的SPPF模块，SPPF_Global模块在mAP50上提升了1%，在mAP50-95上提升了0.8%，有效提高了模型的检测精度。此外，SPPF_Global模块在参数量和计算量方面与SPPF模块相近，保持了较低的资源消耗水平。而推理速度也与SPPF模块相当，保持在0.88ms。这表明SPPF_Global模块在保持资源消耗较低的同时，成功提升了模型的检测性能。对比其他主流空间金字塔池化模块，SPPF_Global模块表现出更高的性能和更低的资源消耗。这些结果表明了SPPF_Global模块的有效性，它在保持了模型速度的同时，提升了检测的准确性，为光学遥感图像飞机目标检测任务提供了一个有效的选择。

### 3.3.4 不同注意力机制的实验与结果分析

为了评估DDA模块对模型大小和精度方面的影响，在MAR20数据集上进行了实验，与其他注意力机制CBAM（Convolutional Block Attention Module）<sup>\[</sup>[<sup>68</sup>](#_ENREF_68)<sup>\]</sup>、CA（Coordinate Attention）<sup>\[</sup>[<sup>69</sup>](#_ENREF_69)<sup>\]</sup>、CPCA（Channel prior convolutional attention）<sup>\[</sup>[<sup>70</sup>](#_ENREF_70)<sup>\]</sup>、DLKA（Deformable Large Kernel Attention）<sup>\[</sup>[<sup>71</sup>](#_ENREF_71)<sup>\]</sup>、EMA（Efficient Multi-Scale Attention）<sup>\[</sup>[<sup>72</sup>](#_ENREF_72)<sup>\]</sup>、LSKA（Large Separable Kernel Attention）<sup>\[</sup>[<sup>73</sup>](#_ENREF_73)<sup>\]</sup>、SA（Shuffle Attention）<sup>\[</sup>[<sup>74</sup>](#_ENREF_74)<sup>\]</sup>、SimAM（A Simple, Parameter-Free Attention Module）<sup>\[</sup>[<sup>75</sup>](#_ENREF_75)<sup>\]</sup>、TA（Triplet Attention）<sup>\[</sup>[<sup>76</sup>](#_ENREF_76)<sup>\]</sup>共9种进行了性能对比，表3-2为不同注意力机制的性能对比结果。

表3-2 不同注意力机制的性能对比

|     |     |     |     |     |     |     |     |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Model | Precision | Recall | mAP50 | mAP50-95 | Parameters<br><br>(M) | FLOPs<br><br>(B) | Latency<br><br>(ms) |
| YOLOv8n | 81.0% | 78.7% | 84.6% | 63.2% | 3.01 | 8.1 | 0.88 |
| +CBAM | 80.7% | 79.0% | 84.6% | 63.1% | 3.08 | 8.2 | 0.89 |
| +CA | 81.0% | 78.4% | 84.8% | 63.6% | 3.02 | 8.1 | 0.95 |
| +CPCA | 81.5% | 78.8% | 85.0% | 63.6% | 3.14 | 8.3 | 1.21 |
| +DLKA | 82.4% | 78.9% | 86.0% | 64.2% | 4.64 | 9.4 | 0.90 |
| +EMA | 81.9% | 76.5% | 84.6% | 63.3% | 3.02 | 8.2 | 0.90 |
| +LSKA | 80.6% | 78.0% | 84.8% | 63.5% | 3.08 | 8.2 | 0.89 |
| +SA | 80.6% | 77.7% | 84.8% | 63.4% | 3.01 | 8.1 | 0.89 |
| +SimAM | 82.7% | 77.3% | 85.1% | 63.6% | 3.01 | 8.1 | 0.89 |
| +TA | 80.4% | 79.1% | 85.1% | 63.7% | 3.01 | 8.1 | 0.90 |
| +DDA | 81.7% | 79.5% | 85.9% | 64.1% | 3.01 | 8.0 | 0.88 |

从表中可以看出，在原始YOLOv8n模型上加入DDA模块之后，模型的精确率、召回率、mAP50和mAP50-95分别提高了0.7%、0.8%、1.3%、0.9%。说明DDA模块通过空间域和通道域的信息引导，有效地提升了模型对图像中重要细节特征的捕获和利用能力，降低了模型在不同飞机型号之间的误判率。值得注意的是，添加DDA模块后，模型的参数量、运算量和推理时间保持不变。这表明DDA在提升模型性能的同时，没有增加资源损耗。与其他注意力机制进行性能比较，DDA模块表现出了显著的优势。其中添加SimAM后模型的精确率最高，但是也导致了召回率的下降，这说明此时模型更专注于准确识别那些确定为飞机的区域，但可能会错过一些细小的飞机部分或者与飞机相似的目标，从而导致漏检。DLKA的精度略高与DDA，但是其需要更高的计算成本，不利于资源受限或实时推理的场景下的应用。

因此，综合考虑检测精度与模型大小，本文提出的DDA模块都优于其他注意力机制，更加适用于光学遥感图像飞机目标检测任务。

### 3.3.5 消融实验与结果分析

为了验证文中所提出的各模块及模块组合的有效性，本文在MAR20数据集上展开一组消融实验，其中“√”表示在YOLOv8n中加入该模块，“×”表示没有加入该模块。实验结果如表3-3所示。

表3-3 消融实验

|     |     |     |     |     |     |     |     |     |     |     |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| SPPF_<br><br>Global | DDA | PDS | PIoU | Precision | Recall | mAP50 | mAP50-95 | Parameters<br><br>(M) | FLOPs<br><br>(B) | Latency<br><br>(ms) |
| ×   | ×   | ×   | ×   | 81.0% | 78.7% | 84.6% | 63.2% | 3.01 | 8.1 | 0.88 |
| √   | ×   | ×   | ×   | 82.2% | 78.5% | 85.6% | 64.0% | 3.06 | 8.0 | 0.88 |
| ×   | √   | ×   | ×   | 81.7% | 79.5% | 85.9% | 64.1% | 3.01 | 8.1 | 0.88 |
| ×   | ×   | √   | ×   | 83.1% | 78.5% | 86.0% | 64.6% | 2.74 | 7.8 | 1.04 |
| √   | √   | ×   | ×   | 82.6% | 79.7% | 86.5% | 64.6% | 3.06 | 8.0 | 0.89 |
| √   | √   | √   | ×   | 82.7% | 80.8% | 87.0% | 65.6% | 2.81 | 7.8 | 1.06 |
| √   | √   | √   | √   | 84.3% | 81.3% | 87.8% | 65.8% | 2.81 | 7.8 | 1.06 |

由表中数据可知，采用SPPF_Global模块后精确率、mAP50和mAP50-95分别提高了1.2%、1%和0.8％。这表明SPPF_Global模块能够有效地提高模型的检测准确性，减少了误检情况，为模型带来了明显的性能提升。

尽管单独使用DDA模块也能提高检测精度，但是与SPPF_Global结合后，模型的总体性能进一步得到了提升，这说明SPPF_Global模块和DDA注意力机制具有互补性，它们的组合能够综合利用全局信息和细粒度的注意力机制，提高了模型对目标的检测准确性和鲁棒性。

使用PDS模块改进YOLOv8n的下采样方式虽然因为引入分支和拼接操作略微增加了0.16ms的推理时间，但却也成功降低了参数量和运算量，有效地改善了模型对小目标的检测能力，使得模型能够更好地捕获细节信息并提高检测精度。将PDS模块引入SPPF_Global模块和DDA注意力机制组合的模型后，模型的精确率、召回率、mAP50和mAP50-95较原始模型分别提高1.7%、2.1%、2.4%、2.4%。

采用PIoU作为损失函数后，精确率和召回率分别提高了1.6%、0.5%，mAP50和mAP50-95分别提高了0.8%、0.2%，说明PIoU能够帮助预测框更加直接有效地回归。

最后，综合以上改进，相较于原模型，改进后的模型精确率、召回率、mAP50和mAP50-95分别提高了3.3%、2.6%、3.2%、2.6%，参数量和运算量分别降低6.6%、3.7%，更加满足光学遥感图像飞机目标检测的需求。

图3-6（a）~（d）分别为模型改进前后精确率、召回率、mAP50和mAP50-95的训练曲线，能够清晰的观测到改进后的有效性。

（a）Precision （b）Recall

（c）mAP50 （d）mAP50-95

图3-6 训练曲线图

### 3.3.6 对比实验与结果分析

为了更好的验证本文改进的模型GDA-YOLO在光学遥感图像飞机目标检测任务上的先进性，本文在MAR20数据集上与Faster R-CNN<sup>\[</sup>[<sup>13</sup>](#_ENREF_13)<sup>\]</sup>、RT-DETR<sup>\[</sup>[<sup>41</sup>](#_ENREF_41)<sup>\]</sup>、Gold-YOLO-n<sup>\[</sup>[<sup>77</sup>](#_ENREF_77)<sup>\]</sup>、YOLOv5n<sup>\[</sup>[<sup>25</sup>](#_ENREF_25)<sup>\]</sup>、YOLOv5s、YOLOv6n<sup>\[</sup>[<sup>26</sup>](#_ENREF_26)<sup>\]</sup>、YOLOv7-tiny<sup>\[</sup>[<sup>27</sup>](#_ENREF_27)<sup>\]</sup>、YOLOv8n<sup>\[</sup>[<sup>28</sup>](#_ENREF_28)<sup>\]</sup>、YOLOv9t<sup>\[</sup>[<sup>29</sup>](#_ENREF_29)<sup>\]</sup>、YOLOv10n<sup>\[</sup>[<sup>30</sup>](#_ENREF_30)<sup>\]</sup>、YOLO11n<sup>\[</sup>[<sup>31</sup>](#_ENREF_31)<sup>\]</sup>和YOLOv12n<sup>\[</sup>[<sup>32</sup>](#_ENREF_32)<sup>\]</sup>共12种模型进行性能对比，对比结果如表3-4所示，其中加粗表示最优值，下划线表示次优值。

表3-4 MAR20数据集对比实验

|     |     |     |     |     |     |     |     |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Model | Precision | Recall | mAP50 | mAP50-95 | Parameters<br><br>(M) | FLOPs<br><br>(B) | Latency<br><br>(ms) |
| Faster R-CNN | 66.1% | 61.1% | 80.9% | 58.7% | 41.75 | 91.23 | 8.74 |
| RT-DETR | **87.7%** | **83.4%** | 83.0% | 61.9% | 19.90 | 57.0 | 4.34 |
| Gold-YOLO-n | 78.2% | 75.7% | 81.8% | 59.8% | 5.61 | 12.07 | 1.35 |
| YOLOv5n | 80.6% | 75.4% | 81.9% | 59.6% | **1.79** | **4.2** | **0.72** |
| YOLOv5s | 82.6% | 79.5% | 85.9% | 63.5% | 7.06 | 15.9 | 1.53 |
| YOLOv6n | 79.7% | 74.3% | 81.9% | 59.4% | 4.63 | 11.35 | 0.99 |
| YOLOv7-tiny | 79.9% | 75.5% | 82.5% | 59.5% | 6.06 | 13.2 | 0.85 |
| YOLOv8n | 81.0% | 78.7% | 84.6% | 63.2% | 3.01 | 8.1 | 0.88 |
| YOLOv9t | 76.6% | 70.7% | 79.1% | 59.2% | 1.97 | 7.6 | 2.81 |
| YOLOv10n | 79.5% | 77.6% | 84.4% | 63.1% | 2.70 | 8.3 | 1.45 |
| YOLO11n | 80.1% | 77.8% | 83.6% | 62.4% | 2.59 | 6.3 | 1.64 |
| YOLOv12n | 76.8% | 74.5% | 80.7% | 60.1% | 2.56 | 6.3 | 2.72 |
| GDA-YOLO | 84.3% | 81.3% | **87.8%** | **65.8%** | 2.81 | 7.8 | 1.06 |

从表中可以看到，GDA-YOLO在mAP50和mAP50-95这两项指标上表现最为优异，这表明GDA-YOLO在飞机目标检测任务上精确性和鲁棒性都有很好的表现。虽然在精确率和召回率上略低于RT-DETR，但是RT-DETR需要大量的计算资源，从其高参数量、运算量和较长的推理时间可以看出。相比之下，GDA-YOLO在保持较高性能的同时，在资源消耗和推理时间方面表现得更为高效。在模型体积方面，YOLOv5n的体积最小，但其精度相对较低，这说明虽然较小的模型可能会节省资源，但会以降低精度为代价。因此，GDA-YOLO在平衡精度和资源消耗方面表现出更好的效果。

综上所述，GDA-YOLO的性能最佳。不仅在精度和鲁棒性上优于其他模型，而且保持较低的资源消耗和较快的推理速度，在光学遥感图像飞机目标检测任务上具有较高的实用性和先进性。

为进一步评估各模型在复杂环境和小目标检测中的性能，图3-7和图3-8分别展示了不同模型在这两类场景下的可视化结果。每种飞机型号用特定颜色框表示。

|     |     |     |     |
| --- | --- | --- | --- |
| （a）label | （b）RT-DETR | （c）Gold-YOLO-n | （d）YOLOv5s |

|     |     |     |     |
| --- | --- | --- | --- |
| （e）YOLOv6n | （f）YOLOv7-tiny | （g）YOLOv8n | （h）YOLOv9t |

|     |     |     |     |
| --- | --- | --- | --- |
| （i）YOLOv10n | （j）YOLO11 | （k）YOLOv12n | （l）GDA-YOLO |

图3-7 复杂环境下不同模型的可视化结果

|     |     |     |     |
| --- | --- | --- | --- |
| （a）label | （b）RT-DETR | （c）Gold-YOLO-n | （d）YOLOv5s |

|     |     |     |     |
| --- | --- | --- | --- |
| （e）YOLOv6n | （f）YOLOv7-tiny | （g）YOLOv8n | （h）YOLOv9t |

|     |     |     |     |
| --- | --- | --- | --- |
| （i）YOLOv10n | （j）YOLO11 | （k）YOLOv12n | （l）GDA-YOLO |

图3-8 小目标环境下不同模型的可视化结果

从图中可以发现，RT-DETR和Gold-YOLO-n虽然在这两种环境下都检测出了飞机目标，但它们过分关注图像中的细节，将一些无关的背景噪声和纹理误判为目标；YOLOv5s、YOLOv7-tiny、YOLOv9t、YOLOv10n和YOLO11虽然没有受到复杂环境的影响，但是缺乏对小目标的适应性，YOLOv7-tiny不仅将地面上的飞机痕迹误判为目标，而且还出现了漏检和错检的情况，对于小目标的检测能力较弱，YOLOv9t则几乎将机型A16误判为A13；YOLOv6n、YOLOv8n和YOLOv12n则在复杂环境和小目标环境下都未能准确定位和区分飞机目标。相比于其他模型，GDA-YOLO不仅成功准确地找到了飞机的位置，并进行了正确分类，在定位和分类方面表现出色，主要原因在于GDA-YOLO采用了SPPF_Global模块，增强了模型对整体图像情况的理解能力，从而提高了对复杂背景的抵抗能力。另外，双域注意力机制增强了模型对于关键区域的捕获能力，提高了对飞机机型的识别准确性。并行下采样模块进一步改进了模型的尺度感知能力，帮助小目标更好地被检测和定位。

最后，为了验证改进后模型在不同数据集中的泛化性，在NWPU VHR-10数据集上进行了对比实验，表3-5为对比实验结果。

表3-5 NWPU VHR-10数据集对比实验

|     |     |     |     |     |     |     |     |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Model | Precision | Recall | mAP50 | mAP50-95 | Parameters<br><br>(M) | FLOPs<br><br>(B) | Latency<br><br>(ms) |
| RT-DETR | 87.6% | 86.3% | 88.9% | **56.1%** | 19.88 | 57.0 | 4.34 |
| Gold-YOLO | 89.9% | 79.0% | 86.0% | 48.2% | 5.61 | 12.06 | 2.07 |
| YOLOv5n | 90.2% | 78.6% | 86.1% | 46.8% | **1.77** | **4.2** | 1.20 |
| YOLOv5s | **92.5%** | 85.3% | 89.6% | 51.6% | 7.04 | 15.8 | 1.79 |
| YOLOv6n | 85.2% | 80.9% | 85.6% | 47.7% | 4.63 | 11.34 | 1.55 |
| YOLOv7-tiny | 87.2% | 87.0% | 89.4% | 49.5% | 6.03 | 13.1 | 2.29 |
| YOLOv8n | 86.1% | 82.1% | 87.7% | 54.1% | 3.01 | 8.1 | **0.87** |
| YOLOv9t | 89.8% | 77.6% | 86.4% | 52.4% | 1.97 | 7.6 | 2.28 |
| YOLOv10n | 81.6% | 77.0% | 82.5% | 49.6% | 2.70 | 8.2 | 1.42 |
| YOLO11n | 88.7% | 79.5% | 86.0% | 50.7% | 2.58 | 6.3 | 1.22 |
| YOLOv12n | 86.3% | 78.7% | 84.0% | 50.0% | 2.56 | 6.3 | 2.12 |
| GDA-YOLO | 91.1% | **87.2%** | **90.2%** | 54.4% | 2.80 | 7.8 | 1.05 |

根据表中数据可以看出，GDA-YOLO在NWPU VHR-10数据集上的性能优越。精确率、召回率、mAP50和mAP50-95分别达到了91.1%、87.2%、90.2%、54.4%，较原始模型提升了5%、5.1%、2.5%、0.3%。其中GDA-YOLO的召回率和mAP50达到是表中最高的，高召回率意味着模型能够找到更多的真实目标，较高的mAP50表示模型在较低的IoU阈值下具有卓越的精确度，这两个指标的提升表明GDA-YOLO不仅在检测准确度上取得了明显的进步，而且在整体的目标覆盖率和检出性能上都得到了显著改善，这些优势共同表明GDA-YOLO在该数据集上的泛化能力和实用性大幅增强。此外，GDA-YOLO在资源效率和推理速度方面表现得也非常出色，远低于其他表现较好的模型，这意味着在保持高性能的同时，模型的复杂度和计算资源需求相对较低，预测延迟仅为1.05ms，显著快于其他模型。综合来看，GDA-YOLO在NWPU VHR-10数据集上的性能表现优异，既保持了较高的精度和召回率，同时在资源效率和推理速度方面也表现得非常出色，进一步验证了该模型在不同数据集中的泛化能力。

## 3.4 本章小结

本章基于YOLOv8n模型提出了一种融合全局信息与双域注意力机制的光学遥感图像飞机目标检测算法。首先，设计了SPPF_Global模块，引入全局最大池化层以增强对整个图像全局特征的捕获能力，减少背景干扰，提高检测准确性。其次，通过融合空间域和通道域信息，提出DDA注意力机制，加强模型对图像中重要区域和关键部件的关注，有助于更好地区分不同飞机型号的细微差别。随后，采用并行路径改进下采样模块，提升了小目标识别能力。最后，通过引入了PIoU损失函数，以自适应惩罚因子帮助预测框更直接有效地回归，提高了模型的收敛速度和检测精度。本文在公开数据集MAR20和NWPU VHR-10上进行了实验，结果表明，与原始YOLOv8n相比，改进后的模型在MAR20数据集上精确率、召回率和mAP50分别提高了3.3%、2.6%、3.2%和2.6%，在NWPU VHR-10数据集上分别提高了5%、5.1%、2.5%和0.3%。同时，模型的参数量和运算量分别降低了6.6%和3.7%，这些改进综合提升了模型在光学遥感图像飞机目标检测任务中的性能，并展现了在不同数据集上的泛化性能，为高效、准确地检测飞机目标提供了可靠的解决方案。

# 基于飞机目标检测与细粒度识别算法的轻量化方法研究

在光学遥感图像中的飞机目标检测与细粒度识别任务中，模型轻量化是提高推理速度和实现边缘端部署的关键技术挑战。本章将系统分析目前主流的轻量化技术，并提出针对性方案，重点讨论如何基于模型剪枝和知识蒸馏技术实现轻量化优化，以确保在满足硬件适配需求的同时，最大限度地提升模型性能与部署效率，最后通过一系列实验结果验证所提方案在实际应用中的可行性与优势。

## 4.1 轻量化方案的选择和制定

在光学遥感图像飞机目标检测与细粒度识别任务中，为了在硬件受限的场景下实现高效推理，必须在精度、速度与硬件适配性之间取得平衡。目前，主流的轻量化方法主要包括轻量化模型架构设计、量化、神经网络架构搜索（NAS）、模型剪枝以及知识蒸馏。本节将逐一分析这些方法的原理、优势与局限性，并结合GDA-YOLO的模型特性和硬件要求确定最终技术路线。

轻量化模型设计旨在通过优化网络结构来减少参数量与计算量，例如采用MobileNet、ShuffleNet、GhostNet等高效主干，其核心在于利用深度可分离卷积或分组卷积实现高效计算。然而，前一章节已针对遥感任务特性进行了网络结构的专项优化，直接替换通用轻量化主干不仅需要重新调整模块连接逻辑，还可能破坏现有模型在背景抑制和小目标特征保留方面的优势，且开发成本较高且性能难以预测，因此本研究不采用架构重构方案。

量化技术通过降低模型权重和激活值的数值精度来实现存储和计算优化。虽然INT8量化能将32位浮点数转换为8位整数，但其依赖复杂的校准流程，并且在处理复杂背景和细粒度目标时容易引起显著精度下降。相比之下，FP16量化在保留浮点表示的同时大幅降低显存占用和计算负载，且流程更简单、平衡性更好，更适合端到端部署。鉴于本章节主要目标为降低计算复杂度和存储需求，而量化对精度的具体影响需结合硬件评估，本研究将在后续的模型部署章节中采用FP16量化，并结合TensorRT实现推理加速。

NAS通过自动搜索最优网络结构理论上可以同时兼顾精度与效率，但其搜索过程通常需要需要数千 GPU 时的计算资源，且搜索空间设计需高度定制化。考虑到GDA-YOLO中包含全局信息融合、双域注意力等复杂定制模块，直接嵌入通用搜索空间风险较高，计算成本和适配难度远超实际条件，因此NAS不纳入本研究的轻量化方案。

模型剪枝通过移除冗余参数或结构压缩模型规模，主要分为非结构化剪枝和结构化剪枝。非结构化剪枝以单个权重为单位，虽能达到较高的压缩率，但生成的稀疏矩阵依赖专用的稀疏计算库，难以在通用硬件上实现高效加速。相比之下，结构化剪枝以通道或层为单位，保持模型的密集计算结构，更易部署。针对GDA-YOLO多分支和复杂依赖的特点，结构化剪枝能够保证剪枝后模型的合法性和性能，是更为理想的选择。

知识蒸馏则通过将大型复杂教师模型的知识传递给小型学生模型，在保持模型性能的同时实现模型压缩。其核心在于利用教师模型产生的软目标概率分布作为监督信号，帮助学生模型学习更具泛化能力的特征表示。特别是在剪枝后，模型可能会出现精度下降，此时引入基于逻辑的知识蒸馏，通过模仿教师最终输出的概率分布，不依赖中间层特征对齐，不仅实现简单且计算成本低，还能有效恢复学生模型的性能。因此，将知识蒸馏作为剪枝后的补偿手段，能在轻量化的同时最大程度保留检测精度。

综上所述，结合模型特性与硬件适配要求，本研究最终确定的轻量化技术路线如图4-1所示。基于GDA-YOLO模型，首先采用结构化剪枝大幅降低计算量；随后利用基于逻辑的知识蒸馏恢复并提升剪枝后模型的性能；最后，在后续的模型部署章节中，采用FP16量化技术并结合TensorRT实现推理加速。

图4-1 轻量化技术路线

## 4.2 模型剪枝流程

### 4.2.1 模型预处理

为实现安全剪枝并保持模型功能完整性，本研究从模块重构与关键层保护两个维度对GDA-YOLO进行了预处理优化，主要包括C2f模块重构与检测头跳层设计。

（1）C2f模块的结构重构

在GDA-YOLO模型中，C2f模块的结构如图2-12所示，特征图经过初始卷积层后，会通过切片（Split）操作将通道均分为两部分（记为A和B），其中A进入Bottleneck模块进行特征增强，最终与B在通道维度拼接（Concat）后输出。然而，若对初始卷积层进行剪枝操作，其输出通道数可能因剪枝比例无法被2整除，导致后续切片操作失败。例如，若初始卷积层的输出通道数从64剪枝至63，则无法均分A和B，引发维度不匹配错误。

为解决此问题，本研究提出C2f_Pruning模块，结构如图4-2所示，其核心改进为切片前置与卷积后置。

图4-2 C2f_Pruning模块结构图

原始C2f模块是将输入特征图输入卷积计算之后再输入至后续层计算，而在该模块中，首先对输入特征图进行切片，然后分别将每个切片输入到两个独立的卷积层中进行计算，这两个卷积核的参数由原始模块中首个卷积层在通道维度上拆分而来。最后，将两个卷积的输出在通道维度上拼接，得到与原始卷积输出等效的特征图。如公式（4-1）所示，重构后的模块输出与原始模块满足数学等价性。

（4-1）

式中，表示模块输出的通道数，操作是将卷积后的结果按照第二维度进行拼接。通过此设计，消除了剪枝后因通道数变化而引发的切片问题，虽然这种修改会增加一个卷积核，从而略微增加计算量和参数量，但其代价远低于因剪枝失败导致的模型不可用风险。

（2）检测头跳层设计

在YOLOv8模型中，检测头负责生成多尺度预测框并进行分类，其主要组成包括回归分支、分类分支和分布焦点损失层。为了确保在剪枝操作后模型的检测精度和功能完整性，本研究在剪枝过程中有针对性地跳过了检测头中的关键输出层和解码层。

具体而言，回归分支的输出层用于生成边界框坐标的离散分布参数，若对该层进行剪枝，将直接破坏边界框的编码逻辑，导致坐标预测出现偏差。分类分支的输出层负责输出类别概率分布，剪枝此层可能减少有效类别通道，进而引发漏检或误分类。分布焦点损失层将回归分支输出的离散分布转换为连续空间坐标，其计算逻辑依赖固定的通道数，剪枝会破坏分布参数维度，导致解码失败。由于这些层的功能特殊性和不可训练性，剪枝操作无实际优化意义，因此在设计中选择跳过这些层，以避免对模型性能和功能的负面影响。

### 4.2.2 构建依赖图

在结构化剪枝中，参数分组是实现模型压缩的关键挑战。如图4-3（a）所示，当剪枝某个神经元以提高计算效率时，与其相连的所有参数需同时移除，这些参数构成了结构化剪枝的基本单元，通常称为组（Group）。然而，不同网络架构中的参数分组方式存在较大差异。图4-3（b）~（d）分别展示了残差结构、拼接结构和降维结构对参数分组的影响。这些结构甚至可以嵌套组合，进一步增加分组模式的复杂性。在传统剪枝方法中，参数分组通常依赖手动设定，这不仅耗时且繁琐，还要求开发人员深入理解网络结构及层间依赖关系。因此，参数分组成为结构化剪枝算法实际应用的关键难题。

（a）基本结构 （b）残差结构

（c）拼接结构 （d）降维结构

图4-3 不同结构中的参数依赖关系

为了解决这些问题，实现复杂网络结构的自动化剪枝，本文基于Torch-Pruning框架进行剪枝，该框架的底层算法为依赖图（Dependency Graph，DepGraph），其核心思想是通过依赖图显式建模层间与层内的参数耦合关系，实现剪枝组的自动化生成。依赖图的构建不仅解决了传统方法的局限性，还为复杂网络提供了普适性剪枝框架。

在结构化剪枝中，同一分组内的参数是两两耦合的，因此当移除其中某个参数时，该组内的所有参数均需同步移除，以确保网络结构的完整性。DepGraph采用二元分组矩阵存储神经元之间的耦合关系，其中代表第层和第层的神经元存在耦合关系，需要同步剪枝。借助此矩阵，剪枝过程可转换为矩阵查询任务，从而提升计算效率：

（4-2）

由于依赖关系不仅涉及神经元之间的直接连接，还需考虑中间层的影响。DepGraph通过局部依赖分析逐层推导神经元的分组关系。例如，若层A与层B存在依赖关系，且层B又与层C相关，则可推断层A亦与层C具有依赖关系，即便它们之间没有直接连接。这种相邻层间的局部依赖关系即为依赖图（Dependency Graph），记作D。依赖图将相邻层间的局部依赖关系抽象为路径搜索任务，若依赖图中的节点和之间存在路径相连，则它们属于同一剪枝分组。

然而，上述的依赖图D中并不能包含对输入和输出通道上的修剪。为此，DepGraph提出了一种更细粒度的模型描述方式，从逻辑上将每一层拆解成输入和输出。此时，一个简单的堆叠网络就可以描述为公式（4-3），其中符号表示网络连接。

（4-3）

通常而言，每个神经网络中都会存在复杂的依赖关系，因此需要进一步区分层间依赖与层内依赖。其中，层间依赖由相邻层的直接连接产生，例如某层的输出作为下一层的输入，这意味着这两层需同步剪枝。而层内依赖则取决于该层的输入与输出特性，可进一步分为输入输出独立和输入输出耦合，前者允许分别剪枝，采用不同剪枝策略；而后者必须使用相同剪枝策略，如逐元素运算。

基于上述分类方式，神经网络模型中各层的依赖图构建规则可形式化描述为公式（4-4）：

（4-4）

其中表示层间依赖关系，代表层内依赖关系，符号“”表示逻辑“与”，用于确保剪枝策略的匹配，而表示具体的剪枝方案。

为了更好地理解依赖图的构建过程，以残差结构块为例，展示依赖图的构建及可视化结果如图4-4所示。在具体剪枝时，可选取任意节点作为起点，例如以作为起点，递归搜索所有可访问节点，并将其归入同一剪枝组。值得注意的是，在卷积网络中，由于输入和输出采用了不同的剪枝布局（即），在依赖图中和之间不存在层间依赖。然而，若存在跳跃连接（如），则递归搜索过程中和仍会被归入同一剪枝组，即它们仍需同步裁剪。此外，对于批归一化（BN）层，其输入输出通常存在简单的层内依赖。

（a）残差结构单元图 （b）依赖关系图

图4-4 残差结构单元的依赖关系构建

### 4.2.3 基于LAMP重要性评估的通道剪枝

通过依赖图的自动化构建，解决了结构化剪枝中参数分组的核心难题，实现了对神经网络中层间与层内复杂耦合关系的精准建模。然而，依赖图仅保障了模型结构的合法性，剪枝的具体执行仍需解决另一关键问题：如何评估通道重要性以选择最优剪枝目标，从而在压缩模型规模的同时最小化精度损失。

传统的基于权重幅值的剪枝方法（如L1-Norm）可以通过移除低幅值通道实现稀疏化，但其依赖人工设定逐层剪枝比例或复杂超参数搜索，难以适应复杂网络的结构特性，且易引发“层崩溃”问题，即某层的所有通道被误判为冗余而整体移除，导致模型功能失效。为解决上述问题，本文基于层自适应幅度剪枝（Layer-adaptive Magnitude-based Pruning，LAMP）评分算法进行通道剪枝，其核心思想是通过层间重要性归一化与动态稀疏度分配，实现剪枝比例的自动优化。

首先，对于全连接层或卷积层的权重张量，将其展平为一维向量并建立权重索引、，根据权重绝对值的大小按升序排序，即满足时，。基于这一排序，定义索引对应得权重的LAMP分数定义为公式（4-5）：

\= （4-5）

式中，分子代表了目标连接的权重幅度的平方，分母代表了在该层中所有更大权重幅度平方之和，因此LAMP分数衡量了目标连接在当前层其他连接中的重要性。此外，在每一层还至少保留一个具有LAMP分数为1的连接，从而避免了以往剪枝算法出现的层级完全被剪除导致的“层崩溃”问题。

在设定目标剪枝比例后，算法将通道按照全局重要性升序排列，从最不重要的通道开始逐层移除，直到满足全局稀疏性目标。这个过程相当于通过自动选择的分层稀疏度执行动态剪枝，如公式（4-6）所示：

（4-6）

在此过程中，每次剪枝操作均触发依赖图的动态更新机制，自动调整后续层的输入/输出通道数（如特征拼接层的通道对齐），确保模型始终处于合法状态。相较于传统方法，LAMP通过依赖图的约束与全局重要性排序，避免了人工逐层设定剪枝比例的繁琐过程，提高了剪枝效率。

### 4.2.4 微调训练

本文采用剪枝与知识蒸馏相结合的轻量化策略，其核心在于通过结构压缩与知识迁移的协同优化实现模型的高效精简。在这一框架下，评估不同剪枝率对模型性能的影响是选择最优学生模型的关键步骤。然而，剪枝操作本质上是对网络拓扑结构的重构，这种结构改变会显著影响模型的参数分布和特征表达能力，导致性能的暂时性下降。因此，需要通过微调训练来修复剪枝带来的结构损伤，使模型能够重新适应新的网络架构，从而恢复其表征能力。

微调训练过程中，模型通过全局参数优化动态调整权重分布，逐步重建被剪枝破坏的特征映射路径，最终达到与新结构相匹配的性能水平。只有在充分微调的基础上评估模型性能，才能准确反映不同剪枝率对模型精度的真实影响，避免因参数未充分优化而导致的评估偏差。

在微调训练的具体实现中，主要存在两种策略：局部微调和全网络微调。局部微调仅对剪枝后的部分层进行参数更新，虽然计算效率较高，但可能因层间特征失配而限制模型的恢复能力；相比之下，全网络微调通过对整个网络的所有层进行协同优化，能够更好地适应剪枝后的结构变化，确保模型在精简架构下重建完整的特征表达能力。基于上述分析，本文在微调训练阶段采用全网络训练策略，并结合标准的优化技术（如学习率动态调整、批量训练等），使剪枝后的模型能够通过全局参数更新逐步恢复到一个较高的性能水平，为后续的知识蒸馏奠定基础。

## 4.3 知识蒸馏优化方案

本节将详细分析密集目标检测蒸馏过程中存在的跨任务协议不一致问题，特别是在遥感飞机目标检测与细粒度识别任务中，由于分类与定位任务的预测机制不同，教师模型与学生模型的输出分数往往存在显著偏差，影响知识迁移的有效性。为此，本文设计了一种适用于GDA-YOLO的蒸馏损失函数，在兼顾分类与定位需求的同时，有效缓解协议不一致问题，从而在剪枝后进一步恢复并提升模型整体性能。

### 4.3.1 跨任务协议不一致问题

在密集目标检测任务中，尤其是遥感飞机目标检测与细粒度识别任务中，模型需要从整幅图像生成的密集特征图上，为每个采样点预测其所属类别的得分以及相应的边界框。然而，图像中背景像素的数量远超前景目标，导致前景与背景之间存在严重的不平衡。在训练过程中，绝大部分采样点都属于背景类别，当采用Softmax方法为每个样本分配K+1个类别的概率时（其中K为前景类别数，另一个概率为背景），由于背景类别占据数量优势，Softmax方法倾向于偏向背景类别，导致分类效果不佳。为了解决这一问题，许多密集检测模型采用Sigmoid方法计算分类得分。Sigmoid方法将多类别分类问题转化为多个独立的二分类问题，这种方法有效缓解了前景与背景类别的不平衡问题。具体而言，模型会生成尺寸为H×W×K的分类图，其中H和W分别代表图像的高度和宽度，而K表示类别数。每个位置的标签是通过独热编码方式标记正样本，负样本则标记为全零张量。对于样本，表示其分类logits，采用Sigmoid协议计算获得分类得分，即。此外还有一个针对的标签张量。通过二元交叉熵损失，如公式（4-7）所示，模型可以评估预测得分与标签之间的误差。

（4-7）

其中，为第个位置、第类的二值交叉熵损失，定义为公式（4-8）：

（4-8）

然而在通用分类蒸馏方法中，对于样本，通常使用Softmax协议进行分类蒸馏，令和分别表示其教师模型和学生模型的分类logits，即，，分类蒸馏损失定义为教师分数与学生分数之间的Kullback-Leibler（KL）散度：

（4-9）

其中，表示分类蒸馏损失，表示KL散度。

由于Softmax和Sigmoid在分类得分计算上的差异，直接使用图像分类中的蒸馏方法（基于Softmax）在目标检测任务中效果不佳。即使蒸馏损失为0，学生模型在目标检测任务中的分类得分仍然无法达到教师模型的水平，导致分类性能下降。例如，当是一个与形状相同的常量张量，且时，根据公式（2-3），Softmax计算出的概率分布保持不变：

（4-10）

因此，蒸馏损失等于零，并且没有从教师模型到学生模型的进一步定位知识转移。然而，对于Sigmoid，学生模型和教师模型的分类得分并不完全一致，即。因此学生模型无法从教师模型继承正确的预测能力，导致蒸馏效果不佳。

此外，在定位任务中，现有的定位蒸馏方法（如LD<sup>\[</sup>[<sup>78</sup>](#_ENREF_78)<sup>\]</sup>）通常将边界框转换为概率分布，以解决定位蒸馏问题，使用离散的边界框预测头（例如广义焦点损失头<sup>\[</sup>[<sup>79</sup>](#_ENREF_79)<sup>\]</sup>）来精确预测每个样本的定位概率分布。然而，当前的目标检测模型通常使用连续框偏移预测头，这就使得在使用LD方法时，需要对教师模型进行特定的训练，以适配离散位置概率预测头，这种限制显著降低了LD方法的普适性。

### 4.3.2 蒸馏损失函数优化

针对遥感飞机密集检测任务中存在的跨任务协议不一致问题，本文基于BCKD（Bridging Cross-task Protocol Inconsistency for Distillation）<sup>\[</sup>[<sup>80</sup>](#_ENREF_80)<sup>\]</sup>的思想，提出适配GDA-YOLO模型的蒸馏损失函数设计方案。该方案结合二元分类蒸馏损失、基于IoU的定位蒸馏损失与GDA-YOLO原始损失函数，优化教师模型向剪枝后的轻量化学生模型的知识迁移，实现分类与定位性能的同步提升。

（1）二元分类蒸馏损失

针对密集目标检测中分类任务的特点，本文将分类logit图视为多个独立的二元分类任务进行处理。具体来说，对于输入样本，教师模型和学生模型分别生成分类logits（和）。通过Sigmoid协议，分别计算得到二元分类得分，即和，然后基于这些二元分类分数计算得到总的二元分类蒸馏损失：

（4-11）

其中，为二元交叉熵损失，分别表示，的第个位置和第个类别，为分类蒸馏损失。

考虑到教师与学生模型在输出上可能存在较大差异，为使模型更关注那些误差较大的样本，引入损失加权策略，通过计算样本的重要性权重：

（4-12）

对分类蒸馏损失进行加权，最终的分类蒸馏损失公式为公式，使得模型专注于学习重要的样本。加权后的二元分类蒸馏损失如公式（4-13）所示，其中为采样点总数，为前景类别数：

（4-13）

（2）基于IoU的定位蒸馏损失

在定位任务中，为了直接传递教师模型的定位知识而不依赖于复杂的边界框离散化，本研究采用基于IoU的定位蒸馏损失，利用两个边界框之间的交并比作为蒸馏目标。对于给定的输入样本，将教师模型和学生模型在第个位置的预测分别表示为和。然后，通过锚点位置和预测的偏移量来计算边界框的位置，其中表示第个锚点，通过解码器得到的边界框分别表示为和。接下来，计算这两个边界框之间的交并比，记作。

同样地，为使模型更加关注定位精度较低的关键样本，引入损失加权策略，最终，定位蒸馏损失的计算公式可以表示为：

（4-14）

其中表示对第个采样点在所有类别上计算得到的最大权重。这种无结构的定位蒸馏损失方法通过直接对比教师和学生模型在定位上的差异，避免了传统方法中对离散化过程的依赖，并且更加高效地传递了定位知识。

（3）总蒸馏损失函数

为平衡原始任务学习与知识迁移，本文将GDA-YOLO的原始损失与上述蒸馏损失联合优化，构建了总蒸馏损失函数，其形式为：

（4-15）

其中，是GDA-YOLO原始的损失函数，包含分类损失、定位损失和置信度损失。为蒸馏损失平衡系数，用于调节GDA-YOLO和蒸馏损失之间平衡，防止学生模型过度拟合教师输出，和分别是分类蒸馏损失和定位蒸馏损失的权重系数。通过对总蒸馏损失函数的优化，可以使得学生模型在剪枝后既能恢复原有性能，又能进一步通过蒸馏过程获得教师模型的优势，最终实现更高效、更鲁棒的模型压缩效果。

## 4.4 实验结果与分析

### 4.4.1 实验设备和数据集

本章的轻量化实验硬件环境与第三章保持一致，包括Ubuntu 20.04.5 LTS操作系统、AMD EPYC 9754 128-Core CPU、NVIDIA GeForce RTX 3090 GPU（显存容量 24GB）及基于Python 3.8.18和Pytorch 1.13.1的深度学习框架。

实验数据集为MAR20数据集，包含3842张图像和20种军用飞机型号（A1-A20），训练集和验证集分别包含1331张图像（7870个目标实例）和2511张图像（14471个目标实例）。由于数据集中飞机外观特征相似，细粒度类别之间具有较高的相似性，为轻量化模型性能验证提供了较大挑战。

### 4.4.2 公共评价指标

为了全面评估模型性能，本文在第三章的评价指标基础上新增了每秒帧数（FPS），即模型每秒推理的图片数量，以直观反映推理速度。评价指标包括精确率（P）、召回率（R）、平均精度均值（mAP）、参数量、浮点运算次数（FLOPs）和FPS。其中，FPS计算公式（4-16）为：

（4-16）

其中，为测试次数，设置为500，为每次测试的图片数量，设置为32，为次测试的总耗时。为避免GPU在低功耗状态下影响推理速度，测试前需进行预热，预热参数为=200、=32，推理过程与正式测试一致。上述指标从多方面对模型的精度、速度及复杂度进行评估，保证了结果的科学性和全面性。

### 4.4.3 剪枝实验与结果分析

为了进一步压缩模型规模、提高推理速度，并验证剪枝方法的效果，同时探究剪枝系数对模型性能的影响，本文对第三章提出的GDA-YOLO进行了剪枝实验。实验通过逐步增加剪枝率，从未剪枝（剪枝率为0）到剪枝率为15，评估剪枝对模型性能的影响，剪枝率的表达式如公式（4-17）所示：

（4-17）

其中，、分别表示剪枝之前模型和剪枝之后模型的计算复杂度。在每一剪枝率下，对模型进行剪枝后均通过微调以恢复性能，并最终获得优化后的模型。实验从多维度对剪枝后的模型性能进行了全面评估，包括模型参数量、计算复杂度、精确率、召回率、平均精度均值以及推理帧率，对模型性能的影响结果如表4-1所示。

表4-1 不同剪枝率对模型性能的影响

|     |     |     |     |     |     |     |     |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Pruning_Rate | Parameters<br><br>（M） | FLOPs<br><br>(B) | Precision | Recall | mAP50 | mAP50-95 | FPS |
| 0.0 | 2.81 | 7.8 | 84.3% | 81.3% | 87.8% | 65.8% | 936.5 |
| 1.5 | 1.32 | 5.2 | 84.7% | 81.0% | 87.6% | 66.4% | 1080.2 |
| 2.0 | 0.83 | 3.9 | 85.3% | 81.2% | 87.7% | 66.4% | 1176.9 |
| 2.5 | 0.59 | 3.1 | 85.0% | 80.6% | 87.1% | 65.4% | 1251.9 |
| 3.0 | 0.46 | 2.5 | 82.6% | 79.9% | 86.0% | 64.3% | 1359.5 |
| 3.5 | 0.38 | 2.2 | 82.1% | 79.7% | 86.0% | 64.4% | 1460.6 |
| 4.0 | 0.32 | 1.9 | 80.2% | 76.9% | 83.7% | 62.3% | 1541.6 |
| 4.5 | 0.28 | 1.7 | 77.2% | 75.9% | 81.2% | 60.0% | 1585.0 |
| 5.0 | 0.25 | 1.5 | 76.2% | 72.9% | 79.9% | 59.0% | 1588.4 |
| 5.5 | 0.22 | 1.4 | 73.2% | 69.5% | 75.7% | 55.6% | 1611.6 |
| 6.0 | 0.20 | 1.3 | 71.4% | 70.9% | 75.1% | 54.7% | 1669.6 |
| 6.5 | 0.18 | 1.1 | 65.1% | 68.1% | 69.3% | 50.7% | 1745.2 |
| 7.0 | 0.17 | 1.1 | 56.1% | 65.6% | 63.0% | 45.7% | 1863.9 |
| 8.0 | 0.15 | 0.9 | 53.4% | 63.6% | 61.1% | 44.0% | 1993.0 |
| 9.0 | 0.13 | 0.8 | 40.3% | 59.5% | 46.9% | 33.8% | 2100.1 |
| 10.0 | 0.12 | 0.8 | 37.0% | 60.4% | 42.6% | 30.1% | 2189.2 |
| 11.0 | 0.11 | 0.7 | 32.8% | 59.7% | 38.2% | 26.8% | 2257.1 |
| 12.0 | 0.10 | 0.6 | 37.4% | 55.2% | 36.6% | 25.6% | 2333.2 |
| 15.0 | 0.09 | 0.5 | 47.9% | 40.4% | 28.1% | 19.4% | 2524.0 |

为了更好地分析剪枝对模型性能的影响，图4-5展示了不同剪枝率下模型性能的变化曲线。图中分别绘制了参数量、运算量、mAP50和mAP50-95与剪枝率的关系。通过以剪枝率为横坐标，mAP50、mAP50-95、参数量和运算量为纵坐标，展示了不同剪枝率下模型的性能变化趋势。特别地，图中标出了剪枝率为3.5时的关键数据点，以便突出该剪枝率对模型性能的影响。这些图表为确定最佳剪枝率提供了直观的参考依据。

图4-5 不同剪枝率下模型性能变化曲线

从实验结果可以看出，随着剪枝率逐步增加，模型的参数量和计算量逐渐减少，同时推理速度显著提升。在剪枝率从0.0增加到3.5时，模型的检测精度，包括精确率、召回率、mAP50和mAP50-95表现出一定的波动，但整体上仍呈现出优化的趋势。特别是在剪枝率为3.5时，模型的mAP50达到86.0%，mAP50-95为64.4%，同时推理速度从936.5 FPS提升至1460.6 FPS，提升了约55.9%。这一结果表明，剪枝在提升模型推理速度的同时，也能在一定范围内保持较好的精度。

然而，当剪枝率超过3.5后，模型的检测精度开始显著下降。特别是在剪枝率达到6.0及以上时，mAP50和mAP50-95出现了明显衰减，尽管推理速度继续提升，但精度的下降已超过了速度提升所带来的收益。剪枝率为6.0时，mAP50降至75.1%，mAP50-95降至54.7%，推理速度为1669.6 FPS，精度的下降已显著影响了模型的整体表现。

当剪枝率进一步增加至10.0及以上时，模型的性能开始急剧下降。剪枝率为10.0时，mAP50降至37.0%，mAP50-95降至30.1%，推理速度虽然达到2189.2 FPS，但精度的明显损失使得模型在实际应用中不再具有足够的有效性。随着剪枝率增加至15.0，精度进一步下降，mAP50和mAP50-95分别降至28.1%和19.4%，尽管推理速度继续提升，但过度剪枝导致的精度损失显然无法通过速度提升来弥补。

综合考虑剪枝率对精度、推理速度和参数量的影响，可以发现剪枝率为3.5时在性能和效率之间达到了最佳平衡。此时，模型的参数量、计算量和推理速度相对合理，而检测精度仍能保持较高水平。因此，剪枝率为3.5的模型被选定为后续知识蒸馏阶段的学生模型，以进一步提升模型的精度和效率，并为高效部署提供支持。

图4-6显示了模型剪枝前后通道对比图，图中可以清晰地观察到剪枝策略在模型各部分的通道保留和削减情况。其中，橙色柱状表示第三章优化模型剪枝前的通道数，红色柱状表示剪枝率为3.5时模型的通道数。横轴表示模型中的模块名称及其对应层次，纵轴表示通道数。

图4-6 剪枝前后通道对比图

从通道图可以看出，剪枝算法优先针对高通道数的层（如model.5、model.7和model.9）进行大幅度剪枝，而对低通道数的层（如初始卷积层model.0和model.1）影响较小。这是因为初始层负责提取底层的边缘和纹理特征，是特征表达的重要基础，因此需要尽可能保留。而高通道模块中可能存在较多冗余特征，通过有效剪枝可以显著降低计算开销并压缩模型规模，同时保证底层特征提取的完整性。这种策略展现了剪枝算法在优化模型性能与保持特征表达能力之间的平衡。

值得注意的是，model.9.cv2.conv的通道数被完全保留，未发生任何裁剪。该层属于SPPF_Global模块的最后一部分，其作用是整合全局上下文特征，增强特征表达能力，对模型整体性能影响重大。剪枝算法识别出该层的重要性，因此优先保护其特征完整性，表明剪枝过程能够有效保护关键层的信息表达能力，避免对全局特征的破坏。

在Neck部分，尤其是model.19至model.22层，通道数被大幅削减。由于这几层负责多尺度特征的融合与传递，剪枝算法判断它们存在一定比例的冗余通道，从而对其进行较大幅度的裁剪，以降低网络计算量。同时，依托 SPPF_Global 等模块高度浓缩的特征信息，模型在通道数减少后依然能维持较好的特征融合能力。

此外，由于在模型预处理阶段对检测头的关键输出层与解码层进行了跳层处理，这些层在剪枝过程中几乎未受到影响，其通道数也基本保持不变。有效保护边界框编码逻辑、类别概率分布以及连续坐标解码的完整性，避免因剪枝而导致的坐标预测偏差或漏检误分类。

### 4.4.4 蒸馏实验与结果分析

（1）教师模型的选择

在蒸馏实验中，教师模型的选择对于蒸馏效果至关重要。教师模型的优劣不仅决定了蒸馏过程的有效性，还直接影响学生模型在性能和推理效率上的表现。因此，选择一个合适的教师模型需要综合考虑模型的性能、计算复杂度、推理速度等因素。在本研究中，本文基于原始YOLOv8和GDA-YOLO的四种不同尺寸进行了实验，评估其在各项指标上的表现，教师模型的性能对比实验数据如表4-2所示。

表4-2 教师模型选择与性能对比

|     |     |     |     |     |     |     |     |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Model | Parameters<br><br>（M） | FLOPs<br><br>（B） | Precision | Recall | mAP50 | mAP50-95 | FPS |
| YOLOv8n | 3.01 | 8.1 | 81.0% | 78.7% | 84.6% | 63.2% | 1131 |
| YOLOv8s | 11.13 | 28.5 | 82.3% | 81.8% | 87.4% | 66.1% | 506.8 |
| YOLOv8m | 25.85 | 78.7 | 84.6% | 82.8% | 88.9% | 67.4% | 210.6 |
| YOLOv8l | 43.62 | 164.9 | 86.4% | 83.8% | 89.9% | 68.4% | 123.7 |
| GDA-YOLO-n | 2.81 | 7.8 | 84.3% | 81.3% | 87.8% | 65.8% | 936.5 |
| GDA-YOLO-s | 10.32 | 27.4 | 85.8% | 81.1% | 88.6% | 67.2% | 444.1 |
| GDA-YOLO-m | 23.76 | 76.1 | 86.5% | 83.3% | 89.4% | 68.3% | 195.5 |
| GDA-YOLO-l | 43.62 | 164.9 | 86.6% | 83.8% | 89.7% | 68.3% | 117.3 |

从表中的实验结果可以看出，随着模型尺寸的增大，检测精度显著提升，如YOLOv8l模型mAP50为89.9%，明显高于YOLOv8n模型的84.6%。这是因为较大的模型拥有更多的参数和更深的网络结构，能够提取更加细致和多样化的特征，从而提高检测能力。

然而，尽管大模型在检测精度上具有优势，其计算复杂度也随之增加。模型的参数量和运算量在从YOLOv8n到YOLOv8l的过程中呈指数级增长，YOLOv8l模型的参数量高达43.62M，而YOLOv8n仅为3.01M。这意味着大模型不仅需要更多的存储空间，还需要更高的计算资源和更长的推理时间。因此，尽管 YOLOv8l在检测精度上表现最好，但其推理速度FPS仅为123.7，这使其在实际部署中可能会成为瓶颈。

与此相对，GDA-YOLO系列在各个尺寸上均表现出较YOLOv8系列更好的性能，尤其在mAP50-95和召回率方面。以GDA-YOLO-m为例，尽管其mAP50略低于YOLOv8l，但其在推理速度上表现更为优秀，达到了195.5 FPS，明显高于YOLOv8l的123.7 FPS，且参数量较YOLOv8l减少了近一半。这使得GDA-YOLO-m在实际应用中更具优势，尤其是在需要平衡精度和推理速度的场景中。

综合考虑以上各项因素，最终选择GDA-YOLO-m作为教师模型，为后续学生模型的蒸馏提供理想的基础。

（2）蒸馏损失平衡系数的选择

基于前文介绍的总蒸馏损失函数，本实验将权重和参考文献\[[80](#_ENREF_80)\]，分别设置为4.0和1.0，以在分类与定位任务之间实现合理的平衡。为进一步优化模型性能，实验针对蒸馏损失平衡系数的取值范围（0.2至2.0）进行了探索，并对不同值下的模型表现进行了分析，实验结果如表4-3所示。

表4-3 蒸馏损失平衡系数对模型性能的影响

|     |     |     |     |     |
| --- | --- | --- | --- | --- |
|     | Precision | Recall | mAP50 | mAP50-95 |
| 0.2 | 83.2% | 80.4% | 86.7% | 64.5% |
| 0.4 | 83.6% | 81.2% | 87.2% | 64.9% |
| 0.6 | 83.4% | 81.1% | 87.5% | 65.2% |
| 0.8 | 82.8% | 82.2% | 87.6% | 64.8% |
| 1   | 84.8% | 80.7% | 87.6% | 65.0% |
| 1.2 | 83.8% | 80.2% | 87.5% | 64.9% |
| 1.4 | 85.3% | 80.5% | 88.1% | 65.2% |
| 1.6 | 85.7% | 80.5% | 88.2% | 65.4% |
| 1.8 | 86.9% | 80.1% | 88.0% | 65.2% |
| 2   | 85.7% | 80.2% | 87.7% | 64.8% |

从表中的数据可以看出，在蒸馏损失权重的初始阶段，即当取值在0.2至0.6之间时，较小的蒸馏损失率导致蒸馏损失函数的优化效果较弱，从而限制了学生模型对教师模型知识的学习。当蒸馏损失率增加至0.8至1.6之间时，蒸馏损失的贡献逐渐显现，模型的性能得到了显著提升。特别是当取值为1.6时，mAP50达到了峰值88.2%，mAP50-95提升至65.4%，表明模型在分类与定位任务之间达到了较为均衡的优化效果，这验证了总蒸馏损失函数设计的有效性。然而，当蒸馏损失权重进一步增大至1.8和2.0时，尽管mAP50略有波动，但mAP50-95出现了明显下降，分别降至65.2%和64.8%。这一现象表明，过高的蒸馏损失权重可能导致学生模型过拟合于教师模型的输出分布，从而降低其泛化能力。

通过上述分析，被确认为最优的蒸馏损失率取值。在这一取值下，分类和定位任务之间得到了良好的平衡，并显著提高了学生模型在检测精度和泛化能力方面的表现，为总蒸馏损失函数的设计与优化提供了有力的支持。

### 4.4.5 模型各阶段性能对比分析

为验证本文轻量化策略的有效性，本节将对模型各阶段性能进行对比分析，具体实验数据如表4-4所示：

表4-4 模型各阶段性能

|     |     |     |     |     |     |     |     |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Model | Parameters（M） | FLOPs<br><br>（B） | Precision | Recall | mAP50 | mAP50-95 | FPS |
| GDA-YOLO | 2.81 | 7.8 | 84.3% | 81.3% | 87.8% | 65.8% | 936.5 |
| GDA-YOLO+剪枝 | 0.38 | 2.2 | 82.1% | 79.7% | 86.0% | 64.4% | 1460.6 |
| GDA-YOLO+剪枝  <br>+蒸馏 | 0.38 | 2.2 | 85.7% | 80.5% | 88.2% | 65.4% | 1462.3 |

从表中可以看出，在GDA-YOLO基础上进行剪枝后，模型的参数量从2.81M减少至0.38M，计算复杂度从7.8 GFLOPs降至2.2 GFLOPs，显著降低了资源消耗。此外，剪枝模型的推理速度大幅提升，达到1460.6 FPS，相较GDA-YOLO提升了55.9%。然而，由于剪枝过程中去除了部分冗余特征，模型在精确率、召回率、mAP50和mAP50-95上分别下降了2.2%、1.6%、1.8%和1.4%。这表明，尽管剪枝显著提高了推理效率，但同时不可避免地引入了性能损失。

引入知识蒸馏后，剪枝模型的性能得到了显著恢复。蒸馏后的模型在精确率、召回率、mAP50和mAP50-95上分别提升了3.6%、0.8%、2.2%和1.0%，几乎完全弥补了剪枝带来的精度下降，同时推理速度仍然保持在1462.3 FPS，几乎未受影响。蒸馏过程通过传递教师模型的细粒度特征信息，有效增强了剪枝模型对目标的表达能力。

结合剪枝与知识蒸馏后的轻量化GDA-YOLO模型与原始GDA-YOLO模型相比，参数量减少了86.5%，计算复杂度降低了71.2%，推理速度提升了56.1%。与此同时，轻量化模型在检测性能方面，召回率有所降低，但仍保持85.7%的精确度，并在mAP50和mAP50-95上分别达到了88.2%和65.4%，相比原始GDA-YOLO稍有提升。

综合来看，所提出的轻量化策略通过剪枝和蒸馏的协同优化，在显著降低资源需求的同时，进一步提升了检测性能，充分验证了其在遥感飞机目标检测与细粒度识别任务中的优越性和实用价值，为资源受限场景下的高效目标检测提供了有效解决方案。

## 4.5 本章小结

本章围绕遥感飞机目标检测与细粒度识别任务的需求，系统探讨了轻量化策略在GDA-YOLO模型上的应用与优化过程。首先，结合模型特性与硬件约束，综合对比当前主流轻量化技术，并最终确定了以结构化剪枝和知识蒸馏为核心的轻量化路线。随后，在对模型进行模块重构与检测头关键层保护的基础上，通过依赖图的构建和LAMP重要性评估实现了自动化的结构化剪枝，避免了通道不匹配和层崩溃等问题。接着，通过全网络微调训练筛选出最佳模型，为后续蒸馏过程奠定了良好基础。最后，针对密集目标检测蒸馏任务中存在的跨任务协议不一致性问题，本文通过引入二元分类蒸馏损失与基于IoU的定位蒸馏损失，并将其与原始损失函数相结合，进一步提升了剪枝后学生模型的精度和鲁棒性。实验结果表明，剪枝后的GDA-YOLO模型参数量从2.81M降至0.38M，减少了86.5%，计算量从7.8 GFLOPs降至2.2 GFLOPs，下降幅度为71.2%。随后，通过蒸馏损失引导学生模型学习教师模型的深层特征，有效弥补了剪枝带来的精度损失。最终，经过轻量化框架的GDA-YOLO模型推理速度显著提升，FPS达到1462.3，相比原始GDA-YOLO提升了56.2%。在精度方面，轻量化后的模型仍保持85.7%的精确度，并在mAP50和mAP50-95上分别达到了88.2%和65.4%，相比原始GDA-YOLO稍有提升。这表明，经过剪枝和蒸馏优化后的模型在保证检测精度的同时，具备了显著的计算效率提升，为嵌入式和边缘设备上的高效目标检测任务提供了有力的技术支持。

# 第五章 遥感飞机目标检测算法应用系统搭建

为了提升深度学习目标检测模型在实际应用中的可操作性与效率，并为未来机载或星载平台的模型部署提供可行的解决方案，本章将基于前一章中轻量化处理后的GDA-YOLO模型，探讨其在嵌入式设备上的部署。通过在NVIDIA平台上应用TensorRT推理优化技术，本章进一步提升了遥感图像中飞机目标检测的性能。同时，本章还设计并实现了一个用户友好的遥感图像飞机目标检测系统，旨在优化用户体验，扩展模型的实际应用范围，并为在不同应用场景中的推广提供可靠的技术支持。

## 5.1 应用系统整体设计

本系统的设计由硬件和软件两大部分组成，通过将深度学习模型部署在嵌入式平台上，结合图形用户界面，系统能够实时处理遥感图像并展示检测结果。

硬件系统的核心是Jetson Xavier NX嵌入式开发板。该平台具备高效的计算能力，适合进行深度学习推理和图像处理任务。系统通过嵌入式平台的摄像头或外部图像源（如图像库或视频流）实时采集遥感图像数据。采集到的图像数据被传输至Jetson Xavier NX平台，利用其搭载的Volta GPU和TensorRT加速器，进行高效的目标检测推理。Jetson Xavier NX的强大计算能力确保了模型推理过程的高效性，特别是在处理大规模图像数据时，能够满足实时性要求。

软件系统通过PyQt5构建的图形用户界面（GUI）提供操作界面，用户可以通过界面选择待检测的图像文件或实时视频流进行目标检测。在软件系统中，训练好的深度学习模型被部署到Jetson Xavier NX开发板上，进行目标检测任务。界面展示了目标检测的结果，包括目标的位置、类别以及置信度信息。用户通过该界面能够查看检测结果并进行相应操作，如保存结果或继续选择不同图像进行检测。软件系统不仅支持静态图像的处理，还能够实时处理视频流中的目标检测任务。

图5-1展示了本系统的整体架构。本系统的工作流程包括图像采集、模型部署、模型加速和可视化展示四个主要环节。首先，系统通过嵌入式平台的摄像头或外部图像源采集遥感图像数据，并将其传输至Jetson Xavier NX开发板进行处理。随后，训练好的目标检测模型被部署至嵌入式平台，并利用其高效计算能力与TensorRT加速技术进行优化推理，以提升检测速度和精度。最终，检测结果通过可视化界面直观展示，呈现目标的类别和数量信息，便于用户分析与后续操作。

图5-1 系统整体架构图

## 5.2 嵌入式计算平台部署

### 5.2.1 硬件平台介绍

随着深度学习技术的不断发展，传统嵌入式平台在应对复杂的深度学习模型时面临着诸多瓶颈。深度学习模型，尤其是卷积神经网络CNN等对计算要求高的模型，通常需要强大的计算资源来进行推理。然而，许多传统嵌入式平台的计算能力有限，在处理器性能、内存容量以及存储空间等方面存在明显的不足，难以满足计算密集型任务的需求。此外，传统平台的开发工具和优化库在高效推理方面表现乏力，限制了模型的部署效率。

为了解决这些问题，专为深度学习设计的嵌入式平台应运而生。NVIDIA Jetson系列平台专为高效深度学习推理和边缘计算设计，在高性能计算与低功耗之间实现了出色的平衡。Jetson系列涵盖了多个版本，包括Jetson Nano、Jetson TX2、Jetson Xavier NX及Jetson AGX Xavier，能够灵活满足不同应用场景的需求。其中，Jetson Xavier NX以其强大的计算能力和紧凑的尺寸在边缘计算和实时目标检测等领域表现尤为突出。

Jetson Xavier NX搭载了6核心的NVIDIA Carmel ARM v8.2 64位处理器，结合384个Volta GPU核心和48个Tensor Core，为深度学习推理提供了卓越的硬件支持。这些Tensor Core能够大幅加速大规模矩阵运算和卷积操作，极大提升了深度学习任务的处理效率。其硬件性能使其能够支持复杂计算任务，尤其适合实时处理大量数据的应用场景。在内存和存储方面，Jetson Xavier NX配备了8GB的LPDDR4x内存和16GB eMMC存储。LPDDR4x内存兼具低功耗和高带宽的优势，能够快速处理和传输深度学习任务中的大规模数据。同时，16GB eMMC存储为操作系统、应用程序和数据存储提供了充足的空间。Jetson Xavier NX的计算能力最高可达21 TOPS（万亿次操作每秒），并能在10瓦至15瓦的功耗范围内高效运行，充分满足边缘设备对低功耗和高效计算的需求。这种高性能低功耗的特性，使其成为遥感飞机目标检测等高性能应用的理想平台，可广泛应用于无人机、智能监控和自动驾驶等领域。此外，Jetson Xavier NX还支持NVIDIA JetPack SDK，提供包括CUDA、cuDNN、TensorRT等在内的硬件加速库，显著提升了深度学习模型的推理速度，并兼容主流的深度学习框架如PyTorch和TensorFlow，方便开发者快速部署优化已有模型。其优化的工具链和丰富的软件生态使得深度学习模型的嵌入式部署更加高效。结合其硬件性能和开发生态优势，Jetson Xavier NX成为支持遥感飞机目标检测系统嵌入式部署的理想平台。因此，本文选择Jetson Xavier NX作为实验部署平台。

 

（a）开发板核心计算板 （b）开发板外观

图5-2 Nvidia Jetson Xavier NX开发板

图5-3 Nvidia Jetson Xaiver NX开发板主界面信息

### 5.2.2 开发环境配置

为了满足嵌入式硬件端的应用需求，本研究在Jetson Xavier NX开发板上搭建了完整的开发环境，为图像处理与目标检测等任务提供支持。开发环境的搭建过程主要包括操作系统安装、基础开发组件的配置以及推理引擎的优化等步骤。

首先，在硬件方面准备了NVIDIA Jetson Xavier NX开发板、HDMI线、显示器、键盘和鼠标等设备，以及一台安装了Ubuntu操作系统的PC用于辅助刷机和环境配置。开发环境搭建的第一步是操作系统安装，选用NVIDIA官方提供的一体化安装工具JetPack SDK，JetPack集成了操作系统镜像、驱动程序以及CUDA、cuDNN、TensorRT等开发组件。本研究选用了JetPack 5.1.4版本，通过PC端的SDK Manager工具将系统镜像刷入开发板。在刷机过程中，需将开发板进入Recovery模式，并通过USB数据线将其与PC连接。随后，按照SDK Manager的安装向导完成操作系统及相关组件的安装。

完成系统安装后，对嵌入式平台的开发组件进行了进一步配置。首先，通过命令更新系统并安装了基本工具，包括Python解释器和OpenCV库等。接着，根据JetPack的版本需求安装了CUDA、cuDNN、TensorRT、OpenCV和VPI等组件。本研究使用的组件版本分别为CUDA 11.4.315、cuDNN 8.6.0.166、TensorRT 8.5.2.2、OpenCV 4.5.4和VPI 2.4.8。安装完成后，通过运行相关命令对组件的版本和功能进行了验证，例如通过nvcc --version检查CUDA的版本，通过Python脚本验证OpenCV和PyTorch的安装情况，以确保其兼容性和稳定性。

在深度学习框架的选择上，根据JetPack版本，安装了适配的PyTorch和Torchvision库，版本分别为PyTorch 2.1.0和Torchvision 0.16.2。为了方便开发和管理环境，本研究通过 Python 虚拟环境工具创建了独立的开发环境，使用Python 3.8作为虚拟环境的运行版本。同时，安装了相关的依赖包并通过环境信息打印进一步验证了开发环境的正确性。

为了进一步提高模型的推理效率，本研究引入了NVIDIA TensorRT推理引擎。TensorRT是一种基于CUDA的优化工具，可显著降低神经网络推理的延迟并提高吞吐量。推理加速的流程包括使用TensorRT的trtexec工具将模型转换为TensorRT引擎文件，并启用多流执行以提升推理性能，开发板所使用的组件版本信息如图所示。

图 5-4 NVIDIA Jetson Xavier NX 开发板组件相关版本信息

### 5.2.3 TensorRT加速处理

（1）网络层及张量的融合

TensorRT对深度学习模型的优化主要通过减少计算资源占用和内存访问，从而加速模型的推理过程。在这一过程中，网络层和张量的融合是最为关键的技术之一。图5-5为TensorRT网络层与张量融合优化示意图，具体来说，TensorRT通过合并多个相邻操作，减少不必要的计算步骤和中间数据存储，显著提高了计算效率。首先，TensorRT通过对模型进行解析与优化，识别并删除冗余操作以及无用的输出层，从而简化了模型结构。在处理相邻网络层时，如卷积层（Conv）、批归一化层（BN）和激活层（ReLU），TensorRT会进行垂直融合，将这些操作合并为一个计算步骤，减少计算过程中的中间步骤和内存访问，显著提高推理速度，如图5-5（b）所示。与此同时，对于具有相似功能或结构的层，TensorRT还进行横向融合，特别是多个相同类型的卷积模块或操作，TensorRT通过将这些模块合并，进一步简化计算路径，并提升整体效率，如图5-5（c）所示。此外，TensorRT对Concat操作进行了优化，省略了不必要的拼接步骤，或将Concat操作与后续计算步骤融合，从而减少了内存消耗和计算开销，如图5-5（d）所示。通过这一系列优化策略，TensorRT不仅提高了内存利用率，还加速了模型的推理过程，最终使得深度学习模型能够在嵌入式平台上实现高效的实时推理。

（a）原始网络架构示意图 （b）垂直融合后的网络架构示意图

（c）横向融合后的网络架构示意图 （d）Concat操作优化后的网络架构示意图

图5-5 TensorRT网络层与张量融合优化示意图

1.  低精度数据类型推理

除了对网络结构进行合并优化，TensorRT还支持低精度数据类型推理，尤其是将模型的计算精度从FP32（单精度浮点）降低到FP16（半精度浮点）。在深度学习模型的训练阶段，通常使用FP32精度，因为训练过程中需要进行大量的反向传播和参数更新，对数值的精度要求较高。图5-6展示了FP32与FP16的符号位表示。

图5-6 FP32与FP16的符号位表示

FP32数据类型在内存中的结构为4字节，其中31位为符号位，23至30位为指数位，0至22位为小数位。然而，在模型推理阶段，尽管使用FP32能够保证较高的精度，但它同时消耗更多的存储和计算资源。为了提高推理效率，TensorRT支持采用FP16数据类型进行推理。FP16数据类型的内存结构为2字节，其中15位为符号位，10至14位为指数位，0至9位为小数位。通过将计算精度降低为FP16，可以减少每次运算的数据位数，从而降低内存带宽的需求和计算负载。

TensorRT的低精度推理不会对模型的精度产生显著影响，尤其是对于深度神经网络（DNN）这种具有较强容错性的模型。通过FP16精度推理，TensorRT能够在保持较小精度损失的同时，显著提升推理速度。对于实时目标检测任务，FP16精度的推理尤其重要，它不仅能显著提升推理吞吐量，还能降低内存消耗和功耗，更加适应嵌入式平台或资源受限环境下的高效推理需求。

1.  算法部署流程

图5-7 算法部署流程

图5-7为算法部署流程，为了在Jetson Xavier NX平台上实现遥感飞机目标检测模型的加速推理，首先需要将训练好的PyTorch模型的权重文件从开发环境迁移至Jetson Xavier NX设备。这些权重文件通常以.pt格式保存，迁移过程可以通过SCP工具或直接将文件拷贝到开发板的存储设备中完成。

在迁移完成后，使用PyTorch提供的工具将训练好的PyTorch模型转换为ONNX格式。ONNX（Open Neural Network Exchange）是一个开源且框架无关的模型格式，能够与多种深度学习框架兼容，并可与TensorRT进行无缝对接。通过将PyTorch模型转换为ONNX格式，可以使得TensorRT能够识别并进一步优化该模型。

转换得到的ONNX模型可以使用TensorRT的trtexec工具进行处理，生成对应的TensorRT引擎文件（.engine）。在此过程中，可以根据Jetson Xavier NX硬件平台的特点选择不同的优化选项，如是否启用FP16精度推理，或是否进行层融合等。TensorRT将通过这些优化选项对模型进行加速优化，以适应嵌入式设备的计算资源和性能需求。

最后，将生成的TensorRT引擎文件部署至Jetson Xavier NX平台，并通过TensorRT的推理接口加载引擎文件进行推理。在推理过程中，要设置输入输出数据、执行推理并获取推理结果。通过这一系列步骤，遥感飞机目标检测模型能够在Jetson Xavier NX平台上高效、实时地进行推理，充分满足嵌入式平台对推理速度、计算资源和功耗的要求。图5-8展示了TensorRT模型构建过程。

图5-8 TensorRT模型构建过程

### 5.2.4 加速效果对比

为了验证本文模型（即轻量化处理后的GDA-YOLO）在Jetson Xavier NX平台上应用TensorRT进行推理加速的效果，本文对比了原始YOLOv8n模型与本文模型在PyTorch环境下的推理结果以及在TensorRT加速下的表现。具体实验结果如表5-1所示。

表5-1 不同推理平台下模型性能对比

|     |     |     |     |     |     |     |     |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Model | 推理<br><br>平台 | 数据<br><br>精度 | Latency<br><br>(ms) | Precision | Recall | mAP50 | mAP50-95 |
| YOLOv8n | PyTorch | FP32 | 34.2 | 81.0% | 78.8% | 84.6% | 63.2% |
| 本文模型 | PyTorch | FP32 | 22.3 | 83.2% | 81.3% | 88.1% | 65.0% |
| 本文模型 | TensoRT | FP32 | 18.2 | 85.2% | 78.8% | 87.4% | 64.4% |
| 本文模型 | TensoRT | FP16 | 15.4 | 85.3% | 78.7% | 87.4% | 64.4% |

从表中数据可以发现，本文模型在PyTorch平台下的推理时间为22.3ms，而在TensorRT平台上缩短至18.2ms，推理速度提升约为18.4%。进一步采用FP16半精度推理后，推理时间降至15.4ms，相较于PyTorch平台速度提升了30.9%。尽管TensorRT加速后模型精度略有波动，但推理速度的显著提升仍能表明，TensorRT通过网络层融合、张量优化和低精度推理等手段能够有效减轻硬件负担，进一步提高了推理效率。

最后，与YOLOv8n模型在PyTorch平台下的推理时间（34.2ms）相比，本文模型（TensorRT，FP16）的推理时间减少了55.0%。同时，本文模型在精度方面也明显优于YOLOv8n模型，精确率、mAP50和mAP50-95分别提升了4.3%、2.8%、1.2%。总体而言，本文模型通过网络结构优化、轻量化处理和TensorRT加速，显著提升了推理效率，同时保持了较高的精度，验证了其在实际应用中的优越性。

## 5.3 检测系统界面设计

### 5.3.1 系统开发环境

本检测系统的开发环境主要基于PyCharm和PyQt5，这两种工具为系统的功能实现和界面设计提供了强大的支持。

PyCharm是一款由JetBrains开发的集成开发环境（IDE），专为Python编程语言设计，它提供了智能的代码补全、语法高亮、错误检查和调试功能，使得开发过程更加高效和精确。在本项目中，PyCharm被用作主要的开发工具，帮助开发者编写和调Python代码，特别是在处理图像数据、调用深度学习模型以及集成各种功能模块时，它的强大功能大大提升了开发效率。

PyQt5是一个基于Qt框架的Python图形用户界面开发工具，它为开发者提供了丰富的控件和布局管理器，能够快速构建功能强大且美观的桌面应用程序。PyQt5支持多平台开发，能够在Windows、macOS和Linux等操作系统上运行，这使得本检测系统具备了良好的跨平台兼容性。在界面设计上，PyQt5提供了多种控件和布局管理器，使得开发者能够方便地设计响应式布局，并创建直观易用的用户界面。此外，PyQt5支持事件驱动编程，能够响应用户的各种操作，如鼠标点击、键盘输入等，确保界面的流畅交互。

### 5.3.2 系统界面设计

本检测系统的界面设计采用模块化布局，以确保各个功能区域的独立性和高效性。系统的主要界面通过使用PyQt5提供的控件，如QPushButton、QLabel等，来构建各个功能模块的交互界面。具体来说，界面设计的关键在于合理的控件定义和布局，确保用户能够方便地操作系统并获取所需信息。

在功能选择区、结果展示区和数据统计区的实现过程中，PyQt5提供的控件起到了核心作用。表5-2和表5-3是系统界面中各控件的设置及其功能。

表5-2 QPushButton控件定义设置

|     |     |     |     |
| --- | --- | --- | --- |
| 控件序号 | 控件类别 | 控件名称 | 控件功能 |
| 1   | QPushButton | model_button | 选择模型权重文件 |
| 2   | QPushButton | image_button | 导入图片检测 |
| 3   | QPushButton | video_button | 导入视频检测 |
| 4   | QPushButton | realtime_button | 开启摄像头实时检测 |
| 5   | QPushButton | start_button | 启动检测任务 |
| 6   | QPushButton | stop_button | 停止检测任务 |
| 7   | QPushButton | save_button | 保存检测结果 |
| 8   | QPushButton | exit_button | 退出系统 |

表5-3 QLabel控件定义设置

|     |     |     |     |
| --- | --- | --- | --- |
| 控件序号 | 控件类别 | 控件名称 | 控件功能 |
| 1   | QLabel | label_1 | 显示待检测图像 |
| 2   | QLabel | label_2 | 显示检测结果图像 |
| 3   | QLabel | label_3 | 显示目标检测统计信息 |
| 4   | QLabel | label_4 | 显示系统名称 |

这些控件通过适当的布局管理器（如QVBoxLayout、QHBoxLayout）被安排在界面的各个区域。QPushButton控件用于实现用户操作的按钮，如选择权重文件、启动检测、停止检测等。QLabel控件则用于显示图像、文本和其他信息。界面布局设计确保了各控件之间的合理间距和对齐，使得界面简洁明了，操作直观。系统的初始界面如图5-9所示。

图5-9 系统的初始界面

### 5.3.3 系统功能展示

本系统的功能展示部分主要涵盖了功能选择区、结果展示区和数据统计区的实现及其效果。通过模块化的界面设计，各个功能区被清晰地划分，并通过简洁直观的控件布局实现了系统操作的高效性与便捷性。

功能选择区包含了多种操作按钮，如“选择模型权重文件”、“图片检测”、“视频检测”、“实时检测”以及“启动检测任务”、“停止检测任务”等按钮。这些功能按操作流程的先后顺序排列，首先通过“选择模型权重文件”加载深度学习模型的权重文件，接着选择检测模式，最后通过启动或停止检测任务进行目标检测。检测任务启动后，结果将在结果展示区中自动更新。

结果展示区包括两个图像显示区域，分别用于展示待检测图像和检测结果图像。待检测图像通过点击左侧区域加载，而检测结果图像则通过系统自动生成，右侧显示检测框及其相关信息，包括目标类别、位置与置信度等。图像显示区域保证了图像在窗口中居中，并可自动调整缩放比例以适应窗口大小，确保检测效果清晰可见。

此外，检测结果的数量统计信息会实时更新，并显示在数据统计区。该区域通过文本框动态展示当前检测到的目标数量，为检测过程提供实时数据支持。这一设计便于对检测任务进行有效的跟踪与评估，从而能够及时调整策略以优化检测效果。

图5-10展示了本系统的整体运行效果，采用Nvidia Jetson Xaiver NX开发板作为模型推理硬件平台，通过图形用户界面获取待检测图像并实现飞机目标检测，并将结果显示在对应框。图5-11为系统实际检测结果，左侧是待检测图像，右侧是检测后的结果图像，并准确标出了检测到的飞机目标数量。

图5-10 系统的整体运行效果

图5-11 系统检测结果

## 5.4 本章小结

本章重点介绍了基于轻量化处理后的GDA-YOLO模型的遥感飞机目标检测系统的应用搭建及部署。首先，在硬件方面，选择了NVIDIA Jetson Xavier NX平台作为嵌入式计算平台，结合其强大的计算能力和高效的TensorRT推理优化技术，显著提升了模型在遥感图像中的目标检测性能。通过在Jetson Xavier NX平台上进行模型部署，实现了基于遥感图像的飞机目标检测与细粒度识别。在软件系统方面，本章设计并实现了一个图形用户界面（GUI）系统，结合深度学习模型与嵌入式平台，实现了实时图像采集、目标检测推理及结果展示的功能。用户可以通过界面实时选择待检测图像或视频流，查看目标检测结果，进一步优化了用户体验。

此外，本章详细阐述了在Jetson Xavier NX平台上进行模型推理加速的过程。通过TensorRT的优化，包括网络层融合、张量优化和低精度推理等手段，显著提升了模型的推理效率，确保了实时性和计算资源的高效利用。实验结果表明，相较于PyTorch平台下，经过TensorRT优化后的模型推理时间22.3ms降至15.4ms，推理速度提升了30.9%。

综上所述，本章成功搭建了一个高效的遥感图像飞机目标检测系统，并通过嵌入式平台部署与推理优化，实现了对大规模图像数据的实时处理，为未来在机载或星载平台上的模型部署提供了可行的解决方案。

# 总结与展望

## 总结

本文针对遥感图像中飞机目标检测与细粒度识别的高精度和实时性需求，提出了一种基于深度学习的算法优化框架，并成功将其部署在嵌入式平台上。主要研究成果如下：

（1）算法优化与性能提升：本文提出了一种融合全局信息与双域注意力机制的检测与细粒度识别算法（GDA-YOLO）。通过引入全局最大池化层增强模型对全局信息的捕捉能力，减少背景干扰；通过双域注意力机制提升模型对飞机细粒度特征的敏感性；优化下采样模块以保留小目标细节信息；并引入改进的PIoU损失函数，提升模型的收敛速度和检测精度。本文在公开数据集MAR20和NWPU VHR-10上进行了实验，结果表明，与原始YOLOv8n相比，该算法在MAR20数据集上精确率、召回率、mAP50以及mAP50-95分别提高了3.3%，2.6%，3.2%和2.6%，在NWPU VHR-10数据集上分别提高了5%，5.1%，2.5%和0.3%。同时，模型的参数量和运算量分别降低了6.6%和3.7%，为高效、准确地检测飞机目标提供了可靠的解决方案。

（2）模型轻量化与效率提升：为满足嵌入式平台对实时目标检测的要求，本文在GDA-YOLO模型上采用了结构化剪枝与知识蒸馏相结合的方法，有效降低了模型的冗余参数和计算复杂度，同时恢复并提升了检测精度。通过预处理、依赖图构建与LAMP评分实现自动化剪枝，通过结合二元分类蒸馏损失、基于IoU的定位蒸馏损失与GDA-YOLO原始损失函数，优化教师模型向剪枝后的轻量化学生模型的知识迁移，成功弥补了剪枝带来的精度损失。实验结果表明，剪枝率设置为3.5时，模型参数量从2.81M降至0.38M，计算复杂度从7.8 GFLOPs降至2.2 GFLOPs，推理速度从936.5 FPS提升至1460.6 FPS，提升了约55.9%。经过知识蒸馏后，模型的mAP50进一步提升至88.2%，mAP50-95提升至65.4%，几乎完全弥补了剪枝带来的精度下降。

（3）嵌入式平台部署与系统实现：本文基于轻量化处理后的GDA-YOLO模型的遥感飞机目标检测系统的应用搭建及部署。首先，在硬件方面，选择了NVIDIA Jetson Xavier NX平台作为嵌入式计算平台，详细阐述了模型部署过程以及网络层融合、张量优化和低精度推理等TensorRT推理优化技术原理，实验结果表明，相较于PyTorch平台下，经过TensorRT优化后的模型推理时间22.3ms降至15.4ms，推理速度提升了30.9%。在软件系统方面，本章设计并实现了一个图形用户界面（GUI）系统，结合深度学习模型与嵌入式平台，实现了实时图像采集、目标检测推理及结果展示的功能。用户可以通过界面实时选择待检测图像或视频流，查看目标检测结果，进一步优化了用户体验。

本文的创新与特色主要体现在以下方面：

（1）针对遥感图像中飞机目标检测的特殊需求，提出了一种全新的算法（GDA-YOLO）。该算法通过设计并引入基于全局信息的快速空间金字塔池化模块，提供全局特征概览，从而帮助模型在复杂环境中更好地区分目标与背景；同时，提出的双域注意力机制通过融合空间域与通道域信息，增强了模型对飞机细粒度特征的敏感性；此外，采用并行路径改进下采样模块，并引入PIoU损失函数，通过自适应惩罚因子加速模型收敛，提高了对小目标飞机的识别能力和预测框的回归效率，为高效、准确地检测飞机目标提供了可靠的解决方案。

（2）针对嵌入式平台计算资源受限、实时性要求高的挑战，提出了一种高效的模型轻量化策略。该策略通过构建依赖图与LAMP重要性评估体系，实现了自动化的结构化剪枝，有效降低了模型的参数量和计算复杂度，显著提升了推理速度。与此同时，通过结合二元分类蒸馏损失、基于IoU的定位蒸馏损失与GDA-YOLO原始损失函数，优化教师模型向剪枝后的轻量化学生模型的知识迁移，成功弥补了剪枝带来的精度损失。不仅为遥感图像目标检测模型在资源受限场景下的高效部署提供了解决方案，也为深度学习模型轻量化技术的发展开辟了新的路径。

## 展望

本文为遥感图像中飞机目标检测与细粒度识别提供了一种高效、精准的解决方案，但在未来的研究中仍有进一步改进的空间，尤其是在以下几个方面：

（1）当前的研究主要集中在单一模态的光学遥感图像上，未来可以探索多模态数据（如光学图像、雷达图像、红外图像等）的融合。通过结合不同模态数据的优势，可以进一步提升模型在复杂环境下的检测精度和鲁棒性。例如，雷达图像对天气条件不敏感，红外图像可以提供温度信息，这些信息可以与光学图像结合，以增强目标检测的可靠性。

（2）尽管本文通过轻量化框架显著提升了模型的推理速度，但在实际应用中，仍需进一步优化模型架构和推理策略，以在保证实时性的同时，进一步提升检测精度。例如，可以探索更高效的网络结构设计，减少冗余计算，同时引入更先进的优化算法，以提高模型的收敛速度和精度。

（3）本文搭建的遥感图像飞机目标检测系统在嵌入式平台上表现出色，但其实际应用范围仍需进一步拓展。未来可以将该系统集成到更广泛的遥感应用中，如无人机侦察、卫星遥感监测等，探索其在不同应用场景下的性能和适用性。此外，还可以进一步优化系统的用户界面和交互设计，提升系统的易用性和用户体验，使其能够更好地满足实际应用需求。

# 参考文献

\[1\] Uijlings J R, Van De Sande K E, Gevers T, et al. Selective search for object recognition\[J\]. International Journal of Computer Vision, 2013, 104: 154-171.

\[2\] Dalal N, Triggs B. Histograms of oriented gradients for human detection\[C\]. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2005: 886-893.

\[3\] Ng P C, Henikoff S. SIFT: Predicting amino acid changes that affect protein function\[J\]. Nucleic Acids Research, 2003, 31(13): 3812-3814.

\[4\] Bay H, Tuytelaars T, Gool L V. SURF: Speeded up robust features\[C\]. Proceedings of the European Conference on Computer Vision, 2006: 404-417.

\[5\] Maulik U, Chakraborty D. Remote sensing image classification: A survey of support-vector-machine-based advanced techniques\[J\]. IEEE Geoscience and Remote Sensing Magazine, 2017, 5(1): 33-52.

\[6\] Chirici G, Mura M, Mcinerney D, et al. A meta-analysis and review of the literature on the k-nearest neighbors technique for forestry applications that use remotely sensed data\[J\]. Remote Sensing of Environment, 2016, 176: 282-294.

\[7\] Sheykhmousa M, Mahdianpari M, Ghanbari H, et al. Support vector machine versus random forest for remote sensing image classification: A meta-analysis and systematic review\[J\]. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2020, 13: 6308-6325.

\[8\] Kumar S. Discriminative random fields: A discriminative framework for contextual interaction in classification\[C\]. Proceedings of the IEEE International Conference on Computer Vision, 2003: 1150-1157.

\[9\] Ramirez I, Sprechmann P, Sapiro G. Classification and clustering via dictionary learning with structured incoherence and shared features\[C\]. Proceedings of the IEEE Computer Conference on Computer Vision and Pattern Recognition, 2010: 3501-3508.

\[10\] Viola P, Jones M. Rapid object detection using a boosted cascade of simple features\[C\]. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2001: 1: I-I.

\[11\] Girshick R, Donahue J, Darrell T, et al. Rich feature hierarchies for accurate object detection and semantic segmentation\[C\]. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2014: 580-587.

\[12\] Girshick R. Fast R-CNN\[C\]. Proceedings of the IEEE International Conference on Computer Vision, 2015: 1440-1448.

\[13\] Ren S, He K, Girshick R, et al. Faster R-CNN: Towards real-time object detection with region proposal networks\[J\]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 39(6): 1137-1149.

\[14\] He K, Gkioxari G, Dollár P, et al. Mask R-CNN\[C\]. Proceedings of the IEEE International Conference on Computer Vision, 2017: 2961-2969.

\[15\] Cai Z, Vasconcelos N. Cascade R-CNN: Delving into high quality object detection\[C\]. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018: 6154-6162.

\[16\] Lin T Y, Dollár P, Girshick R, et al. Feature pyramid networks for object detection\[C\]. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017: 2117-2125.

\[17\] Ghiasi G, Lin T Y, Le Q V. NAS-FPN: Learning scalable feature pyramid architecture for object detection\[C\]. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019: 7036-7045.

\[18\] Tan M, Pang R, Le Q V. EfficientDet: Scalable and efficient object detection\[C\]. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020: 10781-10790.

\[19\] Sun P, Zhang R, Jiang Y, et al. Sparse R-CNN: End-to-end object detection with learnable proposals\[C\]. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021: 14454-14463.

\[20\] Liu Z, Lin Y, Cao Y, et al. Swin transformer: Hierarchical vision transformer using shifted windows\[C\]. Proceedings of the IEEE/CVF International Conference on Computer Vision, 2021: 10012-10022.

\[21\] Redmon J, Divvala S, Girshick R, et al. You only look once: Unified, real-time object detection\[C\]. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 779-788.

\[22\] Redmon J, Farhadi A. YOLO9000: Better, faster, stronger\[C\]. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017: 7263-7271.

\[23\] Redmon J, Farhadi A. YOLOv3: An incremental improvement\[EB/OL\]. (2018-04-09)\[2025-03-07\]. https://doi.org/10.48550/arXiv.1804.02767.

\[24\] Bochkovskiy A, Wang C-Y, Liao H-Y M. YOLOv4: Optimal speed and accuracy of object detection\[EB/OL\]. (2020-04-22)\[2025-03-07\]. https://doi.org/10.48550/arXiv.2004.10934.

\[25\] JOCHER G. YOLOv5 by ultralytics\[EB/OL\]. (2022-11-22)［2025-03-07］. https://github. com/ultralytics/yolov5.

\[26\] Li C, Li L, Geng Y, et al. YOLOv6 v3.0: A full-scale reloading\[EB/OL\]. (2023-01-13)\[2025-03-07\]. https://doi.org/10.48550/arXiv.2301.05586.

\[27\] Wang C Y, Bochkovskiy A, Liao H Y M. YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors\[C\]. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7464-7475.

\[28\] Jocher G， Chaurasia A， Qiu J. Ultralytics YOLOv8\[EB/OL\]. (2024-1-10)［2025-03-07］. https：//github. com/ultralytics/ultralytics.

\[29\] Wang C Y, Yeh I H, Mark Liao H Y. Yolov9: Learning what you want to learn using programmable gradient information\[C\]. Proceedings of the European Conference on Computer Vision, 2024: 1-21.

\[30\] Wang A, Chen H, Liu L, et al. Yolov10: Real-time end-to-end object detection\[J\]. Advances in Neural Information Processing Systems, 2025, 37: 107984-108011.

\[31\] Glenn J, Jing Q. Ultralytics YOLO11\[EB/OL\]. (2024-09-30)\[2025-03-07\]. https://github.com/ultralytics/ultralytics .

\[32\] Tian Y, Ye Q, Doermann D. YOLOv12: Attention-centric real-time object detectors\[EB/OL\]. (2025-02-19)\[2025-03-07\]. https://arxiv.org/abs/2502.12524 .

\[33\] Liu W, Anguelov D, Erhan D, et al. SSD: Single shot multibox detector\[C\]. Proceedings of the European Conference on Computer Vision, 2016: 21-37.

\[34\] Fu C Y, Liu W, Ranga A, et al. DSSD: Deconvolutional single shot detector\[EB/OL\]. (2017-01-23)\[2025-03-07\]. https://doi.org/10.48550/arXiv.1701.06659 .

\[35\] Li Z, Yang L, Zhou F. FSSD: Feature fusion single shot multibox detector\[EB/OL\]. (2017-12-04)\[2025-03-07\]. https://doi.org/10.48550/arXiv.1712.00960 .

\[36\] Lin T Y, Goyal P, Girshick R, et al. Focal loss for dense object detection\[C\]. Proceedings of the IEEE International Conference on Computer Vision, 2017: 2980-2988.

\[37\] Law H, Deng J. Cornernet: Detecting objects as paired keypoints\[C\]. Proceedings of the European Conference on Computer Vision, 2018: 734-750.

\[38\] Duan K, Bai S, Xie L, et al. Centernet: Keypoint triplets for object detection\[C\]. Proceedings of the IEEE/CVF International Conference on Computer Vision, 2019: 6569-6578.

\[39\] Carion N, Massa F, Synnaeve G, et al. End-to-end object detection with transformers\[C\]. Proceedings of the European Conference on Computer Vision, 2020: 213-229.

\[40\] Zhu X, Su W, Lu L, et al. Deformable DETR: Deformable transformers for end-to-end object detection\[EB/OL\]. (2020-10-08)\[2025-03-07\]. https://doi.org/10.48550/arXiv.2010.04159.

\[41\] Zhao Y, Lv W, Xu S, et al. DETRs beat YOLOs on real-time object detection\[C\]. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024: 16965-16974.

\[42\] Xu C, Duan H. Artificial bee colony (ABC) optimized edge potential function (EPF) approach to target recognition for low-altitude aircraft\[J\]. Pattern Recognition Letters, 2010, 31(13): 1759-1772.

\[43\] Wu Q, Sun H, Sun X, et al. Aircraft recognition in high-resolution optical satellite remote sensing images\[J\]. IEEE Geoscience and Remote Sensing Letters, 2015, 12: 112-116.

\[44\] Lin Y, He H, Yin Z, et al. Rotation-invariant object detection in remote sensing images based on radial-gradient angle\[J\]. IEEE Geoscience and Remote Sensing Letters, 2015, 12: 746-750.

\[45\] Diao W, Sun X, Zheng X, et al. Efficient saliency-based object detection in remote sensing images using deep belief networks\[J\]. IEEE Geoscience and Remote Sensing Letters, 2016, 13: 137-141.

\[46\] 何燕. 基于航天遥感图像的飞机目标识别\[D\]. 吉林大学, 2011.

\[47\] Wu Q, Feng D, Cao C, et al. Improved mask R-CNN for aircraft detection in remote sensing images\[J\]. Sensors, 2021, 21(8): 2618.

\[48\] Wang B, Zhou Y, Zhang H, et al. An aircraft target detection method based on regional convolutional neural network for remote sensing images\[C\]. 2019 IEEE 9th International Conference on Electronics Information and Emergency Communication, 2019: 474-478.

\[49\] Liu Z, Gao Y, Du Q, et al. YOLO-extract: Improved yolov5 for aircraft object detection in remote sensing images\[J\]. IEEE Access, 2023, 11: 1742-1751.

\[50\] Zhao Y, Li J, Li W, et al. MS-IAF: Multi-scale information augmentation framework for aircraft detection\[J\]. Remote Sensing, 2022, 14(15): 3696.

\[51\] Zhang D, Zhao Z, Huang S. Investigation of aircraft target detection of remote sensing images based on the improved yolov5\[C\]. 2023 International Conference on Computer Applications Technology, 2023: 266-270.

\[52\] Zuo J, Xu G, Fu K, et al. Aircraft type recognition based on segmentation with deep convolutional neural networks\[J\]. IEEE Geoscience and Remote Sensing Letters, 2018, 15(2): 282-286.

\[53\] 曹旭, 邹焕新, 成飞, 等. 基于RHTC网络的飞机目标检测与精细识别\[J\]. 系统工程与电子技术, 2021, 43(12): 3439-3451.

\[54\] 赵志恒. 基于深度学习的遥感图像飞机目标检测技术研究\[D\]. 中国民用航空飞行学院, 2024.

\[55\] Hubara I, Courbariaux M, Soudry D, et al. Quantized neural networks: Training neural networks with low precision weights and activations\[J\]. Journal of Machine Learning Research, 2018, 18(187): 1-30.

\[56\] Srivastava N, Hinton G, Krizhevsky A, et al. Dropout: A simple way to prevent neural networks from overfitting\[J\]. Journal of Machine Learning Research, 2014, 15(1): 1929-1955.

\[57\] Liu S, Qi L, Qin H, et al. Path aggregation network for instance segmentation\[C\]. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2018: 8759-8768.

\[58\] Ge Z, Liu S, Wang F, et al. YOLOX: Exceeding YOLO series in 2021\[EB/OL\]. (2021-08-06)\[2025-03-07\]. https://doi.org/10.48550/arXiv.2107.08430 .

\[59\] Zheng Z, Wang P, Liu W, et al. Distance-IoU loss: Faster and better learning for bounding box regression\[C\]. Proceedings of the AAAI conference on artificial intelligence. 2020, 34(07): 12993-13000.

\[60\] Wang Q, Wu B, Zhu P, et al. ECA-Net: Efficient channel attention for deep convolutional neural networks\[C\]. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020: 11534-11542.

\[61\] Zhu X, Cheng D, Zhang Z, et al. An empirical study of spatial attention mechanisms in deep networks\[C\]. Proceedings of the IEEE/CVF International Conference on Computer Vision, 2019: 6688-6697.

\[62\] Liu C, Wang K, Li Q, et al. Powerful-IoU: More straightforward and faster bounding box regression loss with a nonmonotonic focusing mechanism\[J\]. Neural Networks, 2024, 170: 276-284.

\[63\] 禹文奇, 程塨, 王美君, 等. MAR20: 遥感图像军用飞机目标识别数据集\[J\]. 遥感学报, 2023, 27(12): 2688-2696.

\[64\] Cheng G, Zhou P, Han J. Learning rotation-invariant convolutional neural networks for object detection in vhr optical remote sensing images\[J\]. IEEE Transactions on Geoscience and Remote Sensing, 2016, 54(12): 7405-7415.

\[65\] He K, Zhang X, Ren S, et al. Spatial pyramid pooling in deep convolutional networks for visual recognition\[J\]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2015, 37(9): 1904-1913.

\[66\] Chen L C, Papandreou G, Kokkinos I, et al. DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully sonnected CRFs\[J\]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 40: 834-848.

\[67\] Liu S, Huang D. Receptive field block net for accurate and fast object detection\[C\]. Proceedings of the European Conference on Computer Vision. 2018: 385-400.

\[68\] Woo S, Park J, Lee J Y, et al. CBAM: Convolutional block attention module\[C\]. Proceedings of the European Conference on Computer Vision. 2018: 3-19.

\[69\] Hou Q, Zhou D, Feng J. Coordinate attention for efficient mobile network design\[C\]. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021: 13713-13722.

\[70\] Huang H, Chen Z, Zou Y, et al. Channel prior convolutional attention for medical image segmentation\[J\]. Computers in Biology and Medicine, 2024, 178: 108784.

\[71\] Azad R, Niggemeier L, Hüttemann M, et al. Beyond self-attention: Deformable large kernel attention for medical image segmentation\[C\]. Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. 2024: 1287-1297.

\[72\] Ouyang D, He S, Zhang G, et al. Efficient multi-scale attention module with cross-spatial learning\[C\]. ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing, 2023: 1-5.

\[73\] Lau K W, Po L M, Rehman Y A U. Large separable kernel attention: Rethinking the large kernel attention design in cnn\[J\]. Expert Systems with Applications, 2024, 236: 121352.

\[74\] Zhang Q L, Yang Y. SA-Net: Shuffle attention for deep convolutional neural networks\[C\]. ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing, 2021: 2235-2239.

\[75\] Yang L, Zhang R Y, Li L, et al. SimAM: A simple, parameter-free attention module for convolutional neural networks\[C\]. Proceedings of the 38th International Conference on Machine Learning, 2021: 11863--11873.

\[76\] Misra D, Nalamada T, Arasanipalai A U, et al. Rotate to attend: Convolutional triplet attention module\[C\]. Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2021: 3139-3148.

\[77\] Wang C, He W, Nie Y, et al. Gold-YOLO: Efficient object detector via gather-and-distribute mechanism\[J\]. Advances in Neural Information Processing Systems, 2023, 36: 51094-51112.

\[78\] Zheng Z, Ye R, Wang P, et al. Localization distillation for dense object detection\[C\]. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022: 9407-9416.

\[79\] Li X, Wang W, Wu L, et al. Generalized focal loss: Learning qualified and distributed bounding boxes for dense object detection\[J\]. Advances in Neural Information Processing Systems, 2020, 33: 21002-21012.

\[80\] Yang L, Zhou X, Li X, et al. Bridging cross-task protocol inconsistency for distillation in dense object detection\[C\]. Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023: 17175-17184.

# 致谢

在本论文完成之际，我衷心感谢在攻读学位期间给予我指导和支持的所有人。

首先，我衷心感谢我的导师林珊玲讲师。林老师不仅在学术上给予了我细致入微的指导，还耐心倾听我的想法和困惑。她严谨的学术态度、渊博的知识和对科研的热情深深影响了我。在研究过程中，林老师多次为我提供宝贵的意见和建议，帮助我克服了诸多困难。她的支持和鼓励是我完成学业的重要动力。

我也要感谢实验室的各位老师，包括林志贤老师、林坚普老师和吕珊红老师。他们在我遇到技术难题时给予了及时的帮助，使我能够顺利推进研究工作。他们的专业知识和丰富的经验为我提供了宝贵的参考，让我在学术道路上受益匪浅。

此外，我要感谢我的企业导师蔡子丰、陈佳、宋慧娟和廖晓苏。在实践项目中，他们不仅提供了专业的技术指导，还让我对行业现状和发展趋势有了更深入的了解。他们的经验和见解极大地拓宽了我的视野，也为我今后的职业发展奠定了坚实的基础。

我还要感谢我的同门们，他们是我学术旅程中的伙伴和支持者。我们一起讨论学术问题，分享学习经验，互相鼓励。在实验室里度过的时光充满了欢乐和挑战，这些经历将成为我宝贵的回忆。

感谢我的家人。他们的理解和支持是我能够全身心投入学习和研究的重要保障。无论遇到什么困难，家人都始终给予我鼓励和信心。他们是我最坚实的后盾。

最后，感谢为评审本论文付出了辛勤劳动的全体专家学者，向你们致敬！

谢谢！

# 个人简历

张雪（1999-），女，汉族，福建福州人。

2018年9月-2022年6月，就读于福建农林大学，主修电子科学与技术专业，

获得工学学士学位。

2022年9月至今，在福州大学先进制造学院新一代电子信息技术（含量子技术等）专业学习，攻读专业硕士学位。

# 在学期间的研究成果及发表的学术论文