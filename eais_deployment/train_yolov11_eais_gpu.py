# -*- coding: utf-8 -*-
"""
YOLOv11 é˜¿é‡Œäº‘EAIS GPUè®­ç»ƒè„šæœ¬ - çº¢å¤–å°ç›®æ ‡æ£€æµ‹
é’ˆå¯¹é­”æ­ç¤¾åŒºé˜¿é‡Œäº‘å¼¹æ€§åŠ é€Ÿè®¡ç®—EAISå®ä¾‹ä¼˜åŒ–

@Project: CQ-09 æŒ‘æˆ˜æ¯
@Dataset: tiaozhanbei_datasets_final 
@Classes: 6 (drone, car, ship, bus, pedestrian, cyclist)
@Hardware: é˜¿é‡Œäº‘EAIS GPUå®ä¾‹
"""
import warnings
warnings.filterwarnings('ignore')
import torch
import os
import sys
from ultralytics import YOLO

def check_gpu_environment():
    """æ£€æŸ¥GPUç¯å¢ƒé…ç½®"""
    print("ğŸ” æ£€æŸ¥GPUç¯å¢ƒ...")
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
        return True
    else:
        print("âŒ æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
        return False

def optimize_gpu_settings():
    """ä¼˜åŒ–GPUè®¾ç½®"""
    if torch.cuda.is_available():
        # å¯ç”¨GPUä¼˜åŒ–
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        
        # æ¸…ç†GPUç¼“å­˜
        torch.cuda.empty_cache()
        
        print("âœ… GPUä¼˜åŒ–è®¾ç½®å·²å¯ç”¨")

def setup_training_environment():
    """è®¾ç½®è®­ç»ƒç¯å¢ƒ"""
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    os.makedirs('runs/train', exist_ok=True)
    os.makedirs('datasets', exist_ok=True)
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # å¼‚æ­¥GPUæ“ä½œ
    os.environ['OMP_NUM_THREADS'] = '8'       # CPUçº¿ç¨‹æ•°
    
    print("ğŸ“ è®­ç»ƒç¯å¢ƒå·²è®¾ç½®")

if __name__ == '__main__':
    print("ğŸš€ å¼€å§‹YOLOv11 é˜¿é‡Œäº‘EAIS GPUè®­ç»ƒ")
    print("=" * 60)
    
    # 1. æ£€æŸ¥GPUç¯å¢ƒ
    gpu_available = check_gpu_environment()
    
    # 2. ä¼˜åŒ–GPUè®¾ç½®
    optimize_gpu_settings()
    
    # 3. è®¾ç½®è®­ç»ƒç¯å¢ƒ
    setup_training_environment()
    
    # 4. åˆå§‹åŒ–YOLOv11æ¨¡å‹
    print("\nğŸ“¥ åŠ è½½YOLOv11xé¢„è®­ç»ƒæ¨¡å‹...")
    model = YOLO('yolo11x.pt')  # åˆ‡æ¢åˆ°xç‰ˆæœ¬
    
    # 5. é…ç½®è®­ç»ƒå‚æ•° - é’ˆå¯¹é˜¿é‡Œäº‘EAIS GPUä¼˜åŒ–
    print("\nğŸ“ é…ç½®è®­ç»ƒå‚æ•°...")
    
    # æ ¹æ®GPUå¯ç”¨æ€§è°ƒæ•´è®¾å¤‡å’Œæ‰¹æ¬¡å¤§å°
    if gpu_available:
        device = 'cuda'
        batch_size = 8  # ä¿®æ­£: xç‰ˆæœ¬æ¨¡å‹è¾ƒå¤§ï¼Œå¿…é¡»å‡å°æ‰¹æ¬¡å¤§å°ä»¥é˜²OOM
        workers = 8      # æ›´å¤šçš„æ•°æ®åŠ è½½çº¿ç¨‹
        amp = True       # å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
        print("ğŸš€ ä½¿ç”¨GPUè®­ç»ƒé…ç½® (YOLOv11x - å°æ‰¹æ¬¡)")
    else:
        device = 'cpu'
        batch_size = 4  # CPUæ¨¡å¼ä¸‹ä¹Ÿç›¸åº”å‡å°
        workers = 4
        amp = False
        print("âš ï¸ ä½¿ç”¨CPUè®­ç»ƒé…ç½®")
    
    training_args = {
        # æ•°æ®é…ç½®
        # ä½¿ç”¨æŒ‰åºåˆ—åˆ’åˆ†çš„ã€æ›´ç§‘å­¦çš„æ•°æ®é›†é…ç½®æ–‡ä»¶
        'data': 'configs/dataset_configs/tiaozhanbei_sequenced_x.yaml', 
        'imgsz': 640,                      # æ ‡å‡†å›¾åƒå°ºå¯¸
        'epochs': 100,                     # æ›´å¤šè®­ç»ƒè½®æ¬¡
        'batch': batch_size,
        'workers': workers,
        
        # è®¾å¤‡é…ç½®
        'device': device,
        'amp': amp,                        # è‡ªåŠ¨æ··åˆç²¾åº¦
        
        # ä¼˜åŒ–å™¨é…ç½®
        'optimizer': 'AdamW',
        'lr0': 0.01,                       # åˆå§‹å­¦ä¹ ç‡
        'lrf': 0.01,                       # æœ€ç»ˆå­¦ä¹ ç‡å› å­
        'momentum': 0.937,
        'weight_decay': 0.0005,
        'warmup_epochs': 3,                # çƒ­èº«è½®æ•°
        'warmup_momentum': 0.8,
        'warmup_bias_lr': 0.1,
        
        # æŸå¤±å‡½æ•°æƒé‡
        'box': 7.5,                        # boxæŸå¤±æƒé‡
        'cls': 0.5,                        # åˆ†ç±»æŸå¤±æƒé‡
        'dfl': 1.5,                        # DFLæŸå¤±æƒé‡
        
        # æ•°æ®å¢å¼º
        'hsv_h': 0.015,                    # HSVè‰²è°ƒå¢å¼º
        'hsv_s': 0.7,                      # HSVé¥±å’Œåº¦å¢å¼º
        'hsv_v': 0.4,                      # HSVæ˜åº¦å¢å¼º
        'degrees': 0.0,                    # æ—‹è½¬å¢å¼º
        'translate': 0.1,                  # å¹³ç§»å¢å¼º
        'scale': 0.5,                      # ç¼©æ”¾å¢å¼º
        'shear': 0.0,                      # å‰ªåˆ‡å¢å¼º
        'perspective': 0.0,                # é€è§†å¢å¼º
        'flipud': 0.0,                     # ä¸Šä¸‹ç¿»è½¬
        'fliplr': 0.5,                     # å·¦å³ç¿»è½¬
        'mosaic': 1.0,                     # é©¬èµ›å…‹å¢å¼º
        'mixup': 0.0,                      # Mixupå¢å¼º
        'copy_paste': 0.0,                 # å¤åˆ¶ç²˜è´´å¢å¼º
        
        # è®­ç»ƒé…ç½®
        'patience': 50,                    # æ—©åœè€å¿ƒå€¼
        'save_period': 5,                  # ä¿å­˜é—´éš”
        'val': True,                       # è®­ç»ƒæœŸé—´éªŒè¯
        'plots': True,                     # ä¿å­˜å›¾è¡¨
        'cache': 'ram',                    # ç¼“å­˜åˆ°å†…å­˜
        
        # è¾“å‡ºé…ç½®
        'project': 'runs/train',
        'name': 'yolov11_x_gpu', # ä¿®æ­£: æ›´æ”¹å®éªŒåç§°
        'exist_ok': True,
        'verbose': True,
        
        # é«˜çº§é…ç½®
        'cos_lr': False,                   # ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦
        'close_mosaic': 10,                # æœ€å10ä¸ªepochå…³é—­mosaic
        'resume': False,                   # ä»æ–­ç‚¹æ¢å¤
        'overlap_mask': True,              # é‡å æ©ç 
        'mask_ratio': 4,                   # æ©ç æ¯”ä¾‹
        'dropout': 0.0,                    # Dropout
        'single_cls': False,               # å¤šç±»æ£€æµ‹
    }
    
    # 6. æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print(f"\nâš™ï¸ è®­ç»ƒé…ç½®:")
    print(f"   è®¾å¤‡: {device}")
    print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"   å›¾åƒå°ºå¯¸: {training_args['imgsz']}")
    print(f"   è®­ç»ƒè½®æ¬¡: {training_args['epochs']}")
    print(f"   æ··åˆç²¾åº¦: {amp}")
    print(f"   æ•°æ®åŠ è½½çº¿ç¨‹: {workers}")
    
    # 7. å¼€å§‹è®­ç»ƒ
    print(f"\nğŸ‹ï¸ å¼€å§‹è®­ç»ƒ...")
    try:
        # ç›‘æ§GPUå†…å­˜ä½¿ç”¨
        if gpu_available:
            print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
        
        # è®­ç»ƒæ¨¡å‹
        results = model.train(**training_args)
        
        print("âœ… è®­ç»ƒå®Œæˆï¼")
        
        # 8. æ˜¾ç¤ºè®­ç»ƒç»“æœ
        print(f"\nğŸ“Š è®­ç»ƒç»“æœ:")
        print(f"   æœ€ä½³æ¨¡å‹: {model.trainer.best}")
        print(f"   æœ€åæ¨¡å‹: {model.trainer.last}")
        print(f"   ç»“æœç›®å½•: {model.trainer.save_dir}")
        
        # 9. æ¨¡å‹éªŒè¯
        print(f"\nğŸ” æ¨¡å‹éªŒè¯...")
        metrics = model.val()
        print(f"   mAP50: {metrics.box.map50:.4f}")
        print(f"   mAP50-95: {metrics.box.map:.4f}")
        
        # 10. å¯¼å‡ºæ¨¡å‹ï¼ˆå¯é€‰ï¼‰
        export_formats = ['onnx', 'torchscript']
        for fmt in export_formats:
            try:
                print(f"\nğŸ“¦ å¯¼å‡º{fmt.upper()}æ ¼å¼...")
                export_path = model.export(format=fmt, imgsz=640)
                print(f"   {fmt.upper()}æ¨¡å‹: {export_path}")
            except Exception as e:
                print(f"   {fmt.upper()}å¯¼å‡ºå¤±è´¥: {e}")
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("\nğŸ”§ å»ºè®®:")
        print("   1. æ£€æŸ¥æ•°æ®é›†è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("   2. é™ä½æ‰¹æ¬¡å¤§å° (batch_size)")
        print("   3. å‡å°‘å›¾åƒå°ºå¯¸ (imgsz)")
        print("   4. å…³é—­æ··åˆç²¾åº¦è®­ç»ƒ (amp=False)")
        
        # GPUå†…å­˜ä¸è¶³æ—¶çš„å¤„ç†
        if gpu_available and "out of memory" in str(e).lower():
            print("   ğŸ’¡ GPUå†…å­˜ä¸è¶³ï¼Œå»ºè®®:")
            print("      - å‡å°batch_sizeåˆ°16æˆ–8")
            print("      - å‡å°imgszåˆ°416")
            print("      - è®¾ç½®cache=False")
    
    print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆï¼")
    print("=" * 60)
    
    # 11. æ¸…ç†GPUç¼“å­˜
    if gpu_available:
        torch.cuda.empty_cache()
        print("ğŸ§¹ GPUç¼“å­˜å·²æ¸…ç†")
    
    # 12. æä¾›ä½¿ç”¨å»ºè®®
    print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print(f"   1. è®­ç»ƒç»“æœä¿å­˜åœ¨: runs/train/yolov11_eais_gpu/")
    print(f"   2. æœ€ä½³æ¨¡å‹æƒé‡: runs/train/yolov11_eais_gpu/weights/best.pt")
    print(f"   3. è®­ç»ƒå›¾è¡¨: runs/train/yolov11_eais_gpu/results.png")
    print(f"   4. å¯ä»¥ä½¿ç”¨model.predict()è¿›è¡Œæ¨ç†æµ‹è¯•")
    
    # æ¨ç†ç¤ºä¾‹ä»£ç 
    print(f"\nğŸ“ æ¨ç†ç¤ºä¾‹:")
    print(f"""
# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
model = YOLO('runs/train/yolov11_eais_gpu/weights/best.pt')

# è¿›è¡Œæ¨ç†
results = model('path/to/image.jpg')

# æ˜¾ç¤ºç»“æœ
results[0].show()
    """)
