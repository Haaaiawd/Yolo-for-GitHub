# -*- coding: utf-8 -*-
"""
YOLOv11 è®­ç»ƒè„šæœ¬ - çº¢å¤–å°ç›®æ ‡æ£€æµ‹ (å·²é€‚é…å…‰æµè¾“å…¥)
åŸºäºè½»é‡åŒ–å›½äº§å¤§æ¨¡å‹çš„é«˜å¸§é¢‘å¼±å°ç›®æ ‡æ£€æµ‹è¯†åˆ«æŠ€æœ¯ç ”ç©¶

@Project: CQ-09 æŒ‘æˆ˜æ¯
@Dataset: tiaozhanbei_datasets_final 
@Classes: 6 (drone, car, ship, bus, pedestrian, cyclist)
"""
import argparse
import warnings
import torch
import numpy as np
import cv2
import os
import re
from ultralytics import YOLO
from ultralytics.data.dataset import YOLODataset
from ultralytics.data.augment import Compose

warnings.filterwarnings('ignore')

# =================================================================================
# æ ¸å¿ƒä¿®æ”¹ï¼šè‡ªå®šä¹‰æ•°æ®åŠ è½½å™¨ä»¥æ”¯æŒ5é€šé“ï¼ˆRGB+å…‰æµï¼‰è¾“å…¥
# =================================================================================
class YOLOv11OpticalFlowDataset(YOLODataset):
    """
    ä¸€ä¸ªè‡ªå®šä¹‰çš„YOLOæ•°æ®é›†ç±»ï¼Œç”¨äºåŠ è½½RGBå›¾åƒå’Œå¯¹åº”çš„å…‰æµæ•°æ®ï¼Œ
    å¹¶å°†å®ƒä»¬åˆå¹¶ä¸º5é€šé“è¾“å…¥ã€‚
    """
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    def get_input(self, idx):
        """è·å–å¹¶å¤„ç†å•ä¸ªæ ·æœ¬çš„è¾“å…¥æ•°æ®ï¼ŒåŒ…æ‹¬å›¾åƒå’Œå…‰æµã€‚"""
        # é¦–å…ˆï¼Œä½¿ç”¨çˆ¶ç±»çš„æ–¹æ³•è·å–åŸå§‹çš„RGBå›¾åƒ
        # ç›´æ¥è·å–å›¾åƒï¼Œä¸ä½¿ç”¨get_image_and_labelé¿å…å¤æ‚çš„å˜æ¢
        img_path = self.im_files[idx]
        img = cv2.imread(img_path)
        if img is None:
            raise FileNotFoundError(f"æ— æ³•åŠ è½½å›¾åƒ: {img_path}")
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # è·å–å½“å‰å›¾åƒçš„åŸå§‹è·¯å¾„
        img_path = self.im_files[idx]
        
        flow = None
        try:
            # å¥å£®çš„è·¯å¾„æ¨æ–­é€»è¾‘
            # e.g., from '.../datasets/balanced_tiaozhanbei_split/images/train/data01/0002.jpg'
            # to '.../datasets/balanced_tiaozhanbei_split/flow/train/data01/flow_0001_to_0002.npy'
            path_parts = img_path.replace(os.sep, '/').split('/')
            images_idx = path_parts.index('images')
            
            # æ„å»ºåŸºç¡€çš„å…‰æµç›®å½•
            flow_dir_parts = path_parts[:images_idx] + ['flow'] + path_parts[images_idx + 1:-1]
            flow_dir = '/'.join(flow_dir_parts)

            # è§£æå¸§æ–‡ä»¶å
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ–‡ä»¶åä¸­çš„åºåˆ—å·ï¼Œä¾‹å¦‚ '..._001500.jpg' -> '..._', '001500'
            filename = path_parts[-1]
            match = re.match(r'(.+?_)?(\d+)\.(jpg|png|bmp)', filename, re.IGNORECASE)
            if not match:
                raise FileNotFoundError("æ— æ³•ä»æ–‡ä»¶åè§£æå¸§å·")

            prefix = match.group(1) or ''
            current_frame_num = int(match.group(2))
            frame_num_len = len(match.group(2))

            if current_frame_num > 0:
                prev_frame_num = current_frame_num - 1
                
                # ä¿æŒå¸§å·çš„é›¶å¡«å……æ ¼å¼
                prev_frame_str = str(prev_frame_num).zfill(frame_num_len)
                current_frame_str = str(current_frame_num).zfill(frame_num_len)

                # æ„å»ºå…‰æµæ–‡ä»¶å
                flow_filename = f"flow_{prefix}{prev_frame_str}_to_{prefix}{current_frame_str}.npy"
                flow_filepath = os.path.join(flow_dir, flow_filename)

                if os.path.exists(flow_filepath):
                    flow = np.load(flow_filepath)
                else:
                    # å¦‚æœæ¨ç†å‡ºçš„æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¹Ÿåˆ›å»ºé›¶å…‰æµ
                    raise FileNotFoundError(f"å…‰æµæ–‡ä»¶ä¸å­˜åœ¨: {flow_filepath}")
            
        except (ValueError, IndexError, FileNotFoundError):
            # å¦‚æœæ˜¯ç¬¬ä¸€å¸§æˆ–ä»»ä½•è·¯å¾„è§£æå¤±è´¥ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªå…¨é›¶çš„å…‰æµ
            pass

        if flow is None:
            h, w, _ = img.shape
            flow = np.zeros((h, w, 2), dtype=np.float32)

        # è°ƒæ•´å…‰æµçš„å°ºå¯¸ä»¥åŒ¹é…ï¼ˆå¯èƒ½ç»è¿‡å˜æ¢çš„ï¼‰å›¾åƒå°ºå¯¸
        if flow.shape[:2] != img.shape[:2]:
            flow = cv2.resize(flow, (img.shape[1], img.shape[0]), interpolation=cv2.INTER_LINEAR)
            
        # æ ¸å¿ƒï¼šå°†RGBå›¾åƒå’Œå…‰æµæ•°æ®åœ¨é€šé“ç»´åº¦ä¸Šåˆå¹¶
        # img (H, W, 3) + flow (H, W, 2) -> combined (H, W, 5)
        combined_input = np.concatenate((img, flow), axis=2)
        
        return combined_input

    def build_transforms(self, hyp=None):
        """
        æ„å»ºæ•°æ®å¢å¼º/å˜æ¢ã€‚
        æ³¨æ„ï¼šæˆ‘ä»¬éœ€è¦ç¡®ä¿æ‰€æœ‰å˜æ¢éƒ½èƒ½æ­£ç¡®å¤„ç†5é€šé“æ•°æ®ã€‚
        å¹¸è¿çš„æ˜¯ï¼Œå¤§éƒ¨åˆ†ultralyticsçš„å‡ ä½•å˜æ¢ï¼ˆå¦‚ç¿»è½¬ã€ç¼©æ”¾ï¼‰æ˜¯é€šé“æ— å…³çš„ã€‚
        é¢œè‰²ç©ºé—´çš„å˜æ¢åˆ™éœ€è¦æ³¨æ„ï¼Œä½†é»˜è®¤æƒ…å†µä¸‹å®ƒä»¬é€šå¸¸åªåº”ç”¨äºå‰3ä¸ªé€šé“ã€‚
        ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬è¿™é‡Œç›´æ¥ä½¿ç”¨çˆ¶ç±»çš„æ–¹æ³•ï¼Œå¯¹äºæ ‡å‡†å¢å¼ºæ˜¯å®‰å…¨çš„ã€‚
        """
        if self.augment:
            hyp.mosaic = hyp.mosaic if self.augment and not self.rect else 0.0
            hyp.mixup = hyp.mixup if self.augment and not self.rect else 0.0
            # åˆ›å»ºä¸€ä¸ªèƒ½å¤„ç†5é€šé“çš„Composeå¯¹è±¡
            return Compose(self.get_transforms(hyp))
        else:
            # å¯¹äºéªŒè¯é›†ï¼Œé€šå¸¸åªæœ‰Resizeå’ŒToTensor
            return self.get_transforms(hyp)

    def __getitem__(self, idx):
        """é‡å†™__getitem__æ–¹æ³•ï¼Œè¿”å›5é€šé“æ•°æ®å’Œæ ‡ç­¾ã€‚"""
        # è·å–æ ‡ç­¾ç­‰ä¿¡æ¯
        label = self.labels[idx].copy()
        
        # è·å–5é€šé“è¾“å…¥
        input_data = self.get_input(idx)
        
        # è·å–å˜æ¢
        transform = self.build_transforms(self.hyp)
        
        # åº”ç”¨å˜æ¢
        if transform:
            input_data, label = transform(input_data, label)

        # Transpose a ndarray from (H, W, C) to (C, H, W)
        return torch.from_numpy(input_data.transpose(2, 0, 1)), label


# =================================================================================
# ä¸»è®­ç»ƒé€»è¾‘
# =================================================================================
def main():
    parser = argparse.ArgumentParser(description="YOLOv11 è®­ç»ƒè„šæœ¬ (å·²é€‚é…å…‰æµè¾“å…¥)")
    # é‡è¦ï¼šä¿®æ”¹å¸®åŠ©æ–‡æœ¬ï¼Œæç¤ºä½¿ç”¨5é€šé“æ¨¡å‹
    parser.add_argument('--model', type=str, required=True, help='æ¨¡å‹é…ç½®æ–‡ä»¶çš„è·¯å¾„ (e.g., configs/yolov11-5ch.yaml)')
    parser.add_argument('--data', type=str, required=True, help='æ•°æ®é›†é…ç½®æ–‡ä»¶çš„è·¯å¾„ (e.g., configs/tiaozhanbei_final.yaml)')
    parser.add_argument('--epochs', type=int, default=100, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch', type=int, default=16, help='æ‰¹å¤„ç†å¤§å°')
    parser.add_argument('--imgsz', type=int, default=640, help='è¾“å…¥å›¾åƒå°ºå¯¸')
    parser.add_argument('--project', type=str, default='runs/train', help='é¡¹ç›®ä¿å­˜ç›®å½•')
    parser.add_argument('--name', type=str, default='exp_5channel', help='å®éªŒåç§°')
    parser.add_argument('--device', type=str, default='', help='è¿è¡Œè®¾å¤‡ï¼Œå¦‚ "cpu", "0", "0,1"')
    parser.add_argument('--save_period', type=int, default=-1, help='æ¯éš”Nä¸ªepochä¿å­˜ä¸€æ¬¡æ£€æŸ¥ç‚¹, -1ä¸ºä¸å¯ç”¨')
    # æ ¸å¿ƒä¿®æ”¹ï¼šæ·»åŠ  --weights å‚æ•°ç”¨äºè¿ç§»å­¦ä¹ 
    parser.add_argument('--weights', type=str, default='', help='é¢„è®­ç»ƒæƒé‡æ–‡ä»¶çš„è·¯å¾„ (e.g., path/to/yolo11x.pt)')
    # å¯¹äº5é€šé“æ¨¡å‹ï¼Œé€šå¸¸éœ€è¦ä»yamlæ„å»ºï¼Œè€Œä¸æ˜¯ä»ptæ¢å¤ï¼Œä½†ä¿ç•™resumeé€‰é¡¹ä»¥å¤‡ä¸æ—¶ä¹‹éœ€
    parser.add_argument('--resume', type=str, default='', help='ä»æŒ‡å®šçš„.ptæ–‡ä»¶æ¢å¤è®­ç»ƒ, e.g., path/to/last.pt')
    
    args = parser.parse_args()

    # åˆå§‹åŒ–YOLOæ¨¡å‹
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {args.model}")

    # æ£€æŸ¥æ˜¯å¦æ˜¯é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶
    if args.model.endswith('.pt'):
        print("ğŸ“¦ åŸºäºé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œ5é€šé“æ‰©å±•...")
        model = YOLO(args.model)

        # ä¿®æ”¹ç¬¬ä¸€å±‚å·ç§¯ä»¥æ”¯æŒ5é€šé“è¾“å…¥
        def modify_first_conv_for_5_channels(model):
            """ä¿®æ”¹æ¨¡å‹çš„ç¬¬ä¸€å±‚å·ç§¯ä»¥æ”¯æŒ5é€šé“è¾“å…¥"""
            import torch.nn as nn

            # è·å–ç¬¬ä¸€å±‚å·ç§¯
            first_conv = model.model.model[0].conv

            # åˆ›å»ºæ–°çš„5é€šé“å·ç§¯å±‚
            new_conv = nn.Conv2d(
                in_channels=5,  # 5é€šé“è¾“å…¥
                out_channels=first_conv.out_channels,
                kernel_size=first_conv.kernel_size,
                stride=first_conv.stride,
                padding=first_conv.padding,
                bias=first_conv.bias is not None
            )

            # å¤åˆ¶åŸæœ‰æƒé‡åˆ°æ–°å±‚
            with torch.no_grad():
                # å¤åˆ¶RGBé€šé“çš„æƒé‡
                new_conv.weight[:, :3, :, :] = first_conv.weight
                # ä¸ºå…‰æµé€šé“åˆå§‹åŒ–æƒé‡ï¼ˆå¤åˆ¶ç»¿è‰²é€šé“çš„æƒé‡ï¼‰
                new_conv.weight[:, 3:5, :, :] = first_conv.weight[:, 1:2, :, :].repeat(1, 2, 1, 1)

                if first_conv.bias is not None:
                    new_conv.bias = first_conv.bias

            # æ›¿æ¢ç¬¬ä¸€å±‚
            model.model.model[0].conv = new_conv
            print("âœ… æˆåŠŸå°†ç¬¬ä¸€å±‚å·ç§¯ä»3é€šé“æ‰©å±•åˆ°5é€šé“")

            return model

        # åº”ç”¨5é€šé“ä¿®æ”¹
        model = modify_first_conv_for_5_channels(model)

    else:
        print("ğŸ“‹ ä»YAMLé…ç½®æ–‡ä»¶åˆ›å»ºæ¨¡å‹...")
        model = YOLO(args.model)


    # =============================================================================
    # æ ¸å¿ƒä¿®æ”¹ï¼šå°†è‡ªå®šä¹‰çš„Datasetç±»æ³¨å…¥åˆ°è®­ç»ƒå™¨ä¸­
    # =============================================================================

    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨5é€šé“æ¨¡å‹
    is_5channel = args.model.endswith('5ch.yaml') or '5ch' in args.model

    if is_5channel:
        print("ğŸš€ ä½¿ç”¨5é€šé“æ¨¡å‹ï¼ˆRGB + å…‰æµï¼‰è¿›è¡Œè®­ç»ƒ...")

        # ä¸º5é€šé“æ¨¡å‹è®¾ç½®è‡ªå®šä¹‰æ•°æ®é›†
        from ultralytics.engine.trainer import BaseTrainer
        from ultralytics.models.yolo.detect import DetectionTrainer

        # åˆ›å»ºè‡ªå®šä¹‰è®­ç»ƒå™¨ç±»
        class OpticalFlowTrainer(DetectionTrainer):
            def build_dataset(self, img_path, mode="train", batch=None):
                """æ„å»ºè‡ªå®šä¹‰æ•°æ®é›†ï¼Œæ”¯æŒ5é€šé“è¾“å…¥"""
                dataset = YOLOv11OpticalFlowDataset(
                    img_path=img_path,
                    imgsz=self.args.imgsz,
                    batch_size=batch,
                    augment=mode == "train",
                    hyp=self.hyp,
                    rect=False,
                    cache=getattr(self.args, 'cache', False),
                    single_cls=getattr(self.args, 'single_cls', False),
                    stride=int(self.stride.max() if self.stride else 32),
                    pad=0.0 if mode == "train" else 0.5,
                    prefix=f"{mode}: ",
                    task=self.args.task,
                    classes=getattr(self.args, 'classes', None),
                    data=self.data,
                    fraction=getattr(self.args, 'fraction', 1.0) if mode == "train" else 1.0,
                )
                return dataset

        # ä½¿ç”¨è‡ªå®šä¹‰è®­ç»ƒå™¨
        model.trainer = OpticalFlowTrainer

    else:
        print("ğŸ“· ä½¿ç”¨æ ‡å‡†3é€šé“æ¨¡å‹è¿›è¡Œè®­ç»ƒ...")

    # å¼€å§‹è®­ç»ƒ
    results = model.train(
        data=args.data,
        epochs=args.epochs,
        batch=args.batch,
        imgsz=args.imgsz,
        project=args.project,
        name=args.name,
        device=args.device,
        save_period=args.save_period,
        resume=bool(args.resume),
        verbose=True
    )

    print("âœ… è®­ç»ƒå®Œæˆï¼")
    return results

if __name__ == '__main__':
    main()
